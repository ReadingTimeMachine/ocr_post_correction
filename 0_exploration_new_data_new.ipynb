{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1675029271460,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "RYwpkolCjbwf"
   },
   "source": [
    "## Use opence-v1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285506,
     "status": "ok",
     "timestamp": 1675029556960,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "l2uSZFDYBfUt",
    "outputId": "97d0eaeb-4e7c-4574-818b-33cefe253fe6"
   },
   "outputs": [],
   "source": [
    "#  # mount drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/', force_remount=True)\n",
    "# root_dir = \"/content/gdrive/MyDrive\"\n",
    "# # change the OS to use your project folder as the working directory\n",
    "# notebooks = \"/post_ocr_repository/post_ocr_correction/notebooks/en\"\n",
    "# import os\n",
    "# os.chdir(root_dir + notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HAL\n",
    "# file_dir = '/home/jnaiman/wwt_image_extraction/alignments/'\n",
    "# output_folder = '/home/jnaiman/data/morgan/'\n",
    "# # utils from local\n",
    "# from sys import path\n",
    "# path.append('/home/jnaiman/libraries/')\n",
    "# from utils_ocr_mini import align_texts_fast\n",
    "\n",
    "# local\n",
    "file_dir = '/Users/jnaiman/Dropbox/wwt_image_extraction/OCRPostCorrection/alignments/'\n",
    "output_folder = '/Users/jnaiman/Downloads/tmp/ocrpost/data/morgan/'\n",
    "from sys import path\n",
    "path.append('../scienceDigitization/text_mining_ocr_and_pdf/ocr_spell_check/')\n",
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import align_texts_fast, get_fill_in_types\n",
    "\n",
    "\n",
    "# train_file = 'train_masked_n500000_20230503.csv'\n",
    "# val_file = 'val_masked_n10000_20230503.csv'\n",
    "# test_file = 'test_masked_n10000_20230503.csv'\n",
    "# ender = '_large'\n",
    "\n",
    "# train_file = 'train_masked_n200000_20230502.csv'\n",
    "# val_file = 'val_masked_n5000_20230502.csv'\n",
    "# test_file = 'test_masked_n5000_20230502.csv'\n",
    "# ender = '_regular'\n",
    "\n",
    "train_file = 'train_masked_n100000_20230510.csv'\n",
    "val_file = 'val_masked_n5000_20230510.csv'\n",
    "test_file = 'test_masked_n5000_20230510.csv'\n",
    "ender = '_small_words'\n",
    "\n",
    "\n",
    "window_length = 100 # for subsetting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 2267,
     "status": "ok",
     "timestamp": 1675029559224,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "Twat4cYVq7Wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sys import path\n",
    "#path.append('/home/jnaiman/.local')\n",
    "\n",
    "from nltk.lm import Vocabulary\n",
    "#import sys\n",
    "#sys.path.append(\"../../lib\")\n",
    "#from metrics import levenshtein\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from Levenshtein import distance\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import Levenshtein\n",
    "\n",
    "import time\n",
    "#from multiprocessing import Pool\n",
    "from multiprocess import Pool # not sure if this is needed only on the mac?\n",
    "\n",
    "\n",
    "# from importlib import reload\n",
    "# import utils_ocr_mini\n",
    "# reload(utils_ocr_mini)\n",
    "# from utils_ocr_mini import align_texts_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(x):\n",
    "    A, B, window_length = x\n",
    "    assert len(A) == len(B)\n",
    "    return [(A[i:i + window_length], B[i:i + window_length]) \n",
    "            for i in range(len(A) + 1)]\n",
    "\n",
    "def levenshtein(reference, hypothesis, progress_bar = False):\n",
    "    assert len(reference) == len(hypothesis)\n",
    "    text = zip(reference, hypothesis)\n",
    "    if progress_bar:\n",
    "        text = tqdm(text, total = len(reference))\n",
    "    d = [distance(r, h) for r, h in text]\n",
    "    output = pd.DataFrame({\"reference\":reference, \"hypothesis\":hypothesis})\\\n",
    "    .assign(distance = lambda df: d)\\\n",
    "    .assign(\n",
    "        cer = lambda df: df.apply(\n",
    "            lambda r: 100 * r[\"distance\"] / max(len(r[\"reference\"]), 1), \n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all data, format maybe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(file_dir + train_file)\n",
    "val_data = pd.read_csv(file_dir + val_file)\n",
    "test_data = pd.read_csv(file_dir + test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take out all non-word stuff -- only save words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_formatted_columns(datain):\n",
    "    source = []\n",
    "    target = []\n",
    "    source_aligned = []\n",
    "    target_aligned = []\n",
    "    for i in range(len(datain)):\n",
    "        d = datain.iloc[i]\n",
    "        s = np.array(list(d['aligned sentences source'])) # aligned source, with ^ symbols\n",
    "        t = np.array(list(d['aligned sentences target'])) # aligned target, with @ symbols\n",
    "        a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))\n",
    "        ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "        tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "        source_aligned.append(ss.replace('^','@')) # align with original \n",
    "        target_aligned.append(tt)\n",
    "        source.append(ss.replace('^',''))\n",
    "        target.append(tt.replace('@',''))\n",
    "\n",
    "    datain['words source aligned'] = source_aligned\n",
    "    datain['words target aligned'] = target_aligned\n",
    "    datain['words source'] = source\n",
    "    datain['words target'] = target\n",
    "    return datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = add_formatted_columns(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = add_formatted_columns(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = add_formatted_columns(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = []\n",
    "# target = []\n",
    "# source_aligned = []\n",
    "# target_aligned = []\n",
    "# for i in range(len(val_data)):\n",
    "#     d = val_data.iloc[i]\n",
    "#     s = np.array(list(d['aligned sentences source'])) # aligned source\n",
    "#     t = np.array(list(d['aligned sentences target'])) # aligned target\n",
    "#     a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))\n",
    "#     ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "#     tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "#     source_aligned.append(ss)\n",
    "#     target_aligned.append(tt)\n",
    "#     source.append(ss.replace('@',''))\n",
    "#     target.append(tt.replace('^',''))\n",
    "    \n",
    "# val_data['words source aligned'] = source_aligned\n",
    "# val_data['words target aligned'] = target_aligned\n",
    "# val_data['words source'] = source\n",
    "# val_data['words target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source = []\n",
    "# target = []\n",
    "# source_aligned = []\n",
    "# target_aligned = []\n",
    "# for i in range(len(test_data)):\n",
    "#     d = test_data.iloc[i]\n",
    "#     s = np.array(list(d['aligned sentences source'])) # aligned source\n",
    "#     t = np.array(list(d['aligned sentences target'])) # aligned target\n",
    "#     a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))\n",
    "#     ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "#     tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "#     source_aligned.append(ss)\n",
    "#     target_aligned.append(tt)\n",
    "#     source.append(ss.replace('@',''))\n",
    "#     target.append(tt.replace('^',''))\n",
    "    \n",
    "# test_data['words source aligned'] = source_aligned\n",
    "# test_data['words target aligned'] = target_aligned\n",
    "# test_data['words source'] = source\n",
    "# test_data['words target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.read_csv(file_dir + train_file)\n",
    "# data2 = pd.read_csv(file_dir + val_file)\n",
    "# data3 = pd.read_csv(file_dir + test_file)\n",
    "#data = pd.concat([data1,data2,data3],ignore_index=True)\n",
    "\n",
    "data = pd.concat([train_data,val_data,test_data],ignore_index=True)\n",
    "\n",
    "# data = data.rename(columns={\"sentences source\": \"ocr_aligned\", \n",
    "#                         \"sentences target\": \"gs_aligned\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.loc[ (pd.isnull(data['ocr_aligned'])) | (pd.isnull(data['gs_aligned'])) ]\n",
    "#mask = (pd.isnull(data['ocr_aligned'])) | (pd.isnull(data['gs_aligned']))\n",
    "mask = (pd.isnull(data['words source'])) | (pd.isnull(data['words target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,t in zip(data['words source'].values, data['words target'].values):\n",
    "    if type(s) == float or type(t) == float:\n",
    "        import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aligned sentences source</th>\n",
       "      <th>aligned sentences target</th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>aligned sentences source types</th>\n",
       "      <th>aligned sentences target types</th>\n",
       "      <th>sentences source types</th>\n",
       "      <th>sentences target types</th>\n",
       "      <th>words source aligned</th>\n",
       "      <th>words target aligned</th>\n",
       "      <th>words source</th>\n",
       "      <th>words target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>. Early two-dimensional observations of filame...</td>\n",
       "      <td>@ Early two-dimensional observations of filame...</td>\n",
       "      <td>. Early two-dimensional observations of filame...</td>\n",
       "      <td>Early two-dimensional observations of filamen...</td>\n",
       "      <td>W WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWW...</td>\n",
       "      <td>@ WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWW...</td>\n",
       "      <td>W WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWW...</td>\n",
       "      <td>WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWWW...</td>\n",
       "      <td>Early two-dimensional observations of filamen...</td>\n",
       "      <td>Early two-dimensional observations of filamen...</td>\n",
       "      <td>Early two-dimensional observations of filamen...</td>\n",
       "      <td>Early two-dimensional observations of filamen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However. what is remarkable here is that whil...</td>\n",
       "      <td>However, what is remarkable here is that whil...</td>\n",
       "      <td>However. what is remarkable here is that whil...</td>\n",
       "      <td>However, what is remarkable here is that whil...</td>\n",
       "      <td>WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...</td>\n",
       "      <td>WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...</td>\n",
       "      <td>WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...</td>\n",
       "      <td>WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...</td>\n",
       "      <td>However. what is remarkable here is that whil...</td>\n",
       "      <td>However, what is remarkable here is that whil...</td>\n",
       "      <td>However. what is remarkable here is that whil...</td>\n",
       "      <td>However, what is remarkable here is that whil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "      <td>WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...</td>\n",
       "      <td>WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...</td>\n",
       "      <td>WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...</td>\n",
       "      <td>WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...</td>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "      <td>Therefore, the non-detection of the GRXE in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We- vote tha^ the age estimate by Weinberger ...</td>\n",
       "      <td>We@ note that the age estimate by Weinberger ...</td>\n",
       "      <td>We- vote tha the age estimate by Weinberger e...</td>\n",
       "      <td>We note that the age estimate by Weinberger e...</td>\n",
       "      <td>WWW WWWW WWW^ WWW WWW WWWWWWWW WW WWWWWWWWWW ...</td>\n",
       "      <td>WW@ WWWW WWWW WWW WWW WWWWWWWW WW WWWWWWWWWW ...</td>\n",
       "      <td>WWW WWWW WWW WWW WWW WWWWWWWW WW WWWWWWWWWW W...</td>\n",
       "      <td>WW WWWW WWWW WWW WWW WWWWWWWW WW WWWWWWWWWW W...</td>\n",
       "      <td>We- vote tha^ the age estimate by Weinberger ...</td>\n",
       "      <td>We@ note that the age estimate by Weinberger ...</td>\n",
       "      <td>We- vote tha^ the age estimate by Weinberger ...</td>\n",
       "      <td>We@ note that the age estimate by Weinberger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lem When the accretion rate is slightly lower...</td>\n",
       "      <td>1cm When the accretion rate is slightly lower...</td>\n",
       "      <td>lem When the accretion rate is slightly lower...</td>\n",
       "      <td>1cm When the accretion rate is slightly lower...</td>\n",
       "      <td>WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...</td>\n",
       "      <td>WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...</td>\n",
       "      <td>WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...</td>\n",
       "      <td>WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...</td>\n",
       "      <td>lem When the accretion rate is slightly lower...</td>\n",
       "      <td>1cm When the accretion rate is slightly lower...</td>\n",
       "      <td>lem When the accretion rate is slightly lower...</td>\n",
       "      <td>1cm When the accretion rate is slightly lower...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            aligned sentences source  \\\n",
       "0  . Early two-dimensional observations of filame...   \n",
       "1   However. what is remarkable here is that whil...   \n",
       "2   Therefore, the non-detection of the GRXE in t...   \n",
       "3   We- vote tha^ the age estimate by Weinberger ...   \n",
       "4   lem When the accretion rate is slightly lower...   \n",
       "\n",
       "                            aligned sentences target  \\\n",
       "0  @ Early two-dimensional observations of filame...   \n",
       "1   However, what is remarkable here is that whil...   \n",
       "2   Therefore, the non-detection of the GRXE in t...   \n",
       "3   We@ note that the age estimate by Weinberger ...   \n",
       "4   1cm When the accretion rate is slightly lower...   \n",
       "\n",
       "                                    sentences source  \\\n",
       "0  . Early two-dimensional observations of filame...   \n",
       "1   However. what is remarkable here is that whil...   \n",
       "2   Therefore, the non-detection of the GRXE in t...   \n",
       "3   We- vote tha the age estimate by Weinberger e...   \n",
       "4   lem When the accretion rate is slightly lower...   \n",
       "\n",
       "                                    sentences target  \\\n",
       "0   Early two-dimensional observations of filamen...   \n",
       "1   However, what is remarkable here is that whil...   \n",
       "2   Therefore, the non-detection of the GRXE in t...   \n",
       "3   We note that the age estimate by Weinberger e...   \n",
       "4   1cm When the accretion rate is slightly lower...   \n",
       "\n",
       "                      aligned sentences source types  \\\n",
       "0  W WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWW...   \n",
       "1   WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...   \n",
       "2   WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...   \n",
       "3   WWW WWWW WWW^ WWW WWW WWWWWWWW WW WWWWWWWWWW ...   \n",
       "4   WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...   \n",
       "\n",
       "                      aligned sentences target types  \\\n",
       "0  @ WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWW...   \n",
       "1   WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...   \n",
       "2   WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...   \n",
       "3   WW@ WWWW WWWW WWW WWW WWWWWWWW WW WWWWWWWWWW ...   \n",
       "4   WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...   \n",
       "\n",
       "                              sentences source types  \\\n",
       "0  W WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWW...   \n",
       "1   WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...   \n",
       "2   WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...   \n",
       "3   WWW WWWW WWW WWW WWW WWWWWWWW WW WWWWWWWWWW W...   \n",
       "4   WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...   \n",
       "\n",
       "                              sentences target types  \\\n",
       "0   WWWWW WWWWWWWWWWWWWWW WWWWWWWWWWWW WW WWWWWWW...   \n",
       "1   WWWWWWWW WWWW WW WWWWWWWWWW WWWW WW WWWW WWWW...   \n",
       "2   WWWWWWWWWW WWW WWWWWWWWWWWWW WW WWW WWWW WW W...   \n",
       "3   WW WWWW WWWW WWW WWW WWWWWWWW WW WWWWWWWWWW W...   \n",
       "4   WWW WWWW WWW WWWWWWWWW WWWW WW WWWWWWWW WWWWW...   \n",
       "\n",
       "                                words source aligned  \\\n",
       "0   Early two-dimensional observations of filamen...   \n",
       "1   However. what is remarkable here is that whil...   \n",
       "2   Therefore, the non-detection of the GRXE in t...   \n",
       "3   We- vote tha^ the age estimate by Weinberger ...   \n",
       "4   lem When the accretion rate is slightly lower...   \n",
       "\n",
       "                                words target aligned  \\\n",
       "0   Early two-dimensional observations of filamen...   \n",
       "1   However, what is remarkable here is that whil...   \n",
       "2   Therefore, the non-detection of the GRXE in t...   \n",
       "3   We@ note that the age estimate by Weinberger ...   \n",
       "4   1cm When the accretion rate is slightly lower...   \n",
       "\n",
       "                                        words source  \\\n",
       "0   Early two-dimensional observations of filamen...   \n",
       "1   However. what is remarkable here is that whil...   \n",
       "2   Therefore, the non-detection of the GRXE in t...   \n",
       "3   We- vote tha^ the age estimate by Weinberger ...   \n",
       "4   lem When the accretion rate is slightly lower...   \n",
       "\n",
       "                                        words target  \n",
       "0   Early two-dimensional observations of filamen...  \n",
       "1   However, what is remarkable here is that whil...  \n",
       "2   Therefore, the non-detection of the GRXE in t...  \n",
       "3   We@ note that the age estimate by Weinberger ...  \n",
       "4   1cm When the accretion rate is slightly lower...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[~mask].applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    110000.000000\n",
       "mean          5.023229\n",
       "std           9.369398\n",
       "min           0.000000\n",
       "25%           0.934579\n",
       "50%           2.976190\n",
       "75%           5.853659\n",
       "max         133.333333\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = data[~mask]['words target'], \n",
    "            hypothesis = data[~mask]['words source']).cer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun_vocab = False\n",
    "\n",
    "# if rerun_vocab:\n",
    "#     start_time = time.time()\n",
    "#     #vocabulary = Vocabulary(data[~mask].ocr_aligned.sum() + data[~mask].gs_aligned.sum())\n",
    "#     vocabulary = Vocabulary(data[~mask]['words source'].sum() + data[~mask]['words target'].sum())\n",
    "#     print(len(vocabulary))\n",
    "#     with open(output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\", \"wb\") as file:\n",
    "#         pickle.dump(vocabulary, file)\n",
    "#     end_time = time.time()\n",
    "#     print('time delta =', end_time-start_time, 'seconds, or', \n",
    "#           (end_time-start_time)/60., 'minutes, or',\n",
    "#          (end_time-start_time)/60./60., 'hours')\n",
    "#     # last run:\n",
    "#     #time delta = 11285.80526137352 seconds, 188.09675435622532 minutes, ~3.3 hours on HAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create windowed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in only the training data and do stuff with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(file_dir + train_file)\n",
    "\n",
    "# train = train.rename(columns={\"sentences source\": \"ocr_aligned\", \n",
    "#                         \"sentences target\": \"gs_aligned\"})\n",
    "\n",
    "#mask = (pd.isnull(train['ocr_aligned'])) | (pd.isnull(train['gs_aligned']))\n",
    "#mask = (pd.isnull(train['sentences source'])) | (pd.isnull(train['sentences target']))\n",
    "mask = (pd.isnull(train_data['words source'])) | (pd.isnull(train_data['words target']))\n",
    "\n",
    "train_data = train_data[~mask]\n",
    "\n",
    "# now align\n",
    "gs_aligned = []; ocr_aligned = []\n",
    "gs = []; ocr = []\n",
    "for o,p in zip(train_data['words source'].values, train_data['words target'].values):\n",
    "    eops = Levenshtein.editops(o, p)\n",
    "    ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "    gs_aligned.append(pdf_text_aligned)\n",
    "    # futze with ocr aligned so it matches data input\n",
    "    ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "    ocr_aligned.append(ocr_text_aligned)\n",
    "    gs.append(pdf_text_aligned.replace('@',''))\n",
    "    ocr.append(ocr_text_aligned.replace('@',''))\n",
    "    \n",
    "train_data['gs_aligned'] = gs_aligned\n",
    "train_data['ocr_aligned'] = ocr_aligned\n",
    "train_data['gs'] = gs\n",
    "train_data['ocr'] = ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (pd.isnull(val_data['words source'])) | (pd.isnull(val_data['words target']))\n",
    "\n",
    "val_data = val_data[~mask]\n",
    "\n",
    "# now align\n",
    "gs_aligned = []; ocr_aligned = []\n",
    "gs = []; ocr = []\n",
    "for o,p in zip(val_data['words source'].values, val_data['words target'].values):\n",
    "    eops = Levenshtein.editops(o, p)\n",
    "    ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "    gs_aligned.append(pdf_text_aligned)\n",
    "    # futze with ocr aligned so it matches data input\n",
    "    ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "    ocr_aligned.append(ocr_text_aligned)\n",
    "    gs.append(pdf_text_aligned.replace('@',''))\n",
    "    ocr.append(ocr_text_aligned.replace('@',''))\n",
    "    \n",
    "val_data['gs_aligned'] = gs_aligned\n",
    "val_data['ocr_aligned'] = ocr_aligned\n",
    "val_data['gs'] = gs\n",
    "val_data['ocr'] = ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (pd.isnull(test_data['words source'])) | (pd.isnull(test_data['words target']))\n",
    "\n",
    "test_data = test_data[~mask]\n",
    "\n",
    "# now align\n",
    "gs_aligned = []; ocr_aligned = []\n",
    "gs = []; ocr = []\n",
    "for o,p in zip(test_data['words source'].values, test_data['words target'].values):\n",
    "    eops = Levenshtein.editops(o, p)\n",
    "    ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "    gs_aligned.append(pdf_text_aligned)\n",
    "    # futze with ocr aligned so it matches data input\n",
    "    ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "    ocr_aligned.append(ocr_text_aligned)\n",
    "    gs.append(pdf_text_aligned.replace('@',''))\n",
    "    ocr.append(ocr_text_aligned.replace('@',''))\n",
    "    \n",
    "test_data['gs_aligned'] = gs_aligned\n",
    "test_data['ocr_aligned'] = ocr_aligned\n",
    "test_data['gs'] = gs\n",
    "test_data['ocr'] = ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([train_data,val_data,test_data],ignore_index=True)\n",
    "\n",
    "# data['ocr'].iloc[:10].sum() + data['gs'].iloc[:10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "time delta = 145.02771306037903 seconds, or 2.417128551006317 minutes, or 0.040285475850105286 hours\n"
     ]
    }
   ],
   "source": [
    "rerun_vocab = False\n",
    "\n",
    "if rerun_vocab:\n",
    "    data = pd.concat([train_data,val_data,test_data],ignore_index=True)\n",
    "    start_time = time.time()\n",
    "    #vocabulary = Vocabulary(data[~mask].ocr_aligned.sum() + data[~mask].gs_aligned.sum())\n",
    "    #vocabulary = Vocabulary(data[~mask]['ocr'].sum() + data[~mask]['gs'].sum())\n",
    "    vocabulary = Vocabulary(data['ocr'].sum() + data['gs'].sum() + '@')\n",
    "    print(len(vocabulary))\n",
    "    with open(output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\", \"wb\") as file:\n",
    "        pickle.dump(vocabulary, file)\n",
    "    end_time = time.time()\n",
    "    print('time delta =', end_time-start_time, 'seconds, or', \n",
    "          (end_time-start_time)/60., 'minutes, or',\n",
    "         (end_time-start_time)/60./60., 'hours')\n",
    "    # last run:\n",
    "    #time delta = 11285.80526137352 seconds, 188.09675435622532 minutes, ~3.3 hours on HAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = data.drop(dev.index)\n",
    "train_data.to_pickle(output_folder+\"/data/train_new_pages\"+ender+\".pkl\")\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b5bf9fc7d14ebca671dfa4693c5838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dc67e0fe494ed1b42e646c0fad87af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13826088, 2)\n",
      "total time = 27.231825828552246 seconds, or 0.4538637638092041 minutes\n"
     ]
    }
   ],
   "source": [
    "# df = train#.head(100)\n",
    "# train_aligned = list(p.imap_unordered(create_windows, \n",
    "#                                       tqdm(zip(df.ocr_aligned, \n",
    "#                                                df.gs_aligned, \n",
    "#                                                [window_length for x in df.ocr_aligned]), \n",
    "#                                            total = len(df.ocr_aligned)),\n",
    "#                                       chunksize = 128))\n",
    "# s = []\n",
    "# for r in tqdm(train_aligned):\n",
    "#     s.extend(r)\n",
    "# train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "# print(train_aligned.shape)\n",
    "# train_aligned.head()\n",
    "start_time = time.time()\n",
    "with Pool(4) as p:\n",
    "    train_aligned = list(p.imap_unordered(create_windows, \n",
    "                                          tqdm(zip(train_data.ocr_aligned, \n",
    "                                                   train_data.gs_aligned, \n",
    "                                                   [window_length for x in train_data.ocr_aligned]), \n",
    "                                               total = len(train_data.ocr_aligned)),\n",
    "                                          chunksize = 128))\n",
    "s = []\n",
    "for r in tqdm(train_aligned):\n",
    "    s.extend(r)\n",
    "train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "print(train_aligned.shape)\n",
    "train_aligned.head()\n",
    "end_time = time.time()\n",
    "print('total time =', end_time-start_time, 'seconds, or', (end_time-start_time)/60., 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This research was supported by the TIER 11th ...</td>\n",
       "      <td>This research was supported by the TIFR 11th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This research was supported by the TIER 11th F...</td>\n",
       "      <td>This research was supported by the TIFR 11th F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>his research was supported by the TIER 11th Fi...</td>\n",
       "      <td>his research was supported by the TIFR 11th Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is research was supported by the TIER 11th Fiv...</td>\n",
       "      <td>is research was supported by the TIFR 11th Fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s research was supported by the TIER 11th Five...</td>\n",
       "      <td>s research was supported by the TIFR 11th Five...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0   This research was supported by the TIER 11th ...   \n",
       "1  This research was supported by the TIER 11th F...   \n",
       "2  his research was supported by the TIER 11th Fi...   \n",
       "3  is research was supported by the TIER 11th Fiv...   \n",
       "4  s research was supported by the TIER 11th Five...   \n",
       "\n",
       "                                              target  \n",
       "0   This research was supported by the TIFR 11th ...  \n",
       "1  This research was supported by the TIFR 11th F...  \n",
       "2  his research was supported by the TIFR 11th Fi...  \n",
       "3  is research was supported by the TIFR 11th Fiv...  \n",
       "4  s research was supported by the TIFR 11th Five...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aligned = train_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid = pd.read_csv(file_dir + val_file)\n",
    "\n",
    "# mask = (pd.isnull(valid['sentences source'])) | (pd.isnull(valid['sentences target']))\n",
    "\n",
    "# valid = valid[~mask]\n",
    "\n",
    "# # now align\n",
    "# gs_aligned = []; ocr_aligned = []\n",
    "# for o,p in zip(valid['sentences source'].values, valid['sentences target'].values):\n",
    "#     eops = Levenshtein.editops(o, p)\n",
    "#     ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "#     gs_aligned.append(pdf_text_aligned)\n",
    "#     # futze with ocr aligned so it matches data input\n",
    "#     ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "#     ocr_aligned.append(ocr_text_aligned)\n",
    "    \n",
    "# valid['gs_aligned'] = gs_aligned\n",
    "# valid['ocr_aligned'] = ocr_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690924, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First. claiming both uses for the spectroscop...</td>\n",
       "      <td>First, claiming both uses for the spectroscop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First. claiming both uses for the spectroscopi...</td>\n",
       "      <td>First, claiming both uses for the spectroscopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irst. claiming both uses for the spectroscopic...</td>\n",
       "      <td>irst, claiming both uses for the spectroscopic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rst. claiming both uses for the spectroscopic ...</td>\n",
       "      <td>rst, claiming both uses for the spectroscopic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st. claiming both uses for the spectroscopic s...</td>\n",
       "      <td>st, claiming both uses for the spectroscopic s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0   First. claiming both uses for the spectroscop...   \n",
       "1  First. claiming both uses for the spectroscopi...   \n",
       "2  irst. claiming both uses for the spectroscopic...   \n",
       "3  rst. claiming both uses for the spectroscopic ...   \n",
       "4  st. claiming both uses for the spectroscopic s...   \n",
       "\n",
       "                                              target  \n",
       "0   First, claiming both uses for the spectroscop...  \n",
       "1  First, claiming both uses for the spectroscopi...  \n",
       "2  irst, claiming both uses for the spectroscopic...  \n",
       "3  rst, claiming both uses for the spectroscopic ...  \n",
       "4  st, claiming both uses for the spectroscopic s...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = val_data.apply(lambda r: create_windows((r[\"ocr_aligned\"], r[\"gs_aligned\"], window_length)), \n",
    "                            axis = 1).sum()\n",
    "dev_aligned = pd.DataFrame(dev_aligned, columns = [\"source\", \"target\"])\n",
    "print(dev_aligned.shape)\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First. claiming both uses for the spectroscop...</td>\n",
       "      <td>First, claiming both uses for the spectroscop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First. claiming both uses for the spectroscopi...</td>\n",
       "      <td>First, claiming both uses for the spectroscopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irst. claiming both uses for the spectroscopic...</td>\n",
       "      <td>irst, claiming both uses for the spectroscopic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rst. claiming both uses for the spectroscopic ...</td>\n",
       "      <td>rst, claiming both uses for the spectroscopic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st. claiming both uses for the spectroscopic s...</td>\n",
       "      <td>st, claiming both uses for the spectroscopic s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0   First. claiming both uses for the spectroscop...   \n",
       "1  First. claiming both uses for the spectroscopi...   \n",
       "2  irst. claiming both uses for the spectroscopic...   \n",
       "3  rst. claiming both uses for the spectroscopic ...   \n",
       "4  st. claiming both uses for the spectroscopic s...   \n",
       "\n",
       "                                              target  \n",
       "0   First, claiming both uses for the spectroscop...  \n",
       "1  First, claiming both uses for the spectroscopi...  \n",
       "2  irst, claiming both uses for the spectroscopic...  \n",
       "3  rst, claiming both uses for the spectroscopic ...  \n",
       "4  st, claiming both uses for the spectroscopic s...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"data/train_aligned_new_pages\"+ender+\".pkl\")\n",
    "dev_aligned.to_pickle(output_folder+\"data/dev_aligned_new_pages\"+ender+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jnaiman/Downloads/tmp/ocrpost/data/morgan/data/train_aligned_new_pages_small_words.pkl'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder+\"data/train_aligned_new_pages\"+ender+\".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jnaiman/Downloads/tmp/ocrpost/data/morgan/data/dev_aligned_new_pages_small_words.pkl'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder+\"data/dev_aligned_new_pages\"+ender+\".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(train_aligned)):\n",
    "#     d = train_aligned.iloc[i]\n",
    "#     if '@' in d['source'] or '@' in d['target']:\n",
    "#         import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d['source'], d['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- orig stuff ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1675029559225,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "z2kK0OnM-R8h"
   },
   "outputs": [],
   "source": [
    "new_data_dir = '/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675029559225,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "cJkio5HIBBbs",
    "outputId": "d36f53e3-4eb0-4840-dba5-110d6b903c77"
   },
   "outputs": [],
   "source": [
    "output_folder = '/home/mcosi153/post_ocr_correction/data/en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7892"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_files = sorted(os.listdir(new_data_dir))\n",
    "len(new_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675029559226,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "4RVQ3jz9AG4J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 38890,
     "status": "ok",
     "timestamp": 1675029598110,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "EXsXQWE6AMiZ"
   },
   "outputs": [],
   "source": [
    "new_data_files = glob(new_data_dir+\"*.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1675029598110,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "GBVQ0lacAkP3",
    "outputId": "a3ebe4e1-b0bd-41e5-ed08-794e8e01b91f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/1005_1005.2297d_14607_psfilefixedRTM_hocr.pickle',\n",
       " '/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/9811_astro-ph9811382d_buzzoni_psfilefixedRTM_hocr.pickle',\n",
       " '/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/0908_0908.4092d_Jenkins09b_psfilefixedRTM_hocr.pickle']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675029598111,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "YxzYDKTBBk8h",
    "outputId": "5436a35f-7ccc-4847-e4e5-6e8bbf293dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675029598111,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "X7RPGyb9Brxp"
   },
   "outputs": [],
   "source": [
    "file0 = 1\n",
    "file_name = new_data_files[file0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml in ./.local/lib/python3.8/site-packages (4.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1675029599327,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "HwkWXBp-B-0Z"
   },
   "outputs": [],
   "source": [
    "# with open(file_name,'rb') as f:\n",
    "#     ffout,pdf_text_pages,ocr_text_pages,alignment_pages,pdf_sents_aligned_pages,ocr_sents_aligned_pages,pdf_sents_pages,ocr_sents_pages = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name,'rb') as f:\n",
    "    realign_pages = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1675029599327,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "PJHuDenlcDuK",
    "outputId": "27713c2a-e3b5-4d27-e265-35a7161cf958"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(realign_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1675029599328,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "FoRD0D5lda5X",
    "outputId": "626081a7-7f9e-4083-89c3-463b1bc01af8"
   },
   "outputs": [],
   "source": [
    "#len(pdf_sents_aligned_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1675029599331,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "e8usMbvWq7Wz",
    "outputId": "4039d610-cd1a-4a97-e1e2-b645dab9d555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '0001_astro-ph0001013d_letter_psfilefixedRTM_hocr - Copy.pickle',\n",
       " '0001_astro-ph0001013d_letter_psfilefixedRTM_hocr.pickle']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files = sorted(os.listdir(folder))\n",
    "#len(files)\n",
    "files = sorted(os.listdir(new_data_dir))\n",
    "len(files)\n",
    "files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1675029599519,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "r8VLa58yq7W0",
    "outputId": "25886572-7414-4141-cd6e-45bb41d8eff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7891"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(new_data_dir + '/**/*.pickle', recursive=True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1146639,
     "status": "ok",
     "timestamp": 1675030746155,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "snkuAAeVq7W1",
    "outputId": "c9a8913e-4458-4a36-9217-3e67c5cef142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/1005_1005.2297d_14607_psfilefixedRTM_hocr.pickle\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# def extract(name):\n",
    "   # with open(name) as file: #this is used to open and read text files\n",
    "        #return file.readlines()\n",
    "\n",
    "\n",
    "def create_windows(x):\n",
    "    A, B, window_length = x\n",
    "    assert len(A) == len(B)\n",
    "    return [(A[i:i + window_length], B[i:i + window_length]) \n",
    "            for i in range(len(A) + 1)]\n",
    "    \n",
    "p = Pool(4)\n",
    "    \n",
    "# #data = list(p.imap_unordered(extract, tqdm(files), chunksize = 128,))\n",
    "# #len(data)\n",
    "# #data = extract('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle')\n",
    "\n",
    "source_dataframe = pd.DataFrame({\"ocr_aligned\":[],\"gs_aligned\":[]})\n",
    "\n",
    "#for file_name in files:\n",
    "#for file_index in range(len(files)):# can change length of files ex: files/10 or 1000 to find out if there is less time\n",
    "import random\n",
    "#r = list(range(4773))\n",
    "r = list(range(40))\n",
    "random.shuffle(r)\n",
    "pdf_ocr = []\n",
    "for file_index in r: \n",
    "    file_name = files[file_index]\n",
    "    if file_index % 200 == 0:\n",
    "        print(str(file_index) + \" \" + file_name)\n",
    "    for key in realign_pages:\n",
    "        if 'PDF' in realign_pages[key] and 'OCR' in realign_pages[key]:\n",
    "            pdf_ocr.append({'ocr_aligned': realign_pages[key]['OCR'],'gs_aligned': realign_pages[key]['PDF']})\n",
    "\n",
    "    source_dataframe = pd.DataFrame(pdf_ocr)\n",
    "    #fh = open(str(file_name), 'rb')\n",
    "    #ffout,pdf_text_pages, ocr_text_pages, alignment_pages, pdf_sents_aligned_pages, ocr_sents_aligned_pages, pdf_sents_pages, ocr_sents_pages = pickle.load(fh)\n",
    "    ##print(len(pdf_sents_aligned_pages.keys()))\n",
    "    ##import sys; sys.exit()\n",
    "    #for key in pdf_sents_aligned_pages.keys():\n",
    "      ##for ocr_sents, pdf_sents in zip(ocr_sents_aligned_pages[key], pdf_sents_aligned_pages[key]):\n",
    "        #if ocr_sents_aligned_pages[key] != \"\" and pdf_sents_aligned_pages[key] != \"\":\n",
    "        ##print(\"not empty\")\n",
    "        ##print(key)\n",
    "            #new_dataframe = pd.DataFrame({\"ocr_aligned\":ocr_sents_aligned_pages[key], \"gs_aligned\":pdf_sents_aligned_pages[key]})\n",
    "            #source_dataframe = pd.concat([source_dataframe, new_dataframe], ignore_index = True, sort = False)\n",
    "#         else:\n",
    "#             #print(\"empty string\")\n",
    "#             print(key)\n",
    "\n",
    "# #use source_dataframe add code here to remove str from list\n",
    "# #empty_list = []\n",
    "#print(source_dataframe.shape)\n",
    "\n",
    "# # for index in range(len(source_dataframe.ocr_aligned)-1):\n",
    "# #   if type(source_dataframe.ocr_aligned[index]) != list:\n",
    "# #     source_dataframe.ocr_aligned.pop(index)\n",
    "# #     source_dataframe.gs_aligned.pop(index)\n",
    "\n",
    "# #print(source_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1675030746155,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "3qXs2vD9AJb_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ocr_aligned  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1   basic step when asseniblung a vunthetec stel...   \n",
       "2  As a general feature. SSP post-MS evolution is...   \n",
       "3  MPollax population svuthesis has extensively b...   \n",
       "4   basic step when asseniblung a vunthetec stel...   \n",
       "\n",
       "                                          gs_aligned  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  A basic step when assem@bling a synthetic stel...  \n",
       "2  As a general feature, SSP post-MS evolution is...  \n",
       "3  Stellar population synthesis has extensively b...  \n",
       "4  A basic step when assem@bling a synthetic stel...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1675030746395,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "NfsLhS5z5kjc",
    "outputId": "ea6f19dd-8145-465d-f863-bc15b8684f4d"
   },
   "outputs": [],
   "source": [
    "# for index_number in range(len(source_dataframe.gs_aligned)):\n",
    "#     if index_number % 5000 == 0:\n",
    "#       #print(source_dataframe.ocr_aligned[index_number])\n",
    "#       #print(source_dataframe.gs_aligned[index_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_dataframe.to_csv(\"full_source_dataframe_to_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1675030746396,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "GwiynkJtI9Bt"
   },
   "outputs": [],
   "source": [
    "# the rest of the code is using \"data\" for dataframe\n",
    "data = source_dataframe \n",
    "#data = pd.read_csv(\"full_train_data_672699.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1675030746396,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "Cyk27SJN9a5E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1675030746397,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "SQGTCyu8FLkL",
    "outputId": "24f6cc78-c74c-4bc6-9a7a-993482c9ec29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 2)\n"
     ]
    }
   ],
   "source": [
    "#check how many rows in data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675030746397,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "0FEvNdiGy9fw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ocr_aligned  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1   basic step when asseniblung a vunthetec stel...   \n",
       "2  As a general feature. SSP post-MS evolution is...   \n",
       "3  MPollax population svuthesis has extensively b...   \n",
       "4   basic step when asseniblung a vunthetec stel...   \n",
       "\n",
       "                                          gs_aligned  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  A basic step when assem@bling a synthetic stel...  \n",
       "2  As a general feature, SSP post-MS evolution is...  \n",
       "3  Stellar population synthesis has extensively b...  \n",
       "4  A basic step when assem@bling a synthetic stel...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675030746397,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "4EWkOngLg_tb"
   },
   "outputs": [],
   "source": [
    "#this is what i added to make a list with one pickle file\n",
    "#lst = pd.read_pickle('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle')\n",
    "#with open('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle','rb') as f:\n",
    "# ffout,pdf_text_pages,ocr_text_pages,alignment_pages,pdf_sents_aligned_pages,ocr_sents_aligned_pages,pdf_sents_pages,ocr_sents_pages = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675030746808,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "dcF5ZLDYngU7"
   },
   "outputs": [],
   "source": [
    "#df1 = pd.read_pickle('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1675030746808,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "ecZb13rZCgWG"
   },
   "outputs": [],
   "source": [
    "#print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675030746809,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "D25RmGn9q7W1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# data = pd.DataFrame(data, \n",
    "#                     columns = [\"ocr_to_input\", \n",
    "#                                \"ocr_aligned\", \n",
    "#                                \"gs_aligned\"])\\\n",
    "# .assign(ocr_to_input = lambda df: df.ocr_to_input.str.replace(\"[OCR_toInput] \", \"\", regex = False),\n",
    "#         ocr_aligned = lambda df: df.ocr_aligned.str.replace(\"[OCR_aligned] \", \"\", regex = False),\n",
    "#         gs_aligned = lambda df: df.gs_aligned.str.replace(\"[ GS_aligned] \", \"\", regex = False))\n",
    "\n",
    "# print(data.shape)\n",
    "# data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675030746809,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "lWgbmIskq7W2"
   },
   "outputs": [],
   "source": [
    "#data.to_csv(\"./github_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1675030747320,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "0H4on41Gq7W3",
    "outputId": "6e66fe05-b87d-4608-9926-8032aec81fdc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.333333</td>\n",
       "      <td>77.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.946762</td>\n",
       "      <td>0.946762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_aligned  gs_aligned\n",
       "count   120.000000  120.000000\n",
       "mean     77.333333   77.333333\n",
       "std       0.946762    0.946762\n",
       "min      76.000000   76.000000\n",
       "25%      76.000000   76.000000\n",
       "50%      78.000000   78.000000\n",
       "75%      78.000000   78.000000\n",
       "max      78.000000   78.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7763,
     "status": "ok",
     "timestamp": 1675030755080,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "ggB3xzJuq7W3",
    "outputId": "93373911-3756-4b02-a7ec-7f695d6fad20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Levenshtein in ./.local/lib/python3.8/site-packages (0.20.9)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in ./.local/lib/python3.8/site-packages (from Levenshtein) (2.13.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Levenshtein\n",
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "       \n",
    "def levenshtein(reference, hypothesis, progress_bar = False):\n",
    "    assert len(reference) == len(hypothesis)\n",
    "    text = zip(reference, hypothesis)\n",
    "    if progress_bar:\n",
    "        text = tqdm(text, total = len(reference))\n",
    "    d = [distance(r, h) for r, h in text]\n",
    "    output = pd.DataFrame({\"reference\":reference, \"hypothesis\":hypothesis})\\\n",
    "    .assign(distance = lambda df: d)\\\n",
    "    .assign(\n",
    "        cer = lambda df: df.apply(\n",
    "            lambda r: 100 * r[\"distance\"] / max(len(r[\"reference\"]), 1), \n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1675030755080,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "VCTJUASoSvGw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1675030755081,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "VGaMv03Kq7W4"
   },
   "outputs": [],
   "source": [
    "# levenshtein(reference = data.gs_aligned.str.replace(\"@\", \"\"), \n",
    "#             hypothesis = data.ocr_to_input).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15293,
     "status": "ok",
     "timestamp": 1675030770365,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "gwxxtpWyq7W4",
    "outputId": "117a740d-c050-4678-a9be-9b2b5f12d872"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120.000000\n",
       "mean       6.848853\n",
       "std        4.233466\n",
       "min        1.315789\n",
       "25%        1.315789\n",
       "50%        7.692308\n",
       "75%       11.538462\n",
       "max       11.538462\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = data.gs_aligned, \n",
    "            hypothesis = data.ocr_aligned).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Vocabulary(data.ocr_aligned.sum() + data.gs_aligned.sum())\n",
    "print(len(vocabulary))\n",
    "with open(output_folder+\"/\"+\"data/vocabulary_new_pages1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770365,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "E4kWzO7Elhqc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "Kum9uJQCo3pk"
   },
   "outputs": [],
   "source": [
    "# data.gs_aligned[51173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "-0qvqkwPU5cp"
   },
   "outputs": [],
   "source": [
    "#output_folder = Path(\"../../data/en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "F5VozHE-rWve"
   },
   "outputs": [],
   "source": [
    "# data.ocr_aligned.pop(51173)\n",
    "# data.gs_aligned.pop(51173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "i4L_FktbrrBO"
   },
   "outputs": [],
   "source": [
    "# type(data.ocr_aligned[51172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770367,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "lE1Vv2SasRT5"
   },
   "outputs": [],
   "source": [
    "# vocab1 = []\n",
    "# vocab2 = []\n",
    "\n",
    "# for index in range(len(data.ocr_aligned)-1):\n",
    "#   if type(data.ocr_aligned[index]) != type(vocab1):\n",
    "#     print(data.ocr_aligned[index])\n",
    "\n",
    "#   else:\n",
    "#       vocab1 = vocab1 + data.ocr_aligned[index]\n",
    "#     #source_dataframe.ocr_aligned.pop()\n",
    "#     #source_dataframe.gs_aligned.pop()\n",
    "\n",
    "# for index in range(len(data.gs_aligned)-1):\n",
    "#   if type(data.gs_aligned[index]) != type(vocab2):\n",
    "#     print(data.gs_aligned[index])\n",
    "#   else:\n",
    "#       vocab2 = vocab2 + data.gs_aligned[index]\n",
    "#     #source_dataframe.ocr_aligned.pop()\n",
    "\n",
    "# vocab = vocab1 + vocab2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770367,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "KLyyhirmuoRI"
   },
   "outputs": [],
   "source": [
    "# data.gs_aligned.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdHduFRX5LQh"
   },
   "outputs": [],
   "source": [
    "# for d in data.ocr_aligned.values:\n",
    "#   if type(d) != list:\n",
    "#     print(d, \"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a9PCUN2c5uDp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@e confront the two models from Table @n this wavelength interval with each other. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gs_aligned.values [- 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:38\n"
     ]
    }
   ],
   "source": [
    "ocr = data.ocr_aligned.sum()\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:39\n"
     ]
    }
   ],
   "source": [
    "gs = data.gs_aligned.sum()\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "j5TYBK7Vq7W5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:40\n"
     ]
    }
   ],
   "source": [
    "#vocabulary = Vocabulary(data.ocr_aligned.sum() + data.gs_aligned.sum())\n",
    "vocab = ocr + gs\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:41\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Vocabulary(ocr + gs)\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Current Time = 15:55:42\n"
     ]
    }
   ],
   "source": [
    "# vocabulary = Vocabulary(vocab)\n",
    "print(len(vocabulary))\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:46\n"
     ]
    }
   ],
   "source": [
    "with open(output_folder+\"/data/vocabulary_new_pages.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-bv4AXVHq7W5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = data.sample(n = 5, random_state = 1)\n",
    "dev.to_pickle(output_folder+\"/data/dev_new_pages.pkl\")\n",
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Micp4fEsq7W6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.drop(dev.index)\n",
    "train.to_pickle(output_folder+\"/data/train_new_pages.pkl\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "r4DPEHInq7W6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.356522</td>\n",
       "      <td>77.356522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.938376</td>\n",
       "      <td>0.938376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_aligned  gs_aligned\n",
       "count   115.000000  115.000000\n",
       "mean     77.356522   77.356522\n",
       "std       0.938376    0.938376\n",
       "min      76.000000   76.000000\n",
       "25%      76.000000   76.000000\n",
       "50%      78.000000   78.000000\n",
       "75%      78.000000   78.000000\n",
       "max      78.000000   78.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lQZdmXf9q7W7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>76.800000</td>\n",
       "      <td>76.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.095445</td>\n",
       "      <td>1.095445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_aligned  gs_aligned\n",
       "count     5.000000    5.000000\n",
       "mean     76.800000   76.800000\n",
       "std       1.095445    1.095445\n",
       "min      76.000000   76.000000\n",
       "25%      76.000000   76.000000\n",
       "50%      76.000000   76.000000\n",
       "75%      78.000000   78.000000\n",
       "max      78.000000   78.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OPyPNC5Mq7W7"
   },
   "outputs": [],
   "source": [
    "# levenshtein(reference = dev.gs_aligned.str.replace(\"@\", \"\"), \n",
    "#              hypothesis = dev.ocr_to_input).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hY6U7SZbq7W7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     3.866397\n",
       "std      3.492563\n",
       "min      1.315789\n",
       "25%      1.315789\n",
       "50%      1.315789\n",
       "75%      7.692308\n",
       "max      7.692308\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = dev.gs_aligned, \n",
    "            hypothesis = dev.ocr_aligned).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qNJp4_L4q7W8"
   },
   "outputs": [],
   "source": [
    "window_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# def extract(name):\n",
    "   # with open(name) as file: #this is used to open and read text files\n",
    "        #return file.readlines()\n",
    "\n",
    "\n",
    "def create_windows(x):\n",
    "    A, B, window_length = x\n",
    "    assert len(A) == len(B)\n",
    "    return [(A[i:i + window_length], B[i:i + window_length]) \n",
    "            for i in range(len(A) + 1)]\n",
    "p = Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rPD8VGSlq7W8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5962392d142487e93770e10285aa49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd69436e50ec41dd81780bfce0fea979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pollax population svuthesis has extensively be...</td>\n",
       "      <td>tellar population synthesis has extensively be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollax population svuthesis has extensively bee...</td>\n",
       "      <td>ellar population synthesis has extensively bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llax population svuthesis has extensively been...</td>\n",
       "      <td>llar population synthesis has extensively been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lax population svuthesis has extensively been ...</td>\n",
       "      <td>lar population synthesis has extensively been ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1  Pollax population svuthesis has extensively be...   \n",
       "2  ollax population svuthesis has extensively bee...   \n",
       "3  llax population svuthesis has extensively been...   \n",
       "4  lax population svuthesis has extensively been ...   \n",
       "\n",
       "                                              target  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  tellar population synthesis has extensively be...  \n",
       "2  ellar population synthesis has extensively bee...  \n",
       "3  llar population synthesis has extensively been...  \n",
       "4  lar population synthesis has extensively been ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train#.head(100)\n",
    "train_aligned = list(p.imap_unordered(create_windows, \n",
    "                                      tqdm(zip(df.ocr_aligned, \n",
    "                                               df.gs_aligned, \n",
    "                                               [window_length for x in df.ocr_aligned]), \n",
    "                                           total = len(df.ocr_aligned)),\n",
    "                                      chunksize = 128))\n",
    "s = []\n",
    "for r in tqdm(train_aligned):\n",
    "    s.extend(r)\n",
    "train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "print(train_aligned.shape)\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NdtLZU8kq7W8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pollax population svuthesis has extensively be...</td>\n",
       "      <td>tellar population synthesis has extensively be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollax population svuthesis has extensively bee...</td>\n",
       "      <td>ellar population synthesis has extensively bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llax population svuthesis has extensively been...</td>\n",
       "      <td>llar population synthesis has extensively been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lax population svuthesis has extensively been ...</td>\n",
       "      <td>lar population synthesis has extensively been ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1  Pollax population svuthesis has extensively be...   \n",
       "2  ollax population svuthesis has extensively bee...   \n",
       "3  llax population svuthesis has extensively been...   \n",
       "4  lax population svuthesis has extensively been ...   \n",
       "\n",
       "                                              target  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  tellar population synthesis has extensively be...  \n",
       "2  ellar population synthesis has extensively bee...  \n",
       "3  llar population synthesis has extensively been...  \n",
       "4  lar population synthesis has extensively been ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aligned = train_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vzwv9ldEq7W8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s a general feature. SSP post-MS evolution is ...</td>\n",
       "      <td>s a general feature, SSP post-MS evolution is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a general feature. SSP post-MS evolution is r...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a general feature. SSP post-MS evolution is re...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general feature. SSP post-MS evolution is rec...</td>\n",
       "      <td>general feature, SSP post-MS evolution is rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  As a general feature. SSP post-MS evolution is...   \n",
       "1  s a general feature. SSP post-MS evolution is ...   \n",
       "2   a general feature. SSP post-MS evolution is r...   \n",
       "3  a general feature. SSP post-MS evolution is re...   \n",
       "4   general feature. SSP post-MS evolution is rec...   \n",
       "\n",
       "                                              target  \n",
       "0  As a general feature, SSP post-MS evolution is...  \n",
       "1  s a general feature, SSP post-MS evolution is ...  \n",
       "2   a general feature, SSP post-MS evolution is r...  \n",
       "3  a general feature, SSP post-MS evolution is re...  \n",
       "4   general feature, SSP post-MS evolution is rec...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev.apply(lambda r: create_windows((r[\"ocr_aligned\"], r[\"gs_aligned\"], window_length)), \n",
    "                            axis = 1).sum()\n",
    "dev_aligned = pd.DataFrame(dev_aligned, columns = [\"source\", \"target\"])\n",
    "print(dev_aligned.shape)\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_sample_df=train_aligned.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_sample_df.to_csv(\"trained_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "55tYY6PRq7W9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s a general feature. SSP post-MS evolution is ...</td>\n",
       "      <td>s a general feature, SSP post-MS evolution is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a general feature. SSP post-MS evolution is r...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a general feature. SSP post-MS evolution is re...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general feature. SSP post-MS evolution is rec...</td>\n",
       "      <td>general feature, SSP post-MS evolution is rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  As a general feature. SSP post-MS evolution is...   \n",
       "1  s a general feature. SSP post-MS evolution is ...   \n",
       "2   a general feature. SSP post-MS evolution is r...   \n",
       "3  a general feature. SSP post-MS evolution is re...   \n",
       "4   general feature. SSP post-MS evolution is rec...   \n",
       "\n",
       "                                              target  \n",
       "0  As a general feature, SSP post-MS evolution is...  \n",
       "1  s a general feature, SSP post-MS evolution is ...  \n",
       "2   a general feature, SSP post-MS evolution is r...  \n",
       "3  a general feature, SSP post-MS evolution is re...  \n",
       "4   general feature, SSP post-MS evolution is rec...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"/data/train_aligned_new_pages.pkl\")\n",
    "dev_aligned.to_pickle(output_folder+\"/data/dev_aligned_new_pages.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91919976"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 dataframes have been created so far\n",
      "20 dataframes have been created so far\n",
      "30 dataframes have been created so far\n",
      "40 dataframes have been created so far\n",
      "50 dataframes have been created so far\n",
      "60 dataframes have been created so far\n",
      "70 dataframes have been created so far\n",
      "80 dataframes have been created so far\n",
      "90 dataframes have been created so far\n"
     ]
    }
   ],
   "source": [
    "train_aligned_chunks = np.array_split(df, 92)\n",
    "for i, df in enumerate(train_aligned_chunks):\n",
    "    if i % 10 == 0 and i != 0:\n",
    "        print(f\"{i} dataframes have been created so far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(92):\n",
    "    train_aligned_chunks[i].to_pickle(output_folder+\"/data/train_aligned_new_full\"+str(i).zfill(4)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = dev_aligned\n",
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.to_pickle(output_folder+\"/data/dev_aligned_new_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nLXGOTHq7W9"
   },
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"/data/train_aligned_new_full.pkl\")\n",
    "dev_aligned.to_pickle(output_folder+\"/data/dev_aligned_new_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(output_folder+\"/data/train_aligned_new_full.pkl\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>85</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>69</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>95</td>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B   C   D\n",
       "0   29  94  33  50\n",
       "1   14  54  75  51\n",
       "2   35  36  61  66\n",
       "3   25   9  72  41\n",
       "4   26  66   9  22\n",
       "..  ..  ..  ..  ..\n",
       "95  41  27  88  65\n",
       "96   6  53  39  52\n",
       "97  85  39  59  92\n",
       "98  69  51   1  87\n",
       "99  95  97  90  25\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks = np.array_split(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0  29  94  33  50\n",
       "1  14  54  75  51\n",
       "2  35  36  61  66\n",
       "3  25   9  72  41\n",
       "4  26  66   9  22\n",
       "5  90  64  78  94\n",
       "6  77  95  99  98\n",
       "7  34  32  88  43\n",
       "8   2  80  38  18\n",
       "9  68  94  10   9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1946020/866910306.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/data/train_aligned_new_full\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    df_chunks[i].to_pickle(output_folder+\"/data/train_aligned_new_full\"+str(i).zfill(3)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
