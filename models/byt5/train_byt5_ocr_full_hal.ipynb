{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya2rjz5flA0f"
   },
   "source": [
    "This runs our model with byt5-ocr specific corrections: https://huggingface.co/yelpfeast/byt5-base-english-ocr-correction \n",
    "\n",
    "Make sure you are in the PyTorchOCR environment on HAL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCqaqXXMmqF_"
   },
   "outputs": [],
   "source": [
    "main_dir = '/home/jnaiman/'\n",
    "output_dir = main_dir + 'models/byt5_inline_cite_ref_ocr/' # math/cite/refs -- just left in as raw\n",
    "aligned_dataset_dir = '/home/jnaiman/wwt_image_extraction/alignments/'\n",
    "\n",
    "# which model do we want to start from pre-trained?\n",
    "#model_pretrained = 'google/byt5-small' # orig\n",
    "model_pretrained = 'yelpfeast/byt5-base-english-ocr-correction' # for OCR correction specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oxxtYvsbncTB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(aligned_dataset_dir+'train_masked_n500000_20230503.csv')\n",
    "eval_df = pd.read_csv(aligned_dataset_dir+'val_masked_n10000_20230503.csv')\n",
    "test_df = pd.read_csv(aligned_dataset_dir+'test_masked_n10000_20230503.csv')\n",
    "\n",
    "only_words = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wotefPaCoxuA",
    "outputId": "92286aae-79e6-4a20-a4f6-60bcca924a83"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers==4.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2bfOyWk8lkUr"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir14BJRimVE8"
   },
   "source": [
    "Order here is important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6THPU5s7l5Ey"
   },
   "outputs": [],
   "source": [
    "# !pip install pybind11 \n",
    "# !pip install fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g154RiKGlb_h"
   },
   "outputs": [],
   "source": [
    "from transformers import HfArgumentParser, TensorFlowBenchmark, TensorFlowBenchmarkArguments\n",
    "#import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WX29dDbfls7l"
   },
   "outputs": [],
   "source": [
    "#import fastwer\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3Giern-Vlfsr"
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(main_dir + 'libraries/')\n",
    "from utils_ocr_mini import get_fill_in_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJUsyo_UlZko",
    "outputId": "b52e62fd-3c1c-4bdb-a1b7-f6dc04f2833c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "cuda.empty_cache()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nOeops60nnoU"
   },
   "outputs": [],
   "source": [
    "def add_formatted_columns(datain):\n",
    "    source = []\n",
    "    target = []\n",
    "    source_aligned = []\n",
    "    target_aligned = []\n",
    "    for i in range(len(datain)):\n",
    "        d = datain.iloc[i]\n",
    "        s = np.array(list(d['aligned sentences source'])) # aligned source, with ^ symbols\n",
    "        t = np.array(list(d['aligned sentences target'])) # aligned target, with @ symbols\n",
    "        a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))\n",
    "        if len(s) == len(t):\n",
    "            ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "            tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "        else:\n",
    "            print('have issue, testing')\n",
    "            if t[0] == ' ' and s[0] != ' ':\n",
    "                t = np.array(list(d['aligned sentences target']))[1:] # aligned target, with @ symbols\n",
    "                a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))[1:]\n",
    "                if len(s) == len(t):\n",
    "                    ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "                    tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "                else:\n",
    "                    print('not aligned, best guess')\n",
    "                    import sys; sys.exit()\n",
    "\n",
    "        source_aligned.append(ss.replace('^','@')) # align with original \n",
    "        target_aligned.append(tt)\n",
    "        source.append(ss.replace('^',''))\n",
    "        target.append(tt.replace('@',''))\n",
    "\n",
    "    datain['words source aligned'] = source_aligned\n",
    "    datain['words target aligned'] = target_aligned\n",
    "    datain['words source'] = source\n",
    "    datain['words target'] = target\n",
    "    return datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "QItVt00_lZiZ",
    "outputId": "f807c704-9aaf-452a-a148-04f08de34893"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aligned sentences source</th>\n",
       "      <th>aligned sentences target</th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>aligned sentences source types</th>\n",
       "      <th>aligned sentences target types</th>\n",
       "      <th>sentences source types</th>\n",
       "      <th>sentences target types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To a good approxiuiati^^^ the radial velocity...</td>\n",
       "      <td>To a good approxim@ation, the radial velocity...</td>\n",
       "      <td>To a good approxiuiati the radial velocity of...</td>\n",
       "      <td>To a good approximation, the radial velocity ...</td>\n",
       "      <td>WW W WWWW WWWWWWWWWWWW^^^ WWW WWWWWW WWWWWWWW...</td>\n",
       "      <td>WW W WWWW WWWWWWWW@WWWWWW WWW WWWWWW WWWWWWWW...</td>\n",
       "      <td>WW W WWWW WWWWWWWWWWWW WWW WWWWWW WWWWWWWW WW...</td>\n",
       "      <td>WW W WWWW WWWWWWWWWWWWWW WWW WWWWWW WWWWWWWW ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where all the units must be in ces and the ^L^...</td>\n",
       "      <td>Where all the units must be in cgs and the $L_...</td>\n",
       "      <td>Where all the units must be in ces and the Leu...</td>\n",
       "      <td>Where all the units must be in cgs and the $L_...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW ^I^...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>^At sulliciently high temperatures the ^^^^^^^...</td>\n",
       "      <td>At sufficiently high temperatures the $^4\\mat...</td>\n",
       "      <td>At sulliciently high temperatures the !1 and =...</td>\n",
       "      <td>At sufficiently high temperatures the $^4\\mat...</td>\n",
       "      <td>^WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW ^^^^^^^...</td>\n",
       "      <td>WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...</td>\n",
       "      <td>WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW II WWW I...</td>\n",
       "      <td>WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The resulting spectral resolution was ^^^^^^8...</td>\n",
       "      <td>The resulting spectral resolution was $\\sim 8...</td>\n",
       "      <td>The resulting spectral resolution was 8 kIlz ...</td>\n",
       "      <td>The resulting spectral resolution was $\\sim 8...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW ^^^^^II...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW II WWWW...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One approach is ^o search for a CAV signal fo...</td>\n",
       "      <td>One approach is to search for a GW@ signal fo...</td>\n",
       "      <td>One approach is o search for a CAV signal fol...</td>\n",
       "      <td>One approach is to search for a GW signal fol...</td>\n",
       "      <td>WWW WWWWWWWW WW ^W WWWWWW WWW W WWW WWWWWW WW...</td>\n",
       "      <td>WWW WWWWWWWW WW WW WWWWWW WWW W WW@ WWWWWW WW...</td>\n",
       "      <td>WWW WWWWWWWW WW W WWWWWW WWW W WWW WWWWWW WWW...</td>\n",
       "      <td>WWW WWWWWWWW WW WW WWWWWW WWW W WW WWWWWW WWW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            aligned sentences source  \\\n",
       "0   To a good approxiuiati^^^ the radial velocity...   \n",
       "1  Where all the units must be in ces and the ^L^...   \n",
       "2  ^At sulliciently high temperatures the ^^^^^^^...   \n",
       "3   The resulting spectral resolution was ^^^^^^8...   \n",
       "4   One approach is ^o search for a CAV signal fo...   \n",
       "\n",
       "                            aligned sentences target  \\\n",
       "0   To a good approxim@ation, the radial velocity...   \n",
       "1  Where all the units must be in cgs and the $L_...   \n",
       "2   At sufficiently high temperatures the $^4\\mat...   \n",
       "3   The resulting spectral resolution was $\\sim 8...   \n",
       "4   One approach is to search for a GW@ signal fo...   \n",
       "\n",
       "                                    sentences source  \\\n",
       "0   To a good approxiuiati the radial velocity of...   \n",
       "1  Where all the units must be in ces and the Leu...   \n",
       "2  At sulliciently high temperatures the !1 and =...   \n",
       "3   The resulting spectral resolution was 8 kIlz ...   \n",
       "4   One approach is o search for a CAV signal fol...   \n",
       "\n",
       "                                    sentences target  \\\n",
       "0   To a good approximation, the radial velocity ...   \n",
       "1  Where all the units must be in cgs and the $L_...   \n",
       "2   At sufficiently high temperatures the $^4\\mat...   \n",
       "3   The resulting spectral resolution was $\\sim 8...   \n",
       "4   One approach is to search for a GW signal fol...   \n",
       "\n",
       "                      aligned sentences source types  \\\n",
       "0   WW W WWWW WWWWWWWWWWWW^^^ WWW WWWWWW WWWWWWWW...   \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW ^I^...   \n",
       "2  ^WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW ^^^^^^^...   \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW ^^^^^II...   \n",
       "4   WWW WWWWWWWW WW ^W WWWWWW WWW W WWW WWWWWW WW...   \n",
       "\n",
       "                      aligned sentences target types  \\\n",
       "0   WW W WWWW WWWWWWWW@WWWWWW WWW WWWWWW WWWWWWWW...   \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...   \n",
       "2   WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...   \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...   \n",
       "4   WWW WWWWWWWW WW WW WWWWWW WWW W WW@ WWWWWW WW...   \n",
       "\n",
       "                              sentences source types  \\\n",
       "0   WW W WWWW WWWWWWWWWWWW WWW WWWWWW WWWWWWWW WW...   \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...   \n",
       "2  WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW II WWW I...   \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW II WWWW...   \n",
       "4   WWW WWWWWWWW WW W WWWWWW WWW W WWW WWWWWW WWW...   \n",
       "\n",
       "                              sentences target types  \n",
       "0   WW W WWWW WWWWWWWWWWWWWW WWW WWWWWW WWWWWWWW ...  \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...  \n",
       "2   WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...  \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...  \n",
       "4   WWW WWWWWWWW WW WW WWWWWW WWW W WW WWWWWW WWW...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oQA5YZDdlZgM"
   },
   "outputs": [],
   "source": [
    "if only_words:\n",
    "    train_df = add_formatted_columns(train_df)\n",
    "    eval_df = add_formatted_columns(eval_df)\n",
    "    test_df = add_formatted_columns(test_df)\n",
    "    # rename sentences we want\n",
    "    train_df = train_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "    eval_df = eval_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "    test_df = test_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "else:\n",
    "    # rename sentences we want\n",
    "    train_df = train_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})\n",
    "    eval_df = eval_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})\n",
    "    test_df = test_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Jd1PXsovlZd2"
   },
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    #\"model_name_or_path\": 'google/byt5-small',\n",
    "    #\"max_len\": 4096,\n",
    "    #\"max_length\": 4096,\n",
    "    \"output_dir\": output_dir,\n",
    "    \"logging_dir\":output_dir + '/logs/',\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"warmup_steps\": 250,\n",
    "    \"logging_steps\": 100,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 1000,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"fp16\": False,\n",
    "    #\"use_cache\": False,\n",
    "    \"max_steps\": 100000,\n",
    "    'save_steps':1000,\n",
    "    'save_strategy':'steps',\n",
    "    'load_best_model_at_end': True#,\n",
    "    # 'metric_for_best_model':'eval_loss',\n",
    "    # 'greater_is_better':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FxQxNcMjoi8O"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MWfk71QslZby"
   },
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "        (TrainingArguments))\n",
    "training_args = parser.parse_dict(args_dict)\n",
    "# set_seed(training_args.seed)\n",
    "args = training_args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-UWnONbvlZZt"
   },
   "outputs": [],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_pretrained,\n",
    "    cache_dir=output_dir, \n",
    "    max_length=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Vbky6fbWlZXe"
   },
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_pretrained,\n",
    "    cache_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lVetcdNVlZVI"
   },
   "outputs": [],
   "source": [
    "# overwriting the default max_length of 20 \n",
    "tokenizer.model_max_length=4096\n",
    "model.config.max_length=4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lVv94v7BlZS6"
   },
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "    def __init__(self, Text, Label):\n",
    "        self.Text = Text\n",
    "        self.Label = Label\n",
    "        # self.tokenizer = tokenizer\n",
    "        # self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.Text)\n",
    "    def __getitem__(self, item):\n",
    "        Text = str(self.Text[item])\n",
    "        Label = self.Label[item]\n",
    "        inputs = tokenizer(Text, padding=\"max_length\", truncation=True, max_length=512)\n",
    "        outputs = tokenizer(Label, padding=\"max_length\", truncation=True, max_length=512)\n",
    "        return {\n",
    "          \"input_ids\":inputs.input_ids,\n",
    "          \"attention_mask\" : inputs.attention_mask,\n",
    "          \"labels\" : outputs.input_ids,\n",
    "          \"decoder_attention_mask\" : outputs.attention_mask,\n",
    "          # \"labels\" : lbz\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "mix1mmuWlZQs"
   },
   "outputs": [],
   "source": [
    "ds_train = GPReviewDataset(\n",
    "  Text=train_df.input_text.to_numpy(),\n",
    "  Label=train_df.target_text.to_numpy()\n",
    "  # tokenizer=tokenizer,\n",
    "  # max_len=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XxekcQahlZOn"
   },
   "outputs": [],
   "source": [
    "ds_test = GPReviewDataset(\n",
    "  Text=eval_df.input_text.to_numpy(),\n",
    "  Label=eval_df.target_text.to_numpy()\n",
    "  # tokenizer=tokenizer,\n",
    "  # max_len=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "XFQ-LlwNlZMd"
   },
   "outputs": [],
   "source": [
    "train_dataset = ds_train\n",
    "valid_dataset = ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vKJTtQS9lZKh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnaiman/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "    # compute_metrics=compute_metrics\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpQpGEMU2hjf",
    "outputId": "8221f736-d6ec-4502-a566-41f775106f69"
   },
   "outputs": [],
   "source": [
    "#!ls gdrive/MyDrive/TPDL\\ 2023\\ Colab\\ Notebooks/byt5_models/byt5_inline_cite_ref_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "B1SmApob2d1_",
    "outputId": "379f8e10-6149-44f5-ddd3-cb8a6c85f52c"
   },
   "outputs": [],
   "source": [
    "#output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kggLRL_42vAL",
    "outputId": "8241612e-e878-485c-cc89-51c6692da677"
   },
   "outputs": [],
   "source": [
    "#f''+output_dir + 'checkpoint-15000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v0mnJg8HlZIc",
    "outputId": "c45bb6b2-6ba5-4fce-89be-46cbf1157bd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-500/).\n",
      "/home/jnaiman/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/trainer.py:1135: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\n",
      "You are resuming training from a checkpoint trained with 4.28.0 of Transformers but your current version is 4.16.2. This is not recommended and could yield to errors or unwanted behaviors.\n",
      "/home/jnaiman/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 500000\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 100000\n",
      "  Continuing training from checkpoint, will skip to saved global_step\n",
      "  Continuing training from epoch 0\n",
      "  Continuing training from global step 500\n",
      "  Will skip the first 0 epochs then the first 2000 batches in the first epoch. If this takes a lot of time, you can add the `--ignore_data_skip` flag to your launch command, but you will resume the training on data already seen by your model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92cac2a84a534d838286ea2bee014054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16868' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 16868/100000 10:09:12 < 51:34:29, 0.45 it/s, Epoch 0.54/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.055996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>0.047050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.042852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.040664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.039628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>0.038539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.037461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.036594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>0.035825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.035448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.034836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.034257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.035400</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.033263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.033162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.032832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-1000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-1000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-1500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-1500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-1500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-2000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-2000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-2500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-2500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-2500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-6500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-6500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-6500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-3500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-4500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-5500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-6000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-6500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-12000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-12000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-12000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-7000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-12500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-12500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-12500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-7500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-13000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-13000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-13000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-13500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-13500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-13500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-8500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-14000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-14000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-14000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-14500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-14500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-14500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-9500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-15000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-15000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-15000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-15500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-15500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-15500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-10500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 10000\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-16000\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-16000/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-16000/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11000] due to args.save_total_limit\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-16500\n",
      "Configuration saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-16500/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-16500/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_inline_cite_ref_ocr/checkpoint-11500] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "trainer.args.save_total_limit = 10\n",
    "trainer.args.logging_steps = 100 # down from 100\n",
    "trainer.args.save_steps=500 # down from 10000\n",
    "#trainer.train() # put in checkpoint if need be here to load \n",
    "trainer.train(output_dir + 'checkpoint-500/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwBjpXo-lY-r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeTmNSxK1yWf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PyTorchOCR]",
   "language": "python",
   "name": "conda-env-.conda-PyTorchOCR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
