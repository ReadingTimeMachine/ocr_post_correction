{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya2rjz5flA0f"
   },
   "source": [
    "~~This runs our model with byt5-ocr specific corrections: https://huggingface.co/yelpfeast/byt5-base-english-ocr-correction ~~\n",
    "\n",
    "Using the historical dataset for training.\n",
    "\n",
    "Make sure you are in the PyTorchOCR environment on HAL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kCqaqXXMmqF_"
   },
   "outputs": [],
   "source": [
    "main_dir = '/home/jnaiman/'\n",
    "aligned_dataset_dir = '/home/jnaiman/wwt_image_extraction/alignments/'\n",
    "\n",
    "historical_dataset_dir = '/home/jnaiman/wwt_image_extraction/historical_docs/groundtruth/'\n",
    "types = ['plain', 'author location']\n",
    "only_words = False\n",
    "\n",
    "# which model do we want to start from pre-trained?\n",
    "model_pretrained = 'google/byt5-small' # orig\n",
    "\n",
    "# load model weights from prior checkpoint\n",
    "#check_point_load = '/home/jnaiman/models/byt5_inline_cite_ref_large/checkpoint-87000'\n",
    "#output_dir = main_dir + 'models/byt5_ocr_full_hal_historical_withPreTrain/' # math/cite/refs -- just left in as raw\n",
    "\n",
    "# output_dir = main_dir + 'models/byt5_ocr_full_hal_historical_ocr/' # math/cite/refs -- just left in as raw\n",
    "# model_pretrained = 'yelpfeast/byt5-base-english-ocr-correction' # for OCR correction specifically\n",
    "# check_point_load = None # to start running\n",
    "\n",
    "output_dir = main_dir + 'models/byt5_ocr_full_hal_historical/' # math/cite/refs -- just left in as raw\n",
    "check_point_load = None # to start running\n",
    "\n",
    "\n",
    "remake_splits = False\n",
    "train_frac = 0.8\n",
    "val_frac = 0.1\n",
    "test_frac = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oxxtYvsbncTB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hfiles = glob(historical_dataset_dir + '*.pickle')\n",
    "len(hfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wotefPaCoxuA",
    "outputId": "92286aae-79e6-4a20-a4f6-60bcca924a83"
   },
   "outputs": [],
   "source": [
    "filenames = []; pages = []; sents = []; \n",
    "source = []; target = []\n",
    "types_here = []\n",
    "#target_cleaned = []; source_cleaned = []\n",
    "for hfile in hfiles:\n",
    "    with open(hfile,'rb') as f:\n",
    "        dir_test = pickle.load(f)\n",
    "\n",
    "    filenames.append(dir_test['filename'])\n",
    "    pages.append(dir_test['page'])\n",
    "    sents.append(dir_test['sent'])\n",
    "    source.append(dir_test['source'])\n",
    "    target.append(dir_test['target'])\n",
    "    types_here.append(dir_test['type'])\n",
    "#     # cleaned\n",
    "#     source_cleaned.append(dir_test['source'].replace('^',''))\n",
    "#     target_cleaned.append(dir_test['target'].replace()\n",
    "    \n",
    "\n",
    "df_historical_test_all = pd.DataFrame({'input_text_unclean':source, \n",
    "                                       'target_text_unclean':target,\n",
    "                                   'filename':filenames, 'page':pages,\n",
    "                                   'sent num':sents, 'type':types_here})\n",
    "\n",
    "df_historical_test = df_historical_test_all.loc[df_historical_test_all['type'].isin(types)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2bfOyWk8lkUr"
   },
   "outputs": [],
   "source": [
    "if train_frac + val_frac + test_frac != 1.0:\n",
    "    print('the sets fracs dont add to 1!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make splits of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if remake_splits:\n",
    "    train_df = df_historical_test.sample(frac=train_frac, replace=False)\n",
    "    dftmp = df_historical_test[~df_historical_test.isin(train_df)].dropna()\n",
    "    # split\n",
    "    eval_df = dftmp.sample(frac=val_frac/(test_frac+val_frac), replace=False)\n",
    "    test_df = dftmp[~dftmp.isin(eval_df)].dropna()\n",
    "\n",
    "    # save all of these\n",
    "    train_df.to_csv(aligned_dataset_dir + 'train_historical'+str(time.time())+'.csv',index=False)\n",
    "    eval_df.to_csv(aligned_dataset_dir + 'val_historical'+str(time.time())+'.csv',index=False)\n",
    "    test_df.to_csv(aligned_dataset_dir + 'test_historical'+str(time.time())+'.csv',index=False)\n",
    "else: # use already there\n",
    "    fs = glob(aligned_dataset_dir + 'train_historical*csv')\n",
    "    fs.sort()\n",
    "    fs = fs[-1] # most recent\n",
    "    train_df = pd.read_csv(fs)\n",
    "    fs = glob(aligned_dataset_dir + 'val_historical*csv')\n",
    "    fs.sort()\n",
    "    fs = fs[-1] # most recent\n",
    "    eval_df = pd.read_csv(fs)\n",
    "    fs = glob(aligned_dataset_dir + 'test_historical*csv')\n",
    "    fs.sort()\n",
    "    fs = fs[-1] # most recent\n",
    "    test_df = pd.read_csv(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text_unclean</th>\n",
       "      <th>target_text_unclean</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>sent num</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The photograph in Figure 1 (Plate 1) was obtai...</td>\n",
       "      <td>The photograph in Figure 1 (Plate 1) was obtai...</td>\n",
       "      <td>1981ApJ___249__390M</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  input_text_unclean  \\\n",
       "0  The photograph in Figure 1 (Plate 1) was obtai...   \n",
       "\n",
       "                                 target_text_unclean             filename  \\\n",
       "0  The photograph in Figure 1 (Plate 1) was obtai...  1981ApJ___249__390M   \n",
       "\n",
       "   page  sent num   type  \n",
       "0     1         0  plain  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some re-naming\n",
    "train_df = train_df.rename(columns={\"input_text_unclean\":\"sentences source\", \n",
    "                        \"target_text_unclean\":\"sentences target\"})\n",
    "eval_df = eval_df.rename(columns={\"input_text_unclean\":\"sentences source\", \n",
    "                        \"target_text_unclean\":\"sentences target\"})\n",
    "test_df = test_df.rename(columns={\"input_text_unclean\":\"sentences source\", \n",
    "                        \"target_text_unclean\":\"sentences target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "g154RiKGlb_h"
   },
   "outputs": [],
   "source": [
    "from transformers import HfArgumentParser, TensorFlowBenchmark, TensorFlowBenchmarkArguments\n",
    "#import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WX29dDbfls7l"
   },
   "outputs": [],
   "source": [
    "#import fastwer\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3Giern-Vlfsr"
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(main_dir + 'libraries/')\n",
    "from utils_ocr_mini import get_fill_in_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJUsyo_UlZko",
    "outputId": "b52e62fd-3c1c-4bdb-a1b7-f6dc04f2833c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "cuda.empty_cache()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nOeops60nnoU"
   },
   "outputs": [],
   "source": [
    "def add_formatted_columns(datain):\n",
    "    source = []\n",
    "    target = []\n",
    "    source_aligned = []\n",
    "    target_aligned = []\n",
    "    for i in range(len(datain)):\n",
    "        d = datain.iloc[i]\n",
    "        s = np.array(list(d['aligned sentences source'])) # aligned source, with ^ symbols\n",
    "        t = np.array(list(d['aligned sentences target'])) # aligned target, with @ symbols\n",
    "        a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))\n",
    "        if len(s) == len(t):\n",
    "            ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "            tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "        else:\n",
    "            print('have issue, testing')\n",
    "            if t[0] == ' ' and s[0] != ' ':\n",
    "                t = np.array(list(d['aligned sentences target']))[1:] # aligned target, with @ symbols\n",
    "                a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))[1:]\n",
    "                if len(s) == len(t):\n",
    "                    ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "                    tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "                else:\n",
    "                    print('not aligned, best guess')\n",
    "                    import sys; sys.exit()\n",
    "\n",
    "        source_aligned.append(ss.replace('^','@')) # align with original \n",
    "        target_aligned.append(tt)\n",
    "        source.append(ss.replace('^',''))\n",
    "        target.append(tt.replace('@',''))\n",
    "\n",
    "    datain['words source aligned'] = source_aligned\n",
    "    datain['words target aligned'] = target_aligned\n",
    "    datain['words source'] = source\n",
    "    datain['words target'] = target\n",
    "    return datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "QItVt00_lZiZ",
    "outputId": "f807c704-9aaf-452a-a148-04f08de34893"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>sent num</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The bulk properties of the outer and reverse s...</td>\n",
       "      <td>The bulk properties of the outer and reverse s...</td>\n",
       "      <td>1996ApJ___469__171G</td>\n",
       "      <td>7</td>\n",
       "      <td>38</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This temperature range is a factor of ~20 grea...</td>\n",
       "      <td>This temperature range is a factor of $\\sim 20...</td>\n",
       "      <td>1996ApJ___470__513M</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y. The straight lines drawn represent: (a) the...</td>\n",
       "      <td>$_{V_\\circ}$. The straight lines drawn represe...</td>\n",
       "      <td>1969AJ_____74__882W</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All catalogued nebulae showing on any of the p...</td>\n",
       "      <td>All catalogued nebulae showing on any of the p...</td>\n",
       "      <td>1917ApJ____46___24P</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ture only, we must assume that, as we ascend t...</td>\n",
       "      <td>ture only, we must assume that, as we ascend t...</td>\n",
       "      <td>1913ApJ____38__407M</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>plain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    sentences source  \\\n",
       "0  The bulk properties of the outer and reverse s...   \n",
       "1  This temperature range is a factor of ~20 grea...   \n",
       "2  y. The straight lines drawn represent: (a) the...   \n",
       "3  All catalogued nebulae showing on any of the p...   \n",
       "4  ture only, we must assume that, as we ascend t...   \n",
       "\n",
       "                                    sentences target             filename  \\\n",
       "0  The bulk properties of the outer and reverse s...  1996ApJ___469__171G   \n",
       "1  This temperature range is a factor of $\\sim 20...  1996ApJ___470__513M   \n",
       "2  $_{V_\\circ}$. The straight lines drawn represe...  1969AJ_____74__882W   \n",
       "3  All catalogued nebulae showing on any of the p...  1917ApJ____46___24P   \n",
       "4  ture only, we must assume that, as we ascend t...  1913ApJ____38__407M   \n",
       "\n",
       "   page  sent num   type  \n",
       "0     7        38  plain  \n",
       "1     5        13  plain  \n",
       "2     7        20  plain  \n",
       "3    13         2  plain  \n",
       "4    86         0  plain  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oQA5YZDdlZgM"
   },
   "outputs": [],
   "source": [
    "if only_words:\n",
    "    train_df = add_formatted_columns(train_df)\n",
    "    eval_df = add_formatted_columns(eval_df)\n",
    "    test_df = add_formatted_columns(test_df)\n",
    "    # rename sentences we want\n",
    "    train_df = train_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "    eval_df = eval_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "    test_df = test_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "else:\n",
    "    # rename sentences we want\n",
    "    train_df = train_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})\n",
    "    eval_df = eval_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})\n",
    "    test_df = test_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Jd1PXsovlZd2"
   },
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    #\"model_name_or_path\": 'google/byt5-small',\n",
    "    #\"max_len\": 4096,\n",
    "    #\"max_length\": 4096,\n",
    "    \"output_dir\": output_dir,\n",
    "    \"logging_dir\":output_dir + '/logs/',\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"warmup_steps\": 250,\n",
    "    \"logging_steps\": 100,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 1000,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"fp16\": False,\n",
    "    #\"use_cache\": False,\n",
    "    \"max_steps\": 100000,\n",
    "    'save_steps':1000,\n",
    "    'save_strategy':'steps',\n",
    "    'load_best_model_at_end': True#,\n",
    "    # 'metric_for_best_model':'eval_loss',\n",
    "    # 'greater_is_better':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FxQxNcMjoi8O"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MWfk71QslZby"
   },
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "        (TrainingArguments))\n",
    "training_args = parser.parse_dict(args_dict)\n",
    "# set_seed(training_args.seed)\n",
    "args = training_args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-UWnONbvlZZt"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cc1d32dd6bb44f3a78aba9dfffaff87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9127464f08e4e77ad628553baf9fb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/698 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2894e5de6c9149188471866011d25207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_pretrained,\n",
    "    cache_dir=output_dir, \n",
    "    max_length=4096\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Vbky6fbWlZXe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093a43d89cc944e0ab78fab950bdad02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_pretrained,\n",
    "    cache_dir=output_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lVetcdNVlZVI"
   },
   "outputs": [],
   "source": [
    "# overwriting the default max_length of 20 \n",
    "tokenizer.model_max_length=4096\n",
    "model.config.max_length=4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lVv94v7BlZS6"
   },
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "    def __init__(self, Text, Label):\n",
    "        self.Text = Text\n",
    "        self.Label = Label\n",
    "        # self.tokenizer = tokenizer\n",
    "        # self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.Text)\n",
    "    def __getitem__(self, item):\n",
    "        Text = str(self.Text[item])\n",
    "        Label = self.Label[item]\n",
    "        inputs = tokenizer(Text, padding=\"max_length\", truncation=True, max_length=512)\n",
    "        outputs = tokenizer(Label, padding=\"max_length\", truncation=True, max_length=512)\n",
    "        return {\n",
    "          \"input_ids\":inputs.input_ids,\n",
    "          \"attention_mask\" : inputs.attention_mask,\n",
    "          \"labels\" : outputs.input_ids,\n",
    "          \"decoder_attention_mask\" : outputs.attention_mask,\n",
    "          # \"labels\" : lbz\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mix1mmuWlZQs"
   },
   "outputs": [],
   "source": [
    "ds_train = GPReviewDataset(\n",
    "  Text=train_df.input_text.to_numpy(),\n",
    "  Label=train_df.target_text.to_numpy()\n",
    "  # tokenizer=tokenizer,\n",
    "  # max_len=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "XxekcQahlZOn"
   },
   "outputs": [],
   "source": [
    "ds_test = GPReviewDataset(\n",
    "  Text=eval_df.input_text.to_numpy(),\n",
    "  Label=eval_df.target_text.to_numpy()\n",
    "  # tokenizer=tokenizer,\n",
    "  # max_len=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XFQ-LlwNlZMd"
   },
   "outputs": [],
   "source": [
    "train_dataset = ds_train\n",
    "valid_dataset = ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "vKJTtQS9lZKh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnaiman/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "    # compute_metrics=compute_metrics\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tpQpGEMU2hjf",
    "outputId": "8221f736-d6ec-4502-a566-41f775106f69"
   },
   "outputs": [],
   "source": [
    "#!ls gdrive/MyDrive/TPDL\\ 2023\\ Colab\\ Notebooks/byt5_models/byt5_inline_cite_ref_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "B1SmApob2d1_",
    "outputId": "379f8e10-6149-44f5-ddd3-cb8a6c85f52c"
   },
   "outputs": [],
   "source": [
    "#output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "kggLRL_42vAL",
    "outputId": "8241612e-e878-485c-cc89-51c6692da677"
   },
   "outputs": [],
   "source": [
    "#f''+output_dir + 'checkpoint-15000'\n",
    "#trainer.args?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v0mnJg8HlZIc",
    "outputId": "c45bb6b2-6ba5-4fce-89be-46cbf1157bd1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnaiman/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 86\n",
      "  Num Epochs = 20000\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='221' max='100000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   221/100000 07:32 < 57:18:28, 0.48 it/s, Epoch 43.91/20000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>64.377300</td>\n",
       "      <td>77.402344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>64.263300</td>\n",
       "      <td>71.808060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>60.828400</td>\n",
       "      <td>63.747990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>54.879700</td>\n",
       "      <td>53.098999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>45.856500</td>\n",
       "      <td>38.290672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>32.150000</td>\n",
       "      <td>23.657043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>14.412200</td>\n",
       "      <td>4.541070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.883400</td>\n",
       "      <td>4.141339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.235800</td>\n",
       "      <td>3.494669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.497000</td>\n",
       "      <td>2.358604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.186600</td>\n",
       "      <td>0.735483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.738400</td>\n",
       "      <td>0.113716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.240900</td>\n",
       "      <td>0.071277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.051396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.047838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.066100</td>\n",
       "      <td>0.046058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.048377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>0.050236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.052394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.052235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.054792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.054552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-10\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-10/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-10/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-20\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-20/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-30\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-30/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-30/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-40\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-40/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-50\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-50/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-50/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-60\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-60/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-70\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-70/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-70/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-80\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-80/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-90\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-90/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-90/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-100\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-100/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-110\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-110/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-110/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-120\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-120/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-130\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-130/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-130/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-140\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-140/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-150\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-150/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-150/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-160\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-160/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-170\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-170/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-170/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-180\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-180/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-180/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-190\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-190/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-190/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-200\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-200/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-200/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-210\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-210/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-210/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-10] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 11\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-220\n",
      "Configuration saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-220/config.json\n",
      "Model weights saved in /home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-220/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/jnaiman/models/byt5_ocr_full_hal_historical/checkpoint-20] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1512558/309552022.py\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m \u001b[0;31m# down from 10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_point_load\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put in checkpoint if need be here to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_point_load\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1363\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m                 if (\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1956\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.args.save_total_limit = 20\n",
    "trainer.args.logging_steps = 10 # down from 100\n",
    "trainer.args.save_steps=10 # down from 10000\n",
    "trainer.args.eval_steps = trainer.args.logging_steps # down from 1000\n",
    "trainer.args.max_steps = 100000 # down from 10000\n",
    "if check_point_load is None:\n",
    "    trainer.train() # put in checkpoint if need be here to load \n",
    "else:\n",
    "    trainer.train(check_point_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwBjpXo-lY-r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GeTmNSxK1yWf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PyTorchOCR]",
   "language": "python",
   "name": "conda-env-.conda-PyTorchOCR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
