{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1675029271460,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "RYwpkolCjbwf"
   },
   "source": [
    "## Use opence-v1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285506,
     "status": "ok",
     "timestamp": 1675029556960,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "l2uSZFDYBfUt",
    "outputId": "97d0eaeb-4e7c-4574-818b-33cefe253fe6"
   },
   "outputs": [],
   "source": [
    "#  # mount drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/', force_remount=True)\n",
    "# root_dir = \"/content/gdrive/MyDrive\"\n",
    "# # change the OS to use your project folder as the working directory\n",
    "# notebooks = \"/post_ocr_repository/post_ocr_correction/notebooks/en\"\n",
    "# import os\n",
    "# os.chdir(root_dir + notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HAL\n",
    "# file_dir = '/home/jnaiman/wwt_image_extraction/alignments/'\n",
    "# output_folder = '/home/jnaiman/data/morgan/'\n",
    "# # utils from local\n",
    "# from sys import path\n",
    "# path.append('/home/jnaiman/libraries/')\n",
    "# from utils_ocr_mini import align_texts_fast\n",
    "\n",
    "# local\n",
    "file_dir = '/Users/jnaiman/Dropbox/wwt_image_extraction/OCRPostCorrection/alignments/'\n",
    "output_folder = '/Users/jnaiman/Downloads/tmp/ocrpost/data/morgan/'\n",
    "from sys import path\n",
    "path.append('../scienceDigitization/text_mining_ocr_and_pdf/ocr_spell_check/')\n",
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import align_texts_fast, get_fill_in_types\n",
    "\n",
    "realign_dir = '/Users/jnaiman/Dropbox/wwt_image_extraction/OCRPostCorrection/ocr_pdf_aligned_sents_each_realign5/'\n",
    "\n",
    "\n",
    "ender = '_small_words_pageLevel'\n",
    "\n",
    "\n",
    "window_length = 100 # for subsetting the data\n",
    "\n",
    "npages_train = 1000\n",
    "npages_val = 250\n",
    "npages_test = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2267,
     "status": "ok",
     "timestamp": 1675029559224,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "Twat4cYVq7Wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sys import path\n",
    "#path.append('/home/jnaiman/.local')\n",
    "\n",
    "from nltk.lm import Vocabulary\n",
    "#import sys\n",
    "#sys.path.append(\"../../lib\")\n",
    "#from metrics import levenshtein\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from Levenshtein import distance\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import Levenshtein\n",
    "\n",
    "import time\n",
    "#from multiprocessing import Pool\n",
    "from multiprocess import Pool # not sure if this is needed only on the mac?\n",
    "\n",
    "\n",
    "# from importlib import reload\n",
    "# import utils_ocr_mini\n",
    "# reload(utils_ocr_mini)\n",
    "# from utils_ocr_mini import align_texts_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(x):\n",
    "    A, B, window_length = x\n",
    "    assert len(A) == len(B)\n",
    "    return [(A[i:i + window_length], B[i:i + window_length]) \n",
    "            for i in range(len(A) + 1)]\n",
    "\n",
    "def levenshtein(reference, hypothesis, progress_bar = False):\n",
    "    assert len(reference) == len(hypothesis)\n",
    "    text = zip(reference, hypothesis)\n",
    "    if progress_bar:\n",
    "        text = tqdm(text, total = len(reference))\n",
    "    d = [distance(r, h) for r, h in text]\n",
    "    output = pd.DataFrame({\"reference\":reference, \"hypothesis\":hypothesis})\\\n",
    "    .assign(distance = lambda df: d)\\\n",
    "    .assign(\n",
    "        cer = lambda df: df.apply(\n",
    "            lambda r: 100 * r[\"distance\"] / max(len(r[\"reference\"]), 1), \n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all data, format maybe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7857"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_files = glob(realign_dir + '*.pickle')\n",
    "len(align_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(npages, arts_save = [], pages_save = [], imod=1000):\n",
    "    # arts_save = []\n",
    "    # pages_save = []\n",
    "    train_pdf = []; train_ocr = []\n",
    "    pages_save_out = []; filenames = []\n",
    "    pdf_clean = []; ocr_clean = []\n",
    "    while len(train_pdf) < npages:\n",
    "        if len(train_pdf)%imod == 0:\n",
    "            print('on', len(train_pdf), 'of', npages)\n",
    "        i = np.random.randint(len(align_files))\n",
    "        with open(align_files[i],'rb') as f:\n",
    "            article = pickle.load(f)\n",
    "        page_keys = list(article.keys())\n",
    "        if len(page_keys) > 0:\n",
    "            j = np.random.randint(len(page_keys))\n",
    "            # check already in there\n",
    "            alreadyIn = False\n",
    "            if align_files[i].split('/')[-1].split('.pickle')[0] in arts_save:\n",
    "                ind = arts_save.index(align_files[i].split('/')[-1].split('.pickle')[0])\n",
    "                if page_keys[j] in pages_save: # also in there, correct one?\n",
    "                    if pages_save[ind] == page_keys[j]: # same index\n",
    "                        alreadyIn = True\n",
    "            if not alreadyIn:\n",
    "                arts_save.append(align_files[i].split('/')[-1].split('.pickle')[0])\n",
    "                pages_save.append(page_keys[j])\n",
    "                if article[page_keys[j]] != {}:\n",
    "                    train_pdf.append(article[page_keys[j]]['PDF'])\n",
    "                    # for formatting\n",
    "                    train_ocr.append(article[page_keys[j]]['OCR'].replace('^','@'))\n",
    "                    # also cleaned\n",
    "                    pdf_clean.append(article[page_keys[j]]['PDF'].replace('@',''))\n",
    "                    ocr_clean.append(article[page_keys[j]]['OCR'].replace('^',''))\n",
    "                    pages_save_out.append(page_keys[j])\n",
    "                    filenames.append(align_files[i].split('/')[-1].split('.pickle')[0])\n",
    "\n",
    "    train_df = pd.DataFrame({'gt':train_pdf, 'ocr':train_ocr, 'filename':filenames, \n",
    "                             'page':pages_save_out,\n",
    "                            'gt_clean':pdf_clean, 'ocr_clean':ocr_clean})\n",
    "    return train_df, arts_save, pages_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 1000\n"
     ]
    }
   ],
   "source": [
    "train_data, arts_save, pages_save = make_dataframe(npages_train,\n",
    "                                                   arts_save = [], pages_save = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 250\n",
      "on 0 of 250\n"
     ]
    }
   ],
   "source": [
    "val_data, arts_save, pages_save = make_dataframe(npages_val, \n",
    "                                                arts_save=arts_save.copy(),\n",
    "                                               pages_save=pages_save.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 250\n",
      "on 0 of 250\n",
      "on 0 of 250\n",
      "on 0 of 250\n",
      "on 0 of 250\n"
     ]
    }
   ],
   "source": [
    "test_data, arts_save, pages_save = make_dataframe(npages_test, \n",
    "                                                arts_save=arts_save.copy(),\n",
    "                                               pages_save=pages_save.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all together to for vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data,val_data,test_data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>ocr</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>gt_clean</th>\n",
       "      <th>ocr_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>1111_1111.5432d_hatp13_psfilefixedRTM_hocr</td>\n",
       "      <td>page8</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>@ Finally. the accurate. observational determi...</td>\n",
       "      <td>1009_1009.1978d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>Finally. the accurate. observational determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>1007_1007.0493d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>0810_0810.0555d_11077aph_psfilefixedRTM_hocr</td>\n",
       "      <td>page4</td>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>1106_1106.1432d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  @ Finally. the accurate. observational determi...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                       filename   page  \\\n",
       "0    1111_1111.5432d_hatp13_psfilefixedRTM_hocr  page8   \n",
       "1        1009_1009.1978d_ms_psfilefixedRTM_hocr  page1   \n",
       "2        1007_1007.0493d_ms_psfilefixedRTM_hocr  page1   \n",
       "3  0810_0810.0555d_11077aph_psfilefixedRTM_hocr  page4   \n",
       "4        1106_1106.1432d_ms_psfilefixedRTM_hocr  page1   \n",
       "\n",
       "                                            gt_clean  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                           ocr_clean  \n",
       "0  The HAT-P-13 system is unusual in that a trans...  \n",
       "1   Finally. the accurate. observational determin...  \n",
       "2  galaxies. BECs are known to have positive colo...  \n",
       "3  where with are the deusity fractions of each m...  \n",
       "4  resolution EVLA observations. We use a concord...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out any weirdos\n",
    "mask = (pd.isnull(data['gt'])) | (pd.isnull(data['ocr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>ocr</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>gt_clean</th>\n",
       "      <th>ocr_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>1111_1111.5432d_hatp13_psfilefixedRTM_hocr</td>\n",
       "      <td>page8</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>@ Finally. the accurate. observational determi...</td>\n",
       "      <td>1009_1009.1978d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>Finally. the accurate. observational determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>1007_1007.0493d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>0810_0810.0555d_11077aph_psfilefixedRTM_hocr</td>\n",
       "      <td>page4</td>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>1106_1106.1432d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  @ Finally. the accurate. observational determi...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                       filename   page  \\\n",
       "0    1111_1111.5432d_hatp13_psfilefixedRTM_hocr  page8   \n",
       "1        1009_1009.1978d_ms_psfilefixedRTM_hocr  page1   \n",
       "2        1007_1007.0493d_ms_psfilefixedRTM_hocr  page1   \n",
       "3  0810_0810.0555d_11077aph_psfilefixedRTM_hocr  page4   \n",
       "4        1106_1106.1432d_ms_psfilefixedRTM_hocr  page1   \n",
       "\n",
       "                                            gt_clean  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                           ocr_clean  \n",
       "0  The HAT-P-13 system is unusual in that a trans...  \n",
       "1   Finally. the accurate. observational determin...  \n",
       "2  galaxies. BECs are known to have positive colo...  \n",
       "3  where with are the deusity fractions of each m...  \n",
       "4  resolution EVLA observations. We use a concord...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename with equivalents for the original OCR method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.rename(columns={\"sentences source\": \"ocr_aligned\", \n",
    "#                         \"sentences target\": \"gs_aligned\"})\n",
    "\n",
    "data = data.rename(columns={'ocr_clean':\"ocr_to_input\", \n",
    "                            'ocr': \"ocr_aligned\",\n",
    "                            'gt':\"gs_aligned\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_to_input</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finally. the accurate. observational determin...</td>\n",
       "      <td>@ Finally. the accurate. observational determi...</td>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ocr_to_input  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1   Finally. the accurate. observational determin...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                         ocr_aligned  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  @ Finally. the accurate. observational determi...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                          gs_aligned  \n",
       "0  The HAT-P-13 system is unusual in that a trans...  \n",
       "1  . Finally, the accurate, observational determi...  \n",
       "2  galaxies. BEGs are known to have positive colo...  \n",
       "3  where with are the density fractions of each m...  \n",
       "4  resolution EVLA observations. We use a concord...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['ocr_to_input','ocr_aligned', 'gs_aligned']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_to_input</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3014.155333</td>\n",
       "      <td>3041.941333</td>\n",
       "      <td>3041.941333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1585.452724</td>\n",
       "      <td>1600.632865</td>\n",
       "      <td>1600.632865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1872.250000</td>\n",
       "      <td>1892.750000</td>\n",
       "      <td>1892.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2866.500000</td>\n",
       "      <td>2897.500000</td>\n",
       "      <td>2897.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4131.250000</td>\n",
       "      <td>4177.500000</td>\n",
       "      <td>4177.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7114.000000</td>\n",
       "      <td>8625.000000</td>\n",
       "      <td>8625.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_to_input  ocr_aligned   gs_aligned\n",
       "count   1500.000000  1500.000000  1500.000000\n",
       "mean    3014.155333  3041.941333  3041.941333\n",
       "std     1585.452724  1600.632865  1600.632865\n",
       "min        1.000000     1.000000     1.000000\n",
       "25%     1872.250000  1892.750000  1892.750000\n",
       "50%     2866.500000  2897.500000  2897.500000\n",
       "75%     4131.250000  4177.500000  4177.500000\n",
       "max     7114.000000  8625.000000  8625.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['ocr_to_input','ocr_aligned', 'gs_aligned']].applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1500.000000\n",
       "mean        5.413870\n",
       "std         6.446605\n",
       "min         0.000000\n",
       "25%         2.402198\n",
       "50%         4.319378\n",
       "75%         6.750639\n",
       "max        88.208617\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = data.gs_aligned.str.replace(\"@\", \"\"), \n",
    "            hypothesis = data.ocr_to_input).cer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1500.000000\n",
       "mean        5.235680\n",
       "std         5.824194\n",
       "min         0.000000\n",
       "25%         2.370930\n",
       "50%         4.249685\n",
       "75%         6.629447\n",
       "max        83.165217\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = data.gs_aligned, \n",
    "            hypothesis = data.ocr_aligned).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean       6.048617\n",
       "std        8.439131\n",
       "min        0.000000\n",
       "25%        2.599628\n",
       "50%        4.564981\n",
       "75%        7.002886\n",
       "max       83.165217\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try with just test dataset:\n",
    "#data = pd.concat([train_data,val_data,test_data],ignore_index=True)\n",
    "levenshtein(reference = data.iloc[-len(test_data):].gs_aligned.replace(\"@\",\"\"), \n",
    "            hypothesis = data.iloc[-len(test_data):].ocr_aligned.replace(\"@\",\"\")).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>ocr</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>gt_clean</th>\n",
       "      <th>ocr_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Define A@:= Since a complement space to the im...</td>\n",
       "      <td>Define AA:= Since a complement space to the im...</td>\n",
       "      <td>1112_1112.2544d_1112.2544_psfilefixedRTM_hocr</td>\n",
       "      <td>page6</td>\n",
       "      <td>Define A:= Since a complement space to the ima...</td>\n",
       "      <td>Define AA:= Since a complement space to the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In van den Bergh (2009) it was speculated that...</td>\n",
       "      <td>In van den Bereh (2009) it was speculated that...</td>\n",
       "      <td>0907_0907.3715d_0907.3715_psfilefixedRTM_hocr</td>\n",
       "      <td>page5</td>\n",
       "      <td>In van den Bergh (2009) it was speculated that...</td>\n",
       "      <td>In van den Bereh (2009) it was speculated that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "      <td>1003_1003.4211d_boosting_psfilefixedRTM_hocr</td>\n",
       "      <td>page11</td>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "      <td>0709_0709.1336d_paper_rev3_aph_psfilefixedRTM_...</td>\n",
       "      <td>page0</td>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strong O band, however. Methane shows only one...</td>\n",
       "      <td>strong @ band. however. Methane shows only one...</td>\n",
       "      <td>0310_astro-ph0310805d_saumon_psfilefixedRTM_hocr</td>\n",
       "      <td>page3</td>\n",
       "      <td>strong O band, however. Methane shows only one...</td>\n",
       "      <td>strong  band. however. Methane shows only one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>motions one can estimate, e.g., the expected m...</td>\n",
       "      <td>motions one can estimate. e.g.. the expected m...</td>\n",
       "      <td>1011_1011.4816d_15641_psfilefixedRTM_hocr</td>\n",
       "      <td>page6</td>\n",
       "      <td>motions one can estimate, e.g., the expected m...</td>\n",
       "      <td>motions one can estimate. e.g.. the expected m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>numerous in our star sample (15381 stars), it ...</td>\n",
       "      <td>numerous in our star sample (15381 stars). it ...</td>\n",
       "      <td>0512_astro-ph0512352d_ngc7789_exp_psfilefixedR...</td>\n",
       "      <td>page7</td>\n",
       "      <td>numerous in our star sample (15381 stars), it ...</td>\n",
       "      <td>numerous in our star sample (15381 stars). it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "      <td>1008_1008.2986d_nsc_psfilefixedRTM_hocr</td>\n",
       "      <td>page2</td>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "      <td>1111_1111.4270d_FCamiloJ2030+3641_psfilefixedR...</td>\n",
       "      <td>page4</td>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>= 9pt = 9pt</td>\n",
       "      <td>| Opt = 9pt</td>\n",
       "      <td>9903_astro-ph9903137d_buris98_psfilefixedRTM_hocr</td>\n",
       "      <td>page3</td>\n",
       "      <td>= 9pt = 9pt</td>\n",
       "      <td>| Opt = 9pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    gt  \\\n",
       "0    Define A@:= Since a complement space to the im...   \n",
       "1    In van den Bergh (2009) it was speculated that...   \n",
       "2    noise due to the low number density of galaxie...   \n",
       "3    X-ray observations with the observatory have e...   \n",
       "4    strong O band, however. Methane shows only one...   \n",
       "..                                                 ...   \n",
       "245  motions one can estimate, e.g., the expected m...   \n",
       "246  numerous in our star sample (15381 stars), it ...   \n",
       "247  we summarize our main conclusions. We assume t...   \n",
       "248  RVM sign convention problem The phase of maxim...   \n",
       "249                                       = 9pt = 9pt    \n",
       "\n",
       "                                                   ocr  \\\n",
       "0    Define AA:= Since a complement space to the im...   \n",
       "1    In van den Bereh (2009) it was speculated that...   \n",
       "2    noise due to the low number density of galaxie...   \n",
       "3    X-ray observations with the observatory have e...   \n",
       "4    strong @ band. however. Methane shows only one...   \n",
       "..                                                 ...   \n",
       "245  motions one can estimate. e.g.. the expected m...   \n",
       "246  numerous in our star sample (15381 stars). it ...   \n",
       "247  we summarize our main conclusions. We assume t...   \n",
       "248  RVM sign convention problem The phase of maxim...   \n",
       "249                                       | Opt = 9pt    \n",
       "\n",
       "                                              filename    page  \\\n",
       "0        1112_1112.2544d_1112.2544_psfilefixedRTM_hocr   page6   \n",
       "1        0907_0907.3715d_0907.3715_psfilefixedRTM_hocr   page5   \n",
       "2         1003_1003.4211d_boosting_psfilefixedRTM_hocr  page11   \n",
       "3    0709_0709.1336d_paper_rev3_aph_psfilefixedRTM_...   page0   \n",
       "4     0310_astro-ph0310805d_saumon_psfilefixedRTM_hocr   page3   \n",
       "..                                                 ...     ...   \n",
       "245          1011_1011.4816d_15641_psfilefixedRTM_hocr   page6   \n",
       "246  0512_astro-ph0512352d_ngc7789_exp_psfilefixedR...   page7   \n",
       "247            1008_1008.2986d_nsc_psfilefixedRTM_hocr   page2   \n",
       "248  1111_1111.4270d_FCamiloJ2030+3641_psfilefixedR...   page4   \n",
       "249  9903_astro-ph9903137d_buris98_psfilefixedRTM_hocr   page3   \n",
       "\n",
       "                                              gt_clean  \\\n",
       "0    Define A:= Since a complement space to the ima...   \n",
       "1    In van den Bergh (2009) it was speculated that...   \n",
       "2    noise due to the low number density of galaxie...   \n",
       "3    X-ray observations with the observatory have e...   \n",
       "4    strong O band, however. Methane shows only one...   \n",
       "..                                                 ...   \n",
       "245  motions one can estimate, e.g., the expected m...   \n",
       "246  numerous in our star sample (15381 stars), it ...   \n",
       "247  we summarize our main conclusions. We assume t...   \n",
       "248  RVM sign convention problem The phase of maxim...   \n",
       "249                                       = 9pt = 9pt    \n",
       "\n",
       "                                             ocr_clean  \n",
       "0    Define AA:= Since a complement space to the im...  \n",
       "1    In van den Bereh (2009) it was speculated that...  \n",
       "2    noise due to the low number density of galaxie...  \n",
       "3    X-ray observations with the observatory have e...  \n",
       "4    strong  band. however. Methane shows only one ...  \n",
       "..                                                 ...  \n",
       "245  motions one can estimate. e.g.. the expected m...  \n",
       "246  numerous in our star sample (15381 stars). it ...  \n",
       "247  we summarize our main conclusions. We assume t...  \n",
       "248  RVM sign convention problem The phase of maxim...  \n",
       "249                                       | Opt = 9pt   \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "time delta = 1.479722023010254 seconds, or 0.024662033716837565 minutes, or 0.0004110338952806261 hours\n"
     ]
    }
   ],
   "source": [
    "rerun_vocab = False\n",
    "\n",
    "if rerun_vocab:\n",
    "    start_time = time.time()\n",
    "    vocabulary = Vocabulary(data.ocr_to_input.sum() + data.ocr_aligned.sum() + data.gs_aligned.sum())\n",
    "    print(len(vocabulary))\n",
    "    with open(output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\", \"wb\") as file:\n",
    "        pickle.dump(vocabulary, file)\n",
    "    end_time = time.time()\n",
    "    print('time delta =', end_time-start_time, 'seconds, or', \n",
    "          (end_time-start_time)/60., 'minutes, or',\n",
    "         (end_time-start_time)/60./60., 'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_rename(datain):\n",
    "    mask = (pd.isnull(datain['gt'])) | (pd.isnull(datain['ocr']))\n",
    "    # datain = datain.rename(columns={'words source':\"ocr_to_input\", \n",
    "    #                             'words source aligned': \"ocr_aligned\",\n",
    "    #                             'words target aligned':\"gs_aligned\"})\n",
    "    datain = datain.rename(columns={'ocr_clean':\"ocr_to_input\", \n",
    "                            'ocr': \"ocr_aligned\",\n",
    "                            'gt':\"gs_aligned\"})\n",
    "    return datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_pickle(output_folder+\"/data/train_new_pages\"+ender+\".pkl\")\n",
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format and save training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mask_rename(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfd9879429340809ae41636836b68af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c78bba31f864b3aaf59475663085c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3041135, 2)\n",
      "total time = 7.2342798709869385 seconds, or 0.12057133118311564 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with Pool(4) as p:\n",
    "    train_aligned = list(p.imap_unordered(create_windows, \n",
    "                                          tqdm(zip(train_data.ocr_aligned, \n",
    "                                                   train_data.gs_aligned, \n",
    "                                                   [window_length for x in train_data.ocr_aligned]), \n",
    "                                               total = len(train_data.ocr_aligned)),\n",
    "                                          chunksize = 128))\n",
    "s = []\n",
    "for r in tqdm(train_aligned):\n",
    "    s.extend(r)\n",
    "train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "print(train_aligned.shape)\n",
    "train_aligned.head()\n",
    "end_time = time.time()\n",
    "print('total time =', end_time-start_time, 'seconds, or', (end_time-start_time)/60., 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this section we discuss the effects of clus...</td>\n",
       "      <td>In this section we discuss the effects of clus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n this section we discuss the effects of clust...</td>\n",
       "      <td>n this section we discuss the effects of clust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this section we discuss the effects of cluste...</td>\n",
       "      <td>this section we discuss the effects of cluste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this section we discuss the effects of cluster...</td>\n",
       "      <td>this section we discuss the effects of cluster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>his section we discuss the effects of cluster ...</td>\n",
       "      <td>his section we discuss the effects of cluster ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  In this section we discuss the effects of clus...   \n",
       "1  n this section we discuss the effects of clust...   \n",
       "2   this section we discuss the effects of cluste...   \n",
       "3  this section we discuss the effects of cluster...   \n",
       "4  his section we discuss the effects of cluster ...   \n",
       "\n",
       "                                              target  \n",
       "0  In this section we discuss the effects of clus...  \n",
       "1  n this section we discuss the effects of clust...  \n",
       "2   this section we discuss the effects of cluste...  \n",
       "3  this section we discuss the effects of cluster...  \n",
       "4  his section we discuss the effects of cluster ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aligned = train_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"data/train_aligned_new_pages\"+ender+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dev:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = mask_rename(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766032, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  total contribution of these two populations re...   \n",
       "1  otal contribution of these two populations res...   \n",
       "2  tal contribution of these two populations resu...   \n",
       "3  al contribution of these two populations resul...   \n",
       "4  l contribution of these two populations result...   \n",
       "\n",
       "                                              target  \n",
       "0  total contribution of these two populations re...  \n",
       "1  otal contribution of these two populations res...  \n",
       "2  tal contribution of these two populations resu...  \n",
       "3  al contribution of these two populations resul...  \n",
       "4  l contribution of these two populations result...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = val_data.apply(lambda r: create_windows((r[\"ocr_aligned\"], r[\"gs_aligned\"], window_length)), \n",
    "                            axis = 1).sum()\n",
    "dev_aligned = pd.DataFrame(dev_aligned, columns = [\"source\", \"target\"])\n",
    "print(dev_aligned.shape)\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  total contribution of these two populations re...   \n",
       "1  otal contribution of these two populations res...   \n",
       "2  tal contribution of these two populations resu...   \n",
       "3  al contribution of these two populations resul...   \n",
       "4  l contribution of these two populations result...   \n",
       "\n",
       "                                              target  \n",
       "0  total contribution of these two populations re...  \n",
       "1  otal contribution of these two populations res...  \n",
       "2  tal contribution of these two populations resu...  \n",
       "3  al contribution of these two populations resul...  \n",
       "4  l contribution of these two populations result...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_aligned.to_pickle(output_folder+\"data/dev_aligned_new_pages\"+ender+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(output_folder + \"data/test_file\"+ender+'csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
