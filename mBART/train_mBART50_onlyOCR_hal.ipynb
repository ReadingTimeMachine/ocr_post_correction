{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ya2rjz5flA0f"
   },
   "source": [
    "This runs our model with mBART-50 specific corrections: https://huggingface.co/facebook/mbart-large-50\n",
    "\n",
    "On HAL, use environment PyTorchOCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on HAL\n"
     ]
    }
   ],
   "source": [
    "if '/home/jnaiman/' in os.getcwd(): # on HAL\n",
    "    print('on HAL')\n",
    "    main_dir = '/home/jnaiman/'\n",
    "    output_dir = main_dir + 'models/mBART_models/ocrOnly_large/' # math/cite/refs -- just left in as raw\n",
    "    aligned_dataset_dir = '/home/jnaiman/wwt_image_extraction/alignments/'\n",
    "else:\n",
    "    print('on Colab')\n",
    "    # mount drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive/', force_remount=True)\n",
    "    \n",
    "    main_dir = 'gdrive/MyDrive/TPDL 2023 Colab Notebooks/'\n",
    "\n",
    "    # where to output models\n",
    "    output_dir = main_dir + 'mBART_models/ocrOnly_large/' # math/cite/refs -- just left in as raw\n",
    "\n",
    "    # where is data stored?\n",
    "    aligned_dataset_dir = main_dir + 'data/alignments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kCqaqXXMmqF_"
   },
   "outputs": [],
   "source": [
    "# which model do we want to start from pre-trained?\n",
    "#model_pretrained = 'google/byt5-small' # orig\n",
    "#model_pretrained = 'yelpfeast/byt5-base-english-ocr-correction' # for OCR correction specifically\n",
    "###model_pretrained = 'facebook/mbart-large-50' # mBART-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oxxtYvsbncTB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(aligned_dataset_dir+'train_masked_n500000_20230503.csv')\n",
    "eval_df = pd.read_csv(aligned_dataset_dir+'val_masked_n10000_20230503.csv')\n",
    "test_df = pd.read_csv(aligned_dataset_dir+'test_masked_n10000_20230503.csv')\n",
    "\n",
    "only_words = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 804
    },
    "id": "wotefPaCoxuA",
    "outputId": "6f08186d-21bc-4c31-d35c-5a6ff1e93129"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers[sentencepiece]==4.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2bfOyWk8lkUr"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ir14BJRimVE8"
   },
   "source": [
    "Order here is important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6THPU5s7l5Ey"
   },
   "outputs": [],
   "source": [
    "# !pip install pybind11 \n",
    "# !pip install fastwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "g154RiKGlb_h"
   },
   "outputs": [],
   "source": [
    "from transformers import HfArgumentParser, TensorFlowBenchmark, TensorFlowBenchmarkArguments\n",
    "#import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "from transformers import TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WX29dDbfls7l"
   },
   "outputs": [],
   "source": [
    "##import fastwer\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3Giern-Vlfsr"
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(main_dir + 'libraries/')\n",
    "from utils_ocr_mini import get_fill_in_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oJUsyo_UlZko",
    "outputId": "0d5d670a-aac0-4c96-e556-f64bfadd58e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "cuda.empty_cache()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nOeops60nnoU"
   },
   "outputs": [],
   "source": [
    "def add_formatted_columns(datain):\n",
    "    source = []\n",
    "    target = []\n",
    "    source_aligned = []\n",
    "    target_aligned = []\n",
    "    for i in range(len(datain)):\n",
    "        d = datain.iloc[i]\n",
    "        s = np.array(list(d['aligned sentences source'])) # aligned source, with ^ symbols\n",
    "        t = np.array(list(d['aligned sentences target'])) # aligned target, with @ symbols\n",
    "        a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))\n",
    "        if len(s) == len(t):\n",
    "            ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "            tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "        else:\n",
    "            print('have issue, testing')\n",
    "            if t[0] == ' ' and s[0] != ' ':\n",
    "                t = np.array(list(d['aligned sentences target']))[1:] # aligned target, with @ symbols\n",
    "                a = np.array(list(get_fill_in_types(d['aligned sentences target types'])))[1:]\n",
    "                if len(s) == len(t):\n",
    "                    ss = \"\".join(s[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "                    tt = \"\".join(t[np.where( (a == ' ') | (a == 'W') | (a == 'w'))[0]].tolist())\n",
    "                else:\n",
    "                    print('not aligned, best guess')\n",
    "                    import sys; sys.exit()\n",
    "\n",
    "        source_aligned.append(ss.replace('^','@')) # align with original \n",
    "        target_aligned.append(tt)\n",
    "        source.append(ss.replace('^',''))\n",
    "        target.append(tt.replace('@',''))\n",
    "\n",
    "    datain['words source aligned'] = source_aligned\n",
    "    datain['words target aligned'] = target_aligned\n",
    "    datain['words source'] = source\n",
    "    datain['words target'] = target\n",
    "    return datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "id": "QItVt00_lZiZ",
    "outputId": "de9645bb-12e7-4a3b-fdf5-aa2462fc3c6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aligned sentences source</th>\n",
       "      <th>aligned sentences target</th>\n",
       "      <th>sentences source</th>\n",
       "      <th>sentences target</th>\n",
       "      <th>aligned sentences source types</th>\n",
       "      <th>aligned sentences target types</th>\n",
       "      <th>sentences source types</th>\n",
       "      <th>sentences target types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>To a good approxiuiati^^^ the radial velocity...</td>\n",
       "      <td>To a good approxim@ation, the radial velocity...</td>\n",
       "      <td>To a good approxiuiati the radial velocity of...</td>\n",
       "      <td>To a good approximation, the radial velocity ...</td>\n",
       "      <td>WW W WWWW WWWWWWWWWWWW^^^ WWW WWWWWW WWWWWWWW...</td>\n",
       "      <td>WW W WWWW WWWWWWWW@WWWWWW WWW WWWWWW WWWWWWWW...</td>\n",
       "      <td>WW W WWWW WWWWWWWWWWWW WWW WWWWWW WWWWWWWW WW...</td>\n",
       "      <td>WW W WWWW WWWWWWWWWWWWWW WWW WWWWWW WWWWWWWW ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Where all the units must be in ces and the ^L^...</td>\n",
       "      <td>Where all the units must be in cgs and the $L_...</td>\n",
       "      <td>Where all the units must be in ces and the Leu...</td>\n",
       "      <td>Where all the units must be in cgs and the $L_...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW ^I^...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...</td>\n",
       "      <td>WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>^At sulliciently high temperatures the ^^^^^^^...</td>\n",
       "      <td>At sufficiently high temperatures the $^4\\mat...</td>\n",
       "      <td>At sulliciently high temperatures the !1 and =...</td>\n",
       "      <td>At sufficiently high temperatures the $^4\\mat...</td>\n",
       "      <td>^WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW ^^^^^^^...</td>\n",
       "      <td>WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...</td>\n",
       "      <td>WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW II WWW I...</td>\n",
       "      <td>WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The resulting spectral resolution was ^^^^^^8...</td>\n",
       "      <td>The resulting spectral resolution was $\\sim 8...</td>\n",
       "      <td>The resulting spectral resolution was 8 kIlz ...</td>\n",
       "      <td>The resulting spectral resolution was $\\sim 8...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW ^^^^^II...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW II WWWW...</td>\n",
       "      <td>WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One approach is ^o search for a CAV signal fo...</td>\n",
       "      <td>One approach is to search for a GW@ signal fo...</td>\n",
       "      <td>One approach is o search for a CAV signal fol...</td>\n",
       "      <td>One approach is to search for a GW signal fol...</td>\n",
       "      <td>WWW WWWWWWWW WW ^W WWWWWW WWW W WWW WWWWWW WW...</td>\n",
       "      <td>WWW WWWWWWWW WW WW WWWWWW WWW W WW@ WWWWWW WW...</td>\n",
       "      <td>WWW WWWWWWWW WW W WWWWWW WWW W WWW WWWWWW WWW...</td>\n",
       "      <td>WWW WWWWWWWW WW WW WWWWWW WWW W WW WWWWWW WWW...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            aligned sentences source  \\\n",
       "0   To a good approxiuiati^^^ the radial velocity...   \n",
       "1  Where all the units must be in ces and the ^L^...   \n",
       "2  ^At sulliciently high temperatures the ^^^^^^^...   \n",
       "3   The resulting spectral resolution was ^^^^^^8...   \n",
       "4   One approach is ^o search for a CAV signal fo...   \n",
       "\n",
       "                            aligned sentences target  \\\n",
       "0   To a good approxim@ation, the radial velocity...   \n",
       "1  Where all the units must be in cgs and the $L_...   \n",
       "2   At sufficiently high temperatures the $^4\\mat...   \n",
       "3   The resulting spectral resolution was $\\sim 8...   \n",
       "4   One approach is to search for a GW@ signal fo...   \n",
       "\n",
       "                                    sentences source  \\\n",
       "0   To a good approxiuiati the radial velocity of...   \n",
       "1  Where all the units must be in ces and the Leu...   \n",
       "2  At sulliciently high temperatures the !1 and =...   \n",
       "3   The resulting spectral resolution was 8 kIlz ...   \n",
       "4   One approach is o search for a CAV signal fol...   \n",
       "\n",
       "                                    sentences target  \\\n",
       "0   To a good approximation, the radial velocity ...   \n",
       "1  Where all the units must be in cgs and the $L_...   \n",
       "2   At sufficiently high temperatures the $^4\\mat...   \n",
       "3   The resulting spectral resolution was $\\sim 8...   \n",
       "4   One approach is to search for a GW signal fol...   \n",
       "\n",
       "                      aligned sentences source types  \\\n",
       "0   WW W WWWW WWWWWWWWWWWW^^^ WWW WWWWWW WWWWWWWW...   \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW ^I^...   \n",
       "2  ^WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW ^^^^^^^...   \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW ^^^^^II...   \n",
       "4   WWW WWWWWWWW WW ^W WWWWWW WWW W WWW WWWWWW WW...   \n",
       "\n",
       "                      aligned sentences target types  \\\n",
       "0   WW W WWWW WWWWWWWW@WWWWWW WWW WWWWWW WWWWWWWW...   \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...   \n",
       "2   WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...   \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...   \n",
       "4   WWW WWWWWWWW WW WW WWWWWW WWW W WW@ WWWWWW WW...   \n",
       "\n",
       "                              sentences source types  \\\n",
       "0   WW W WWWW WWWWWWWWWWWW WWW WWWWWW WWWWWWWW WW...   \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...   \n",
       "2  WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW II WWW I...   \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW II WWWW...   \n",
       "4   WWW WWWWWWWW WW W WWWWWW WWW W WWW WWWWWW WWW...   \n",
       "\n",
       "                              sentences target types  \n",
       "0   WW W WWWW WWWWWWWWWWWWWW WWW WWWWWW WWWWWWWW ...  \n",
       "1  WWWWW WWW WWW WWWWW WWWW WW WW WWW WWW WWW III...  \n",
       "2   WW WWWWWWWWWWWW WWWW WWWWWWWWWWWW WWW IIIIIII...  \n",
       "3   WWW WWWWWWWWW WWWWWWWW WWWWWWWWWW WWW IIIIIII...  \n",
       "4   WWW WWWWWWWW WW WW WWWWWW WWW W WW WWWWWW WWW...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQA5YZDdlZgM",
    "outputId": "e0ebefd3-f6f6-41c2-d0c1-27c8022205da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "have issue, testing\n"
     ]
    }
   ],
   "source": [
    "if only_words:\n",
    "    train_df = add_formatted_columns(train_df)\n",
    "    eval_df = add_formatted_columns(eval_df)\n",
    "    test_df = add_formatted_columns(test_df)\n",
    "    # rename sentences we want\n",
    "    train_df = train_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "    eval_df = eval_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "    test_df = test_df.rename(columns={\"words source\": \"input_text\", \n",
    "                        \"words target\": \"target_text\"})\n",
    "else:\n",
    "    # rename sentences we want\n",
    "    train_df = train_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})\n",
    "    eval_df = eval_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})\n",
    "    test_df = test_df.rename(columns={\"sentences source\": \"input_text\", \n",
    "                        \"sentences target\": \"target_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Jd1PXsovlZd2"
   },
   "outputs": [],
   "source": [
    "args_dict = {\n",
    "    #\"model_name_or_path\": 'google/byt5-small',\n",
    "    #\"max_len\": 4096,\n",
    "    #\"max_length\": 4096,\n",
    "    \"output_dir\": output_dir,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"warmup_steps\": 250,\n",
    "    \"logging_steps\": 100,\n",
    "    \"evaluation_strategy\": \"steps\",\n",
    "    \"eval_steps\": 1000,\n",
    "    \"num_train_epochs\": 4,\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"fp16\": False,\n",
    "    #\"use_cache\": False,\n",
    "    \"max_steps\": 100000,\n",
    "    'save_steps':1000,\n",
    "    'save_strategy':'steps',\n",
    "    'load_best_model_at_end': True#,\n",
    "    # 'metric_for_best_model':'eval_loss',\n",
    "    # 'greater_is_better':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FxQxNcMjoi8O"
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "MWfk71QslZby"
   },
   "outputs": [],
   "source": [
    "parser = HfArgumentParser(\n",
    "        (TrainingArguments))\n",
    "training_args = parser.parse_dict(args_dict)\n",
    "# set_seed(training_args.seed)\n",
    "args = training_args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GvNihf_CtUC6"
   },
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RCGKYeZctdea"
   },
   "outputs": [],
   "source": [
    "#!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "U2hDbx3BtmfI"
   },
   "outputs": [],
   "source": [
    "#!pip install transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-UWnONbvlZZt"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd18da9f8284454981a8983237e8fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac432b587dfb45a68491cb4c50fc32a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d4db26efff4b208091042e1c4f7159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370bda201c80404cbb15cb24420f67dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#     model_pretrained,\n",
    "#     cache_dir=output_dir, \n",
    "#     max_length=4096\n",
    "# )\n",
    "# mbart specific\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50\", src_lang=\"en_XX\", tgt_lang=\"en_XX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Vbky6fbWlZXe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e098f42a764e06b3abd9640818ffe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.28G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model = T5ForConditionalGeneration.from_pretrained(\n",
    "#     model_pretrained,\n",
    "#     cache_dir=output_dir,\n",
    "# )\n",
    "# specific for mBART\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "lVetcdNVlZVI"
   },
   "outputs": [],
   "source": [
    "# overwriting the default max_length of 20 \n",
    "tokenizer.model_max_length=4096\n",
    "model.config.max_length=4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lVv94v7BlZS6"
   },
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "    def __init__(self, Text, Label):\n",
    "        self.Text = Text\n",
    "        self.Label = Label\n",
    "        # self.tokenizer = tokenizer\n",
    "        # self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return len(self.Text)\n",
    "    def __getitem__(self, item):\n",
    "        Text = str(self.Text[item])\n",
    "        Label = self.Label[item]\n",
    "        inputs = tokenizer(Text, padding=\"max_length\", truncation=True, max_length=512)\n",
    "        outputs = tokenizer(Label, padding=\"max_length\", truncation=True, max_length=512)\n",
    "        return {\n",
    "          \"input_ids\":inputs.input_ids,\n",
    "          \"attention_mask\" : inputs.attention_mask,\n",
    "          \"labels\" : outputs.input_ids,\n",
    "          \"decoder_attention_mask\" : outputs.attention_mask,\n",
    "          # \"labels\" : lbz\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "mix1mmuWlZQs"
   },
   "outputs": [],
   "source": [
    "ds_train = GPReviewDataset(\n",
    "  Text=train_df.input_text.to_numpy(),\n",
    "  Label=train_df.target_text.to_numpy()\n",
    "  # tokenizer=tokenizer,\n",
    "  # max_len=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XxekcQahlZOn"
   },
   "outputs": [],
   "source": [
    "ds_test = GPReviewDataset(\n",
    "  Text=eval_df.input_text.to_numpy(),\n",
    "  Label=eval_df.target_text.to_numpy()\n",
    "  # tokenizer=tokenizer,\n",
    "  # max_len=max_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XFQ-LlwNlZMd"
   },
   "outputs": [],
   "source": [
    "train_dataset = ds_train\n",
    "valid_dataset = ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "It looks like the config file at '/home/jnaiman/models/mBART_models/ocrOnly_large/checkpoint-5500/config.json' is not a valid JSON file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0;31m# Load config dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_dict_from_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_758851/3674696270.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model = MBartForConditionalGeneration.from_pretrained(output_dir + 'checkpoint-5500')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'checkpoint-5500'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_from_auto\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             config, kwargs = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    425\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_unused_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             )\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0;31m# That config file may point us toward another config file to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m    638\u001b[0m                 \u001b[0;34mf\"It looks like the config file at '{resolved_config_file}' is not a valid JSON file.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m             )\n",
      "\u001b[0;31mOSError\u001b[0m: It looks like the config file at '/home/jnaiman/models/mBART_models/ocrOnly_large/checkpoint-5500/config.json' is not a valid JSON file."
     ]
    }
   ],
   "source": [
    "#model = MBartForConditionalGeneration.from_pretrained(output_dir + 'checkpoint-5500')\n",
    "model = AutoModel.from_pretrained(output_dir + 'checkpoint-5500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "vKJTtQS9lZKh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jnaiman/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, '__version__') or LooseVersion(tensorboard.__version__) < LooseVersion('1.15'):\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    # callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "    # compute_metrics=compute_metrics\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "v0mnJg8HlZIc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from /home/jnaiman/models/mBART_models/ocrOnly_large/checkpoint-5500).\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_758851/3313658096.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m \u001b[0;31m# down from 10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#trainer.train() # put in checkpoint if need be here to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'checkpoint-5500'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put in checkpoint if need be here to load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCONFIG_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m                 \u001b[0mcheckpoint_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_version\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheckpoint_version\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mfrom_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \"\"\"\n\u001b[0;32m--> 699\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_from_json_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/site-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_dict_from_json_file\u001b[0;34m(cls, json_file)\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__eq__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/PyTorchOCR/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "trainer.args.save_total_limit = 10\n",
    "trainer.args.logging_steps = 100 # down from 100\n",
    "trainer.args.save_steps=500 # down from 10000\n",
    "#trainer.train() # put in checkpoint if need be here to load \n",
    "trainer.train(output_dir + 'checkpoint-5500') # put in checkpoint if need be here to load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jwBjpXo-lY-r"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-PyTorchOCR]",
   "language": "python",
   "name": "conda-env-.conda-PyTorchOCR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
