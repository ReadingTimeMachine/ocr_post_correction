{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60ff4c915af94b0ab4cdfdb6d9fbf8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca3767834b7d407d9b953bdb7a3b7115",
              "IPY_MODEL_44f65e4525e9453fad536f0a6713ce2f",
              "IPY_MODEL_2ff46edf33384465b962a8e22b60d92e"
            ],
            "layout": "IPY_MODEL_db5047880e164999ab24ef40ae44ad3c"
          }
        },
        "ca3767834b7d407d9b953bdb7a3b7115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c7b55ebfec4af6be920b093973bcf9",
            "placeholder": "​",
            "style": "IPY_MODEL_3befbf5009b84740801627ee81c909a2",
            "value": "  0%"
          }
        },
        "44f65e4525e9453fad536f0a6713ce2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c19a1fb404b436cb4f34a3ae6d31762",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_796828cb72a34bd08208a3241afa8682",
            "value": 0
          }
        },
        "2ff46edf33384465b962a8e22b60d92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c1b3b082414d05a9ef57a20fdb0116",
            "placeholder": "​",
            "style": "IPY_MODEL_457a1d49c53a41f0bb0d0ab100313f48",
            "value": " 0/50 [00:00&lt;?, ?it/s]"
          }
        },
        "db5047880e164999ab24ef40ae44ad3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c7b55ebfec4af6be920b093973bcf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3befbf5009b84740801627ee81c909a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c19a1fb404b436cb4f34a3ae6d31762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "796828cb72a34bd08208a3241afa8682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0c1b3b082414d05a9ef57a20fdb0116": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "457a1d49c53a41f0bb0d0ab100313f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a9a6f7d4ac84e6ca4eff72b2efda1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87c5c5236a5f4f6d9f8c09e352ed9370",
              "IPY_MODEL_965787a884644f8aa2baaf03a9f77b20",
              "IPY_MODEL_a47f5370b2814cecb4fdbb4cd9daec3e"
            ],
            "layout": "IPY_MODEL_750f19b39cfc4dcdbe180ba6dadcce95"
          }
        },
        "87c5c5236a5f4f6d9f8c09e352ed9370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354d9e5604814f33aac2ad0b0eac5546",
            "placeholder": "​",
            "style": "IPY_MODEL_375274206e7c417c9108992159a4e332",
            "value": "  1%"
          }
        },
        "965787a884644f8aa2baaf03a9f77b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc809a364aee46baa3625eb7aae7e083",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_63409c4d3cb049be8a626572be5be1e3",
            "value": 68
          }
        },
        "a47f5370b2814cecb4fdbb4cd9daec3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daa4501f7f434b9e9ce5a65e47f7fcfa",
            "placeholder": "​",
            "style": "IPY_MODEL_99a7c30d9de34c0f841deb66794ea0d9",
            "value": " 68/10000 [00:10&lt;24:53,  6.65it/s]"
          }
        },
        "750f19b39cfc4dcdbe180ba6dadcce95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354d9e5604814f33aac2ad0b0eac5546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "375274206e7c417c9108992159a4e332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc809a364aee46baa3625eb7aae7e083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63409c4d3cb049be8a626572be5be1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daa4501f7f434b9e9ce5a65e47f7fcfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a7c30d9de34c0f841deb66794ea0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This runs Morgan's model on full aligned pages.\n",
        "\n",
        "Original model from: https://github.com/jarobyte91/post_ocr_correction\n",
        "\n",
        "Our modifications live: https://github.com/ReadingTimeMachine/ocr_post_correction"
      ],
      "metadata": {
        "id": "aSkfXlMnkm4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MO5l9S5UgWOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c367bb84-fb20-4ba3-c3a0-30f440fb4217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gdrive/MyDrive/TPDL\\ 2023\\ Colab\\ Notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSLDd375huxl",
        "outputId": "73efe5d4-9e97-4b0b-a1ad-98ce952e1d78"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " byt5_models   mBART_models\t\t        train_byt5_ocr_full.ipynb\n",
            " data\t      'morgan training progress.gdoc'   train_mBART50_full.ipynb\n",
            " libraries     run_morgan_model.ipynb\t        train_mBART50_onlyOCR.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "restart_from_checkpoint = True # restart from checkpoint?\n",
        "\n",
        "# where is data?\n",
        "output_folder = 'gdrive/MyDrive/TPDL 2023 Colab Notebooks/data/morgan/' # colab\n",
        "\n",
        "#ender = '_small_words' # small has 100,000 for training, 5000 for dev\n",
        "ender = '_small_words_pageLevel'\n",
        "\n",
        "# model save dir\n",
        "model_save_dir = 'gdrive/MyDrive/TPDL 2023 Colab Notebooks/data/morgan/models/' # colab\n",
        "\n",
        "# its not 100% clear if we need this... setting a flag, but looks like we DO need it for memory issues\n",
        "use_train_dev_size = True\n",
        "train_size = 1000000\n",
        "dev_size = 10000\n",
        "window_length = 100"
      ],
      "metadata": {
        "id": "PC-058gahuPD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as tud\n",
        "import torch.nn as nn\n",
        "import pickle\n",
        "##from tqdm.notebook import tqdm # ?? overwritted below?\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import importlib\n",
        "import sys\n",
        "import pandas as pd\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "#from tqdm.auto import tqdm # overwrites above?\n",
        "import warnings"
      ],
      "metadata": {
        "id": "9Buq9DKngs1-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/jarobyte91/pytorch_beam_search.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozxPKeQnhO13",
        "outputId": "bef325e9-c802-483a-d6ee-166d640a815d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/jarobyte91/pytorch_beam_search.git\n",
            "  Cloning https://github.com/jarobyte91/pytorch_beam_search.git to /tmp/pip-req-build-ws17q60c\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jarobyte91/pytorch_beam_search.git /tmp/pip-req-build-ws17q60c\n",
            "  Resolved https://github.com/jarobyte91/pytorch_beam_search.git to commit 4f6c55d51556d731f3fff49d6032fe417de63c3f\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (2022.12.7)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (1.22.4)\n",
            "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2021.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (1.16.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (2.0.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.61.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (4.5.0)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from pytorch-beam-search==1.2.2) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->pytorch-beam-search==1.2.2) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->pytorch-beam-search==1.2.2) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->pytorch-beam-search==1.2.2) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->pytorch-beam-search==1.2.2) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->pytorch-beam-search==1.2.2) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->pytorch-beam-search==1.2.2) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->pytorch-beam-search==1.2.2) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->pytorch-beam-search==1.2.2) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->pytorch-beam-search==1.2.2) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->pytorch-beam-search==1.2.2) (16.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->pytorch-beam-search==1.2.2) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->pytorch-beam-search==1.2.2) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_beam_search.seq2seq import Transformer, beam_search"
      ],
      "metadata": {
        "id": "n-QJRLnjhUqV"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZ4huQ5EhYj6",
        "outputId": "a6661d6d-ac20-4450-e03b-1af938bfb3c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2i = pickle.load(open(output_folder + \"data/char2i_new_pages\"+ender+\".pkl\", \"rb\"))\n",
        "i2char = pickle.load(open(output_folder + \"data/i2char_new_pages\"+ender+\".pkl\", \"rb\"))"
      ],
      "metadata": {
        "id": "tVfaWB3FhfeB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if use_train_dev_size:\n",
        "    train_source = torch.load(output_folder + \"data/train_source_new_pages\"+ender+\".pt\")[:train_size].to(device)#add to custom data\n",
        "    train_target = torch.load(output_folder + \"data/train_target_new_pages\"+ender+\".pt\")[:train_size].to(device)\n",
        "else:\n",
        "    train_source = torch.load(output_folder + \"data/train_source_new_pages\"+ender+\".pt\").to(device)#add to custom data\n",
        "    train_target = torch.load(output_folder + \"data/train_target_new_pages\"+ender+\".pt\").to(device)\n",
        "    train_size = train_source.shape[0]#*train_source.shape[1] #?? maybe??\n",
        "\n",
        "train_source.shape, train_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njMrfObFiIP1",
        "outputId": "bdb357e7-0e1d-453c-da37-2d98eb136d9e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000000, 102]), torch.Size([1000000, 102]))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_train_dev_size:\n",
        "    dev_source = torch.load(output_folder + \"data/dev_source_new_pages\"+ender+\".pt\")[:dev_size].to(device)\n",
        "    dev_target = torch.load(output_folder + \"data/dev_target_new_pages\"+ender+\".pt\")[:dev_size].to(device)\n",
        "else:\n",
        "    dev_source = torch.load(output_folder + \"data/dev_source_new_pages\"+ender+\".pt\").to(device)\n",
        "    dev_target = torch.load(output_folder + \"data/dev_target_new_pages\"+ender+\".pt\").to(device)\n",
        "    dev_size = dev_source.shape[0]\n",
        "    \n",
        "dev_source.shape, dev_target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rirCtYswiY69",
        "outputId": "2ee277fb-8d22-4568-95fd-d087170f46ef"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10000, 102]), torch.Size([10000, 102]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module): \n",
        "    \"\"\"\n",
        "    A generic sequence-to-sequence model. All other sequence-to-sequence models should extend this class \n",
        "    with a __init__ and forward methods, in the same way as in normal PyTorch.\n",
        "    \"\"\"\n",
        "    def print_architecture(self):\n",
        "        \"\"\"\n",
        "        Displays the information about the model in standard output. \n",
        "        \"\"\"\n",
        "        for k in self.architecture.keys():\n",
        "            print(f\"{k.replace('_', ' ').capitalize()}: {self.architecture[k]}\")\n",
        "        print(f\"Trainable parameters: {sum([p.numel() for p in self.parameters()]):,}\")\n",
        "        print()\n",
        "\n",
        "    def fit(self,#train_loader, \n",
        "            X_train, \n",
        "            Y_train, \n",
        "            X_dev = None, \n",
        "            Y_dev = None, \n",
        "            batch_size = 100, \n",
        "            epochs = 5, \n",
        "            learning_rate = 10**-4, \n",
        "            weight_decay = 0, \n",
        "            progress_bar = 0, \n",
        "            save_path = None):\n",
        "        print(\"fit begins\")\n",
        "        best_dev_loss=float('inf')\n",
        "        best_epoch=float('inf')\n",
        "        \"\"\"\n",
        "        A generic training method with Adam and Cross Entropy.\n",
        "\n",
        "        Parameters\n",
        "        ----------    \n",
        "        X_train: LongTensor of shape (train_examples, train_input_length)\n",
        "            The input sequences of the training set.\n",
        "            \n",
        "        Y_train: LongTensor of shape (train_examples, train_output_length)\n",
        "            The output sequences of the training set.\n",
        "            \n",
        "        X_dev: LongTensor of shape (dev_examples, dev_input_length), optional\n",
        "            The input sequences for the development set.\n",
        "            \n",
        "        Y_train: LongTensor of shape (dev_examples, dev_output_length), optional\n",
        "            The output sequences for the development set.\n",
        "            \n",
        "        batch_size: int\n",
        "            The number of examples to process in each batch.\n",
        "\n",
        "        epochs: int\n",
        "            The number of epochs of the training process.\n",
        "            \n",
        "        learning_rate: float\n",
        "            The learning rate to use with Adam in the training process. \n",
        "            \n",
        "        weight_decay: float\n",
        "            The weight_decay parameter of Adam (L2 penalty), useful for regularizing models. For a deeper \n",
        "            documentation, go to https://pytorch.org/docs/stable/_modules/torch/optim/adam.html#Adam            \n",
        "\n",
        "        progress_bar: int\n",
        "            Shows a tqdm progress bar, useful for tracking progress with large tensors.\n",
        "            If equal to 0, no progress bar is shown. \n",
        "            If equal to 1, shows a bar with one step for every epoch.\n",
        "            If equal to 2, shows the bar when equal to 1 and also shows a bar with one step per batch for every epoch.\n",
        "            If equal to 3, shows the bars when equal to 2 and also shows a bar to track the progress of the evaluation\n",
        "            in the development set.\n",
        "            \n",
        "        save_path: string, optional\n",
        "            Path to save the .pt file containing the model parameters when the training ends.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        performance: Pandas DataFrame\n",
        "            DataFrame with the following columns: epoch, train_loss, train_error_rate, (optionally dev_loss and \n",
        "            dev_error_rate), minutes, learning_rate, weight_decay, model, encoder_embedding_dimension, \n",
        "            decoder_embedding_dimension, encoder_hidden_units, encoder_layers, decoder_hidden_units, decoder_layers, \n",
        "            dropout, parameters and one row for each of the epochs, containing information about the training process.\n",
        "        \"\"\"\n",
        "        assert X_train.shape[0] == Y_train.shape[0]\n",
        "        assert (X_dev is None and Y_dev is None) or (X_dev is not None and Y_dev is not None) \n",
        "        if (X_dev is not None and Y_dev is not None):\n",
        "            assert X_dev.shape[0] == Y_dev.shape[0]\n",
        "            dev = True\n",
        "        else:\n",
        "            dev = False\n",
        "            \n",
        "\n",
        "        train_dataset = tud.TensorDataset(X_train, Y_train)\n",
        "        train_loader = tud.DataLoader(train_dataset, batch_size = batch_size, shuffle = True)# make own class data loader to read in batches at a time\n",
        "    \n",
        "        criterion = nn.CrossEntropyLoss(ignore_index = 0)\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
        "        performance = []\n",
        "        start = timer()\n",
        "        epochs_iterator = range(1, epochs + 1)\n",
        "        if progress_bar > 0:\n",
        "            epochs_iterator = tqdm(epochs_iterator)\n",
        "            print(\"Training started\")\n",
        "        print(\"X_train.shape:\", X_train.shape)\n",
        "        print(\"Y_train.shape:\", Y_train.shape)\n",
        "        if dev:\n",
        "            print(\"X_dev.shape:\", X_dev.shape)\n",
        "            print(\"Y_dev.shape:\", Y_dev.shape)\n",
        "        print(f\"Epochs: {epochs:,}\\nLearning rate: {learning_rate}\\nWeight decay: {weight_decay}\")\n",
        "        header_1 = \"Epoch | Train                \"\n",
        "        header_2 = \"      | Loss     | Error Rate\"\n",
        "        rule = \"-\" * 29\n",
        "        if dev:\n",
        "            header_1 += \" | Development          \"\n",
        "            header_2 += \" | Loss     | Error Rate\"\n",
        "            rule += \"-\" * 24\n",
        "        header_1 += \" | Minutes\"\n",
        "        header_2 += \" |\"\n",
        "        rule += \"-\" * 10\n",
        "        print(header_1, header_2, rule, sep = \"\\n\")\n",
        "        for e in epochs_iterator:\n",
        "            #print('start epoch')\n",
        "            self.train()\n",
        "            losses = []\n",
        "            errors = []\n",
        "            sizes = []\n",
        "            train_iterator = train_loader\n",
        "            if progress_bar > 1:\n",
        "                train_iterator = tqdm(train_iterator)\n",
        "            for x, y in train_iterator:\n",
        "                # compute loss and backpropagate\n",
        "                probabilities = self.forward(x, y).transpose(1, 2)[:, :, :-1]\n",
        "                y = y[:, 1:]\n",
        "                loss = criterion(probabilities, y)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                # compute accuracy\n",
        "                predictions = probabilities.argmax(1)\n",
        "                batch_errors = (predictions != y)\n",
        "                # append the results\n",
        "                losses.append(loss.item())\n",
        "                errors.append(batch_errors.sum().item())\n",
        "                sizes.append(batch_errors.numel())\n",
        "                #print('end epoch')\n",
        "            train_loss = sum(losses) / len(losses)\n",
        "            train_error_rate = 100 * sum(errors) / sum(sizes)\n",
        "            t = (timer() - start) / 60\n",
        "            status_string = f\"{e:>5} | {train_loss:>8.4f} | {train_error_rate:>10.3f}\"\n",
        "            status = {\"epoch\":e,\n",
        "                      \"train_loss\": train_loss,\n",
        "                      \"train_error_rate\": train_error_rate}\n",
        "            if dev:\n",
        "                dev_loss, dev_error_rate = self.evaluate(X_dev, \n",
        "                                                         Y_dev, \n",
        "                                                         batch_size = batch_size, \n",
        "                                                         progress_bar = progress_bar > 2, \n",
        "                                                         criterion = criterion)\n",
        "                status_string += f\" | {dev_loss:>8.4f} | {dev_error_rate:>10.3f}\"\n",
        "                status.update({\"dev_loss\": dev_loss, \"dev_error_rate\": dev_error_rate})\n",
        "            status.update({\"training_minutes\": t,\n",
        "                           \"learning_rate\": learning_rate,\n",
        "                           \"weight_decay\": weight_decay})\n",
        "            performance.append(status)\n",
        "            if save_path is not None: \n",
        "                print(\"dev =\", dev)\n",
        "                print(\"e =\", e)\n",
        "                print(\"dev loss =\", dev_loss)\n",
        "                print(\"best dev loss =\", best_dev_loss)\n",
        "                #if (not dev) or (e < 2) or (dev_loss < min([p[\"dev_loss\"] for p in performance[:-1]])):\n",
        "                if (not dev) or (e < 2) or (dev_loss < best_dev_loss):\n",
        "                    torch.save(self.state_dict(), save_path)\n",
        "                    print(status)\n",
        "                    best_dev_loss = dev_loss\n",
        "                    print(\"save path =\", save_path)\n",
        "            status_string += f\" | {t:>7.1f}\"\n",
        "            print(status_string)\n",
        "        print()\n",
        "        return pd.concat((pd.DataFrame(performance), \n",
        "                          pd.DataFrame([self.architecture for i in performance])), axis = 1)\\\n",
        "               .drop(columns = [\"source_index\", \"target_index\"])\n",
        "    \n",
        "            \n",
        "    def evaluate(self, \n",
        "                 X, \n",
        "                 Y, \n",
        "                 criterion = nn.CrossEntropyLoss(), \n",
        "                 batch_size = 128, \n",
        "                 progress_bar = False):\n",
        "        \"\"\"\n",
        "        Evaluates the model on a dataset.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: LongTensor of shape (examples, input_length)\n",
        "            The input sequences of the dataset.\n",
        "            \n",
        "        Y: LongTensor of shape (examples, output_length)\n",
        "            The output sequences of the dataset.\n",
        "            \n",
        "        criterion: PyTorch module\n",
        "            The loss function to evalue the model on the dataset, has to be able to compare self.forward(X, Y) and Y\n",
        "            to produce a real number.\n",
        "            \n",
        "        batch_size: int\n",
        "            The batch size of the evaluation loop.\n",
        "            \n",
        "        progress_bar: bool\n",
        "            Shows a tqdm progress bar, useful for tracking progress with large tensors.\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        loss: float\n",
        "            The average of criterion across the whole dataset.\n",
        "            \n",
        "        error_rate: float\n",
        "            The step-by-step accuracy of the model across the whole dataset. Useful as a sanity check, as it should\n",
        "            go to zero as the loss goes to zero.\n",
        "            \n",
        "        \"\"\"\n",
        "        dataset = tud.TensorDataset(X, Y)\n",
        "        loader = tud.DataLoader(dataset, batch_size = batch_size)\n",
        "        self.eval()\n",
        "        losses = []\n",
        "        errors = []\n",
        "        sizes = []\n",
        "        with torch.no_grad():\n",
        "            iterator = iter(loader)\n",
        "            if progress_bar:\n",
        "                iterator = tqdm(iterator)\n",
        "            for batch in iterator:\n",
        "                x, y = batch\n",
        "                # compute loss\n",
        "                probabilities = self.forward(x, y).transpose(1, 2)[:, :, :-1]\n",
        "                y = y[:, 1:]\n",
        "                loss = criterion(probabilities, y)\n",
        "                # compute accuracy\n",
        "                predictions = probabilities.argmax(1)\n",
        "                batch_errors = (predictions != y)\n",
        "                # append the results\n",
        "                losses.append(loss.item())\n",
        "                errors.append(batch_errors.sum().item())\n",
        "                sizes.append(batch_errors.numel())\n",
        "            loss = sum(losses) / len(losses)\n",
        "            error_rate = 100 * sum(errors) / sum(sizes)\n",
        "        return loss, error_rate \n",
        "    \n",
        "class LSTM(Seq2Seq):\n",
        "    def __init__(self, \n",
        "                 source_index, \n",
        "                 target_index, \n",
        "                 encoder_embedding_dimension = 32,\n",
        "                 decoder_embedding_dimension = 32,\n",
        "                 encoder_hidden_units = 128, \n",
        "                 encoder_layers = 2,\n",
        "                 decoder_hidden_units = 128,\n",
        "                 decoder_layers = 2,\n",
        "                 dropout = 0.0):\n",
        "        \"\"\"\n",
        "        A standard Seq2Seq LSTM model as in 'Learning Phrase Representations using RNN Encoder-Decoder \n",
        "        for Statistical Machine Translation' by Cho et al. (2014). \n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        in_vocabulary: dictionary\n",
        "            Vocabulary with the index:token pairs for the inputs of the model.\n",
        "            \n",
        "        out_vocabulary: dictionary\n",
        "            Vocabulary with the token:index pairs for the outputs of the model.\n",
        "            \n",
        "        encoder_embedding_dimension: int\n",
        "            Dimension of the embeddings to feed into the encoder.\n",
        "            \n",
        "        decoder_embedding_dimension: int\n",
        "            Dimension of the embeddings to feed into the decoder.\n",
        "            \n",
        "        encoder_hidden_units: int\n",
        "            Hidden size of the encoder.\n",
        "            \n",
        "        encoder_layers: int\n",
        "            Hidden layers of the encoder.\n",
        "            \n",
        "        decoder_hidden_units: int\n",
        "            Hidden units of the decoder.\n",
        "            \n",
        "        decoder_layers: int\n",
        "            Hidden layers of the decoder.\n",
        "            \n",
        "        dropout: float between 0.0 and 1.0\n",
        "            Dropout rate to apply to whole model.\n",
        "        \"\"\"\n",
        "        self.source_index = source_index\n",
        "        self.target_index = target_index\n",
        "        super().__init__()\n",
        "        self.source_embeddings = nn.Embedding(len(source_index), encoder_embedding_dimension)\n",
        "        self.target_embeddings = nn.Embedding(len(target_index), decoder_embedding_dimension)\n",
        "        self.encoder_rnn = nn.LSTM(input_size = encoder_embedding_dimension, \n",
        "                                   hidden_size = encoder_hidden_units, \n",
        "                                   num_layers = encoder_layers,\n",
        "                                   dropout = dropout)\n",
        "        self.decoder_rnn = nn.LSTM(input_size = encoder_layers * encoder_hidden_units + decoder_embedding_dimension, \n",
        "                                   hidden_size = decoder_hidden_units, \n",
        "                                   num_layers = decoder_layers,\n",
        "                                   dropout = dropout)\n",
        "        self.output_layer = nn.Linear(decoder_hidden_units, len(target_index))\n",
        "        self.architecture = dict(model = \"Seq2Seq LSTM\",\n",
        "                                 source_index = source_index, \n",
        "                                 target_index = target_index, \n",
        "                                 encoder_embedding_dimension = encoder_embedding_dimension,\n",
        "                                 decoder_embedding_dimension = decoder_embedding_dimension,\n",
        "                                 encoder_hidden_units = encoder_hidden_units, \n",
        "                                 encoder_layers = encoder_layers,\n",
        "                                 decoder_hidden_units = decoder_hidden_units,\n",
        "                                 decoder_layers = decoder_layers,\n",
        "                                 dropout = dropout)\n",
        "        self.print_architecture()\n",
        "        \n",
        "    def forward(self, X, Y):\n",
        "        \"\"\"\n",
        "        Forward method of the model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: LongTensor of shape (batch_size, input_length)\n",
        "            Tensor of integers containing the inputs for the model.\n",
        "            \n",
        "        Y: LongTensor of shape (batch_size, output_length)\n",
        "            Tensor of integers containing the output produced so far.\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        output: FloatTensor of shape (batch_size, output_length, len(out_vocabulary))\n",
        "            Tensor of floats containing the inputs for the final Softmax layer (usually integrated into the loss function).\n",
        "        \"\"\"\n",
        "        X = self.source_embeddings(X.T)\n",
        "        encoder, (encoder_last_hidden, encoder_last_memory) = self.encoder_rnn(X)\n",
        "        encoder_last_hidden = encoder_last_hidden.transpose(0, 1).flatten(start_dim = 1)\n",
        "        encoder_last_hidden = encoder_last_hidden.repeat((Y.shape[1], 1, 1))\n",
        "        Y = self.target_embeddings(Y.T)\n",
        "        Y = torch.cat((Y, encoder_last_hidden), axis = -1)\n",
        "        decoder, (decoder_last_hidden, decoder_last_memory) = self.decoder_rnn(Y)\n",
        "        output = self.output_layer(decoder.transpose(0, 1))\n",
        "        return output        \n",
        "    \n",
        "    \n",
        "class ReversingLSTM(Seq2Seq):\n",
        "    def __init__(self, \n",
        "                 source_index, \n",
        "                 target_index, \n",
        "                 encoder_embedding_dimension = 32,\n",
        "                 decoder_embedding_dimension = 32,\n",
        "                 encoder_hidden_units = 128, \n",
        "                 encoder_layers = 2,\n",
        "                 decoder_hidden_units = 128,\n",
        "                 decoder_layers = 2,\n",
        "                 dropout = 0.0):\n",
        "        \"\"\"\n",
        "        A standard Seq2Seq LSTM model that reverses the order of the input as in \n",
        "        'Sequence to sequence learning with Neural Networks' by Sutskever et al. (2014). \n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        in_vocabulary: dictionary\n",
        "            Vocabulary with the index:token pairs for the inputs of the model.\n",
        "            \n",
        "        out_vocabulary: dictionary\n",
        "            Vocabulary with the token:index pairs for the outputs of the model.\n",
        "            \n",
        "        encoder_embedding_dimension: int\n",
        "            Dimension of the embeddings to feed into the encoder.\n",
        "            \n",
        "        decoder_embedding_dimension: int\n",
        "            Dimension of the embeddings to feed into the decoder.\n",
        "            \n",
        "        encoder_hidden_units: int\n",
        "            Hidden size of the encoder.\n",
        "            \n",
        "        encoder_layers: int\n",
        "            Hidden layers of the encoder.\n",
        "            \n",
        "        decoder_hidden_units: int\n",
        "            Hidden units of the decoder.\n",
        "            \n",
        "        decoder_layers: int\n",
        "            Hidden layers of the decoder.\n",
        "            \n",
        "        dropout: float between 0.0 and 1.0\n",
        "            Dropout rate to apply to whole model.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.source_index = source_index\n",
        "        self.target_index = target_index\n",
        "        self.source_embeddings = nn.Embedding(len(source_index), encoder_embedding_dimension)\n",
        "        self.target_embeddings = nn.Embedding(len(target_index), decoder_embedding_dimension)\n",
        "        self.encoder_rnn = nn.LSTM(input_size = encoder_embedding_dimension, \n",
        "                                   hidden_size = encoder_hidden_units, \n",
        "                                   num_layers = encoder_layers,\n",
        "                                   dropout = dropout)\n",
        "        self.decoder_rnn = nn.LSTM(input_size = decoder_embedding_dimension, \n",
        "                                   hidden_size = decoder_hidden_units, \n",
        "                                   num_layers = decoder_layers,\n",
        "                                   dropout = dropout)\n",
        "        self.output_layer = nn.Linear(decoder_hidden_units, len(target_index))\n",
        "        self.enc2dec = nn.Linear(encoder_hidden_units * encoder_layers, decoder_hidden_units * decoder_layers)\n",
        "        self.architecture = dict(model = \"Seq2Seq Reversing LSTM\",\n",
        "                                 source_index = source_index, \n",
        "                                 target_index = target_index, \n",
        "                                 encoder_embedding_dimension = encoder_embedding_dimension,\n",
        "                                 decoder_embedding_dimension = decoder_embedding_dimension,\n",
        "                                 encoder_hidden_units = encoder_hidden_units, \n",
        "                                 encoder_layers = encoder_layers,\n",
        "                                 decoder_hidden_units = decoder_hidden_units,\n",
        "                                 decoder_layers = decoder_layers,\n",
        "                                 dropout = dropout)\n",
        "        self.print_architecture()\n",
        "        \n",
        "    def forward(self, X, Y):\n",
        "        \"\"\"\n",
        "        Forward method of the model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: LongTensor of shape (batch_size, input_length)\n",
        "            Tensor of integers containing the inputs for the model.\n",
        "            \n",
        "        Y: LongTensor of shape (batch_size, output_length)\n",
        "            Tensor of integers containing the output produced so far.\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        output: FloatTensor of shape (batch_size, output_length, len(out_vocabulary))\n",
        "            Tensor of floats containing the inputs for the final Softmax layer (usually integrated into the loss function).\n",
        "        \"\"\"\n",
        "        X = self.source_embeddings(torch.flip(X.T, dims = (1, )))\n",
        "        encoder, (encoder_last_hidden, encoder_last_memory) = self.encoder_rnn(X)\n",
        "        encoder_last_hidden = encoder_last_hidden.transpose(0, 1).flatten(start_dim = 1)\n",
        "        enc2dec = self.enc2dec(encoder_last_hidden)\\\n",
        "        .reshape(-1, self.decoder_rnn.num_layers, self.decoder_rnn.hidden_size)\\\n",
        "        .transpose(0, 1)\\\n",
        "        .contiguous()\n",
        "        Y = self.target_embeddings(Y.T)\n",
        "        decoder, (decoder_last_hidden, decoder_last_memory) = self.decoder_rnn(Y, (enc2dec, torch.zeros_like(enc2dec)))\n",
        "        output = self.output_layer(decoder.transpose(0, 1))\n",
        "        return output\n",
        "    \n",
        "    \n",
        "class Transformer(Seq2Seq):\n",
        "    def __init__(self, \n",
        "                 source_index, \n",
        "                 target_index,\n",
        "                 max_sequence_length = 32,\n",
        "                 embedding_dimension = 32,\n",
        "                 feedforward_dimension = 128,\n",
        "                 encoder_layers = 2,\n",
        "                 decoder_layers = 2,\n",
        "                 attention_heads = 2,\n",
        "                 activation = \"relu\",\n",
        "                 dropout = 0.0):\n",
        "        \"\"\"\n",
        "        The standard PyTorch implementation of a Transformer model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        in_vocabulary: dictionary\n",
        "            Vocabulary with the index:token pairs for the inputs of the model.\n",
        "            \n",
        "        out_vocabulary: dictionary\n",
        "            Vocabulary with the token:index pairs for the outputs of the model.\n",
        "            \n",
        "        max_sequence_length: int\n",
        "            Maximum sequence length accepted by the model, both for the encoder and the decoder.\n",
        "            \n",
        "        embedding_dimension: int\n",
        "            Dimension of the embeddings of the model.\n",
        "            \n",
        "        feedforward_dimension: int\n",
        "            Dimension of the feedforward network inside the self-attention layers of the model.\n",
        "            \n",
        "        encoder_layers: int\n",
        "            Hidden layers of the encoder.\n",
        "            \n",
        "        decoder_layers: int\n",
        "            Hidden layers of the decoder.\n",
        "            \n",
        "        attention_heads: int\n",
        "            Attention heads inside every self-attention layer of the model.\n",
        "            \n",
        "        activation: string\n",
        "            Activation function of the feedforward network inside the self-attention layers of the model. Can\n",
        "            be either 'relu' or 'gelu'.\n",
        "            \n",
        "        dropout: float between 0.0 and 1.0\n",
        "            Dropout rate to apply to whole model.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.source_index = source_index\n",
        "        self.target_index = target_index\n",
        "        self.source_embeddings = nn.Embedding(len(source_index), embedding_dimension)\n",
        "        self.target_embeddings = nn.Embedding(len(target_index), embedding_dimension)\n",
        "        self.positional_embeddings = nn.Embedding(max_sequence_length, embedding_dimension)\n",
        "        self.transformer = nn.Transformer(d_model = embedding_dimension, \n",
        "                                          dim_feedforward = feedforward_dimension,\n",
        "                                          nhead = attention_heads, \n",
        "                                          num_encoder_layers = encoder_layers, \n",
        "                                          num_decoder_layers = decoder_layers,\n",
        "                                          activation = activation,\n",
        "                                          dropout = dropout)\n",
        "        self.output_layer = nn.Linear(embedding_dimension, len(target_index))\n",
        "        self.architecture = dict(model = \"Seq2Seq Transformer\",\n",
        "                                 source_index = source_index,\n",
        "                                 target_index = target_index,\n",
        "                                 max_sequence_length = max_sequence_length,\n",
        "                                 embedding_dimension = embedding_dimension,\n",
        "                                 feedforward_dimension = feedforward_dimension,\n",
        "                                 encoder_layers = encoder_layers,\n",
        "                                 decoder_layers = decoder_layers,\n",
        "                                 attention_heads = attention_heads,\n",
        "                                 activation = activation,\n",
        "                                 dropout = dropout)\n",
        "        self.print_architecture()\n",
        "        \n",
        "    def forward(self, X, Y):\n",
        "        \"\"\"\n",
        "        Forward method of the model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        X: LongTensor of shape (batch_size, input_length)\n",
        "            Tensor of integers containing the inputs for the model.\n",
        "            \n",
        "        Y: LongTensor of shape (batch_size, output_length)\n",
        "            Tensor of integers containing the output produced so far.\n",
        "            \n",
        "        Returns\n",
        "        -------\n",
        "        output: FloatTensor of shape (batch_size, output_length, len(out_vocabulary))\n",
        "            Tensor of floats containing the inputs for the final Softmax layer (usually integrated in the loss function).\n",
        "        \"\"\"\n",
        "        assert X.shape[1] <= self.architecture[\"max_sequence_length\"]\n",
        "        assert Y.shape[1] <= self.architecture[\"max_sequence_length\"]\n",
        "        X = self.source_embeddings(X)\n",
        "        X_positional = torch.arange(X.shape[1], device = X.device).repeat((X.shape[0], 1))\n",
        "        X_positional = self.positional_embeddings(X_positional)\n",
        "        X = (X + X_positional).transpose(0, 1)\n",
        "        Y = self.target_embeddings(Y)\n",
        "        Y_positional = torch.arange(Y.shape[1], device = Y.device).repeat((Y.shape[0], 1))\n",
        "        Y_positional = self.positional_embeddings(Y_positional)\n",
        "        Y = (Y + Y_positional).transpose(0, 1)\n",
        "        mask = self.transformer.generate_square_subsequent_mask(Y.shape[0]).to(Y.device)\n",
        "        transformer_output = self.transformer.forward(src = X,\n",
        "                                                      tgt = Y, \n",
        "                                                      tgt_mask = mask)\n",
        "        transformer_output = transformer_output.transpose(0, 1)\n",
        "        return self.output_layer(transformer_output)"
      ],
      "metadata": {
        "id": "pHAp-BquiY5B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.autonotebook import tqdm # overwrites above?"
      ],
      "metadata": {
        "id": "itVr5zYziY3C"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Transformer(char2i, \n",
        "                    i2char, \n",
        "                    max_sequence_length = 110,\n",
        "                    embedding_dimension = 512, #256,\n",
        "                    feedforward_dimension = 2048, #1024,\n",
        "                    attention_heads = 8,\n",
        "                    encoder_layers = 4,\n",
        "                    decoder_layers = 4,\n",
        "                   dropout = .5) # drop out not in orig\n",
        "print(\"model created\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDSKBMz9iY1G",
        "outputId": "965fe840-0512-4e8e-9004-49b7c047871c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Seq2Seq Transformer\n",
            "Source index: {'\\t': 3, ' ': 4, '!': 5, '\"': 6, '#': 7, '$': 8, '%': 9, '&': 10, \"'\": 11, '(': 12, ')': 13, '*': 14, '+': 15, ',': 16, '-': 17, '.': 18, '/': 19, '0': 20, '1': 21, '2': 22, '3': 23, '4': 24, '5': 25, '6': 26, '7': 27, '8': 28, '9': 29, ':': 30, ';': 31, '<': 32, '<UNK>': 33, '=': 34, '>': 35, '?': 36, '@': 37, 'A': 38, 'B': 39, 'C': 40, 'D': 41, 'E': 42, 'F': 43, 'G': 44, 'H': 45, 'I': 46, 'J': 47, 'K': 48, 'L': 49, 'M': 50, 'N': 51, 'O': 52, 'P': 53, 'Q': 54, 'R': 55, 'S': 56, 'T': 57, 'U': 58, 'V': 59, 'W': 60, 'X': 61, 'Y': 62, 'Z': 63, '[': 64, '\\\\': 65, ']': 66, '^': 67, '_': 68, '`': 69, 'a': 70, 'b': 71, 'c': 72, 'd': 73, 'e': 74, 'f': 75, 'g': 76, 'h': 77, 'i': 78, 'j': 79, 'k': 80, 'l': 81, 'm': 82, 'n': 83, 'o': 84, 'p': 85, 'q': 86, 'r': 87, 's': 88, 't': 89, 'u': 90, 'v': 91, 'w': 92, 'x': 93, 'y': 94, 'z': 95, '{': 96, '|': 97, '}': 98, '~': 99, '¡': 100, '¢': 101, '£': 102, '¥': 103, '§': 104, '©': 105, '«': 106, '®': 107, '¯': 108, '°': 109, '´': 110, 'µ': 111, '»': 112, 'À': 113, 'Á': 114, 'Â': 115, 'É': 116, 'Í': 117, 'Ó': 118, 'Ö': 119, 'Ü': 120, 'à': 121, 'á': 122, 'ä': 123, 'ç': 124, 'è': 125, 'é': 126, 'ê': 127, 'í': 128, 'î': 129, 'ó': 130, 'ô': 131, 'ö': 132, 'ü': 133, 'ć': 134, 'Č': 135, 'ğ': 136, 'İ': 137, 'ń': 138, 'ő': 139, 'ş': 140, 'š': 141, '̧': 142, '΄': 143, 'Έ': 144, 'Ί': 145, 'Ό': 146, 'Α': 147, 'Β': 148, 'Γ': 149, 'Δ': 150, 'Ε': 151, 'Ζ': 152, 'Η': 153, 'Θ': 154, 'Ι': 155, 'Κ': 156, 'Λ': 157, 'Μ': 158, 'Ν': 159, 'Ξ': 160, 'Ο': 161, 'Π': 162, 'Ρ': 163, 'Σ': 164, 'Τ': 165, 'Υ': 166, 'Φ': 167, 'Χ': 168, 'Ω': 169, 'ά': 170, 'έ': 171, 'ή': 172, 'ί': 173, 'α': 174, 'β': 175, 'γ': 176, 'δ': 177, 'ε': 178, 'ζ': 179, 'η': 180, 'θ': 181, 'ι': 182, 'κ': 183, 'λ': 184, 'μ': 185, 'ν': 186, 'ξ': 187, 'ο': 188, 'π': 189, 'ρ': 190, 'ς': 191, 'σ': 192, 'τ': 193, 'υ': 194, 'φ': 195, 'χ': 196, 'ω': 197, 'ϊ': 198, 'ό': 199, 'ύ': 200, 'ώ': 201, 'ϐ': 202, 'ϱ': 203, 'ἁ': 204, 'ἃ': 205, 'ἄ': 206, 'ἅ': 207, 'ἐ': 208, 'Ἐ': 209, 'Ἑ': 210, 'Ἠ': 211, 'Ἡ': 212, 'ἰ': 213, 'ἱ': 214, 'ἲ': 215, 'ἳ': 216, 'ἴ': 217, 'ἵ': 218, 'ἶ': 219, 'Ἰ': 220, 'Ἱ': 221, 'Ἴ': 222, 'ὁ': 223, 'ὃ': 224, 'ὅ': 225, 'Ὁ': 226, 'Ὃ': 227, 'ὐ': 228, 'ὓ': 229, 'Ὑ': 230, 'ὧ': 231, 'Ὦ': 232, 'ὰ': 233, 'ὲ': 234, 'ὶ': 235, 'ὸ': 236, 'ᾧ': 237, 'ῃ': 238, 'ῇ': 239, 'ῖ': 240, 'ῥ': 241, 'ῦ': 242, '–': 243, '—': 244, '‘': 245, '’': 246, '“': 247, '”': 248, '€': 249, '™': 250, '←': 251, '↑': 252, '↓': 253, '↔': 254, '↕': 255, '↖': 256, '↗': 257, '↘': 258, '↙': 259, '↛': 260, '↜': 261, '↝': 262, '↣': 263, '↥': 264, '↦': 265, '↧': 266, '↨': 267, '↩': 268, '↪': 269, '↭': 270, '↰': 271, '↱': 272, '↲': 273, '↳': 274, '↴': 275, '↵': 276, '↶': 277, '↷': 278, '↸': 279, '↻': 280, '↼': 281, '↽': 282, '↾': 283, '↿': 284, '⇀': 285, '⇁': 286, '⇂': 287, '⇄': 288, '⇈': 289, '⇉': 290, '⇍': 291, '⇖': 292, '⇜': 293, '⇠': 294, '⇡': 295, '⇣': 296, '⇤': 297, '⇪': 298, '∁': 299, '∃': 300, '∄': 301, '∆': 302, '∇': 303, '∍': 304, '∎': 305, '∏': 306, '∐': 307, '∑': 308, '−': 309, '∔': 310, '∕': 311, '∖': 312, '∙': 313, '∟': 314, '∠': 315, '∡': 316, '∢': 317, '∣': 318, '∥': 319, '∩': 320, '∪': 321, '∫': 322, '∱': 323, '∶': 324, '∷': 325, '∸': 326, '∺': 327, '∼': 328, '∿': 329, '≀': 330, '≈': 331, '≋': 332, '≍': 333, '≏': 334, '≐': 335, '≒': 336, '≓': 337, '≖': 338, '≚': 339, '≜': 340, '≝': 341, '≟': 342, '≣': 343, '≤': 344, '≥': 345, '≦': 346, '≧': 347, '≩': 348, '≯': 349, '≱': 350, '≳': 351, '≸': 352, '≺': 353, '≻': 354, '≼': 355, '≽': 356, '≿': 357, '⊀': 358, '⊂': 359, '⊃': 360, '⊇': 361, '⊈': 362, '⊏': 363, '⊐': 364, '⊓': 365, '⊔': 366, '⊖': 367, '⊜': 368, '⊟': 369, '⊡': 370, '⊣': 371, '⊤': 372, '⊥': 373, '⊪': 374, '⊰': 375, '⊱': 376, '⊲': 377, '⊳': 378, '⊺': 379, '⊻': 380, '⊼': 381, '⊽': 382, '⊾': 383, '⋀': 384, '⋁': 385, '⋂': 386, '⋃': 387, '⋅': 388, '⋆': 389, '⋈': 390, '⋉': 391, '⋋': 392, '⋎': 393, '⋏': 394, '⋔': 395, '⋖': 396, '⋗': 397, '⋚': 398, '⋜': 399, '⋝': 400, '⋞': 401, '⋟': 402, '⋠': 403, '⋡': 404, '⋤': 405, '⋪': 406, '⋮': 407, '⋯': 408, '⋰': 409, '⋱': 410, '<PAD>': 0, '<START>': 1, '<END>': 2}\n",
            "Target index: {3: '\\t', 4: ' ', 5: '!', 6: '\"', 7: '#', 8: '$', 9: '%', 10: '&', 11: \"'\", 12: '(', 13: ')', 14: '*', 15: '+', 16: ',', 17: '-', 18: '.', 19: '/', 20: '0', 21: '1', 22: '2', 23: '3', 24: '4', 25: '5', 26: '6', 27: '7', 28: '8', 29: '9', 30: ':', 31: ';', 32: '<', 33: '<UNK>', 34: '=', 35: '>', 36: '?', 37: '@', 38: 'A', 39: 'B', 40: 'C', 41: 'D', 42: 'E', 43: 'F', 44: 'G', 45: 'H', 46: 'I', 47: 'J', 48: 'K', 49: 'L', 50: 'M', 51: 'N', 52: 'O', 53: 'P', 54: 'Q', 55: 'R', 56: 'S', 57: 'T', 58: 'U', 59: 'V', 60: 'W', 61: 'X', 62: 'Y', 63: 'Z', 64: '[', 65: '\\\\', 66: ']', 67: '^', 68: '_', 69: '`', 70: 'a', 71: 'b', 72: 'c', 73: 'd', 74: 'e', 75: 'f', 76: 'g', 77: 'h', 78: 'i', 79: 'j', 80: 'k', 81: 'l', 82: 'm', 83: 'n', 84: 'o', 85: 'p', 86: 'q', 87: 'r', 88: 's', 89: 't', 90: 'u', 91: 'v', 92: 'w', 93: 'x', 94: 'y', 95: 'z', 96: '{', 97: '|', 98: '}', 99: '~', 100: '¡', 101: '¢', 102: '£', 103: '¥', 104: '§', 105: '©', 106: '«', 107: '®', 108: '¯', 109: '°', 110: '´', 111: 'µ', 112: '»', 113: 'À', 114: 'Á', 115: 'Â', 116: 'É', 117: 'Í', 118: 'Ó', 119: 'Ö', 120: 'Ü', 121: 'à', 122: 'á', 123: 'ä', 124: 'ç', 125: 'è', 126: 'é', 127: 'ê', 128: 'í', 129: 'î', 130: 'ó', 131: 'ô', 132: 'ö', 133: 'ü', 134: 'ć', 135: 'Č', 136: 'ğ', 137: 'İ', 138: 'ń', 139: 'ő', 140: 'ş', 141: 'š', 142: '̧', 143: '΄', 144: 'Έ', 145: 'Ί', 146: 'Ό', 147: 'Α', 148: 'Β', 149: 'Γ', 150: 'Δ', 151: 'Ε', 152: 'Ζ', 153: 'Η', 154: 'Θ', 155: 'Ι', 156: 'Κ', 157: 'Λ', 158: 'Μ', 159: 'Ν', 160: 'Ξ', 161: 'Ο', 162: 'Π', 163: 'Ρ', 164: 'Σ', 165: 'Τ', 166: 'Υ', 167: 'Φ', 168: 'Χ', 169: 'Ω', 170: 'ά', 171: 'έ', 172: 'ή', 173: 'ί', 174: 'α', 175: 'β', 176: 'γ', 177: 'δ', 178: 'ε', 179: 'ζ', 180: 'η', 181: 'θ', 182: 'ι', 183: 'κ', 184: 'λ', 185: 'μ', 186: 'ν', 187: 'ξ', 188: 'ο', 189: 'π', 190: 'ρ', 191: 'ς', 192: 'σ', 193: 'τ', 194: 'υ', 195: 'φ', 196: 'χ', 197: 'ω', 198: 'ϊ', 199: 'ό', 200: 'ύ', 201: 'ώ', 202: 'ϐ', 203: 'ϱ', 204: 'ἁ', 205: 'ἃ', 206: 'ἄ', 207: 'ἅ', 208: 'ἐ', 209: 'Ἐ', 210: 'Ἑ', 211: 'Ἠ', 212: 'Ἡ', 213: 'ἰ', 214: 'ἱ', 215: 'ἲ', 216: 'ἳ', 217: 'ἴ', 218: 'ἵ', 219: 'ἶ', 220: 'Ἰ', 221: 'Ἱ', 222: 'Ἴ', 223: 'ὁ', 224: 'ὃ', 225: 'ὅ', 226: 'Ὁ', 227: 'Ὃ', 228: 'ὐ', 229: 'ὓ', 230: 'Ὑ', 231: 'ὧ', 232: 'Ὦ', 233: 'ὰ', 234: 'ὲ', 235: 'ὶ', 236: 'ὸ', 237: 'ᾧ', 238: 'ῃ', 239: 'ῇ', 240: 'ῖ', 241: 'ῥ', 242: 'ῦ', 243: '–', 244: '—', 245: '‘', 246: '’', 247: '“', 248: '”', 249: '€', 250: '™', 251: '←', 252: '↑', 253: '↓', 254: '↔', 255: '↕', 256: '↖', 257: '↗', 258: '↘', 259: '↙', 260: '↛', 261: '↜', 262: '↝', 263: '↣', 264: '↥', 265: '↦', 266: '↧', 267: '↨', 268: '↩', 269: '↪', 270: '↭', 271: '↰', 272: '↱', 273: '↲', 274: '↳', 275: '↴', 276: '↵', 277: '↶', 278: '↷', 279: '↸', 280: '↻', 281: '↼', 282: '↽', 283: '↾', 284: '↿', 285: '⇀', 286: '⇁', 287: '⇂', 288: '⇄', 289: '⇈', 290: '⇉', 291: '⇍', 292: '⇖', 293: '⇜', 294: '⇠', 295: '⇡', 296: '⇣', 297: '⇤', 298: '⇪', 299: '∁', 300: '∃', 301: '∄', 302: '∆', 303: '∇', 304: '∍', 305: '∎', 306: '∏', 307: '∐', 308: '∑', 309: '−', 310: '∔', 311: '∕', 312: '∖', 313: '∙', 314: '∟', 315: '∠', 316: '∡', 317: '∢', 318: '∣', 319: '∥', 320: '∩', 321: '∪', 322: '∫', 323: '∱', 324: '∶', 325: '∷', 326: '∸', 327: '∺', 328: '∼', 329: '∿', 330: '≀', 331: '≈', 332: '≋', 333: '≍', 334: '≏', 335: '≐', 336: '≒', 337: '≓', 338: '≖', 339: '≚', 340: '≜', 341: '≝', 342: '≟', 343: '≣', 344: '≤', 345: '≥', 346: '≦', 347: '≧', 348: '≩', 349: '≯', 350: '≱', 351: '≳', 352: '≸', 353: '≺', 354: '≻', 355: '≼', 356: '≽', 357: '≿', 358: '⊀', 359: '⊂', 360: '⊃', 361: '⊇', 362: '⊈', 363: '⊏', 364: '⊐', 365: '⊓', 366: '⊔', 367: '⊖', 368: '⊜', 369: '⊟', 370: '⊡', 371: '⊣', 372: '⊤', 373: '⊥', 374: '⊪', 375: '⊰', 376: '⊱', 377: '⊲', 378: '⊳', 379: '⊺', 380: '⊻', 381: '⊼', 382: '⊽', 383: '⊾', 384: '⋀', 385: '⋁', 386: '⋂', 387: '⋃', 388: '⋅', 389: '⋆', 390: '⋈', 391: '⋉', 392: '⋋', 393: '⋎', 394: '⋏', 395: '⋔', 396: '⋖', 397: '⋗', 398: '⋚', 399: '⋜', 400: '⋝', 401: '⋞', 402: '⋟', 403: '⋠', 404: '⋡', 405: '⋤', 406: '⋪', 407: '⋮', 408: '⋯', 409: '⋰', 410: '⋱', 0: '<PAD>', 1: '<START>', 2: '<END>'}\n",
            "Max sequence length: 110\n",
            "Embedding dimension: 512\n",
            "Feedforward dimension: 2048\n",
            "Encoder layers: 4\n",
            "Decoder layers: 4\n",
            "Attention heads: 8\n",
            "Activation: relu\n",
            "Dropout: 0.5\n",
            "Trainable parameters: 30,115,739\n",
            "\n",
            "model created\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (source_embeddings): Embedding(411, 512)\n",
              "  (target_embeddings): Embedding(411, 512)\n",
              "  (positional_embeddings): Embedding(110, 512)\n",
              "  (transformer): Transformer(\n",
              "    (encoder): TransformerEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-3): 4 x TransformerEncoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.5, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.5, inplace=False)\n",
              "          (dropout2): Dropout(p=0.5, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): TransformerDecoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-3): 4 x TransformerDecoderLayer(\n",
              "          (self_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (multihead_attn): MultiheadAttention(\n",
              "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (dropout): Dropout(p=0.5, inplace=False)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (dropout1): Dropout(p=0.5, inplace=False)\n",
              "          (dropout2): Dropout(p=0.5, inplace=False)\n",
              "          (dropout3): Dropout(p=0.5, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (output_layer): Linear(in_features=512, out_features=411, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload from a saved model, if need be:"
      ],
      "metadata": {
        "id": "pbeWOOChYoyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if restart_from_checkpoint:\n",
        "    model.load_state_dict(torch.load(model_save_dir + \"new_torch_file_new_pages\"+ender+\".pt\", map_location=torch.device('cuda')))"
      ],
      "metadata": {
        "id": "yoTHFLu1Ynr0"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log = model.fit(train_source, \n",
        "                train_target,\n",
        "                #train_loader,\n",
        "                dev_source, \n",
        "                dev_target, \n",
        "                epochs = 50, \n",
        "                progress_bar = 2, \n",
        "                learning_rate = 10**-4,\n",
        "                save_path = model_save_dir + \"new_torch_file_new_pages\"+ender+\".pt\")\n",
        "print(\"model.fit completed\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295,
          "referenced_widgets": [
            "60ff4c915af94b0ab4cdfdb6d9fbf8f3",
            "ca3767834b7d407d9b953bdb7a3b7115",
            "44f65e4525e9453fad536f0a6713ce2f",
            "2ff46edf33384465b962a8e22b60d92e",
            "db5047880e164999ab24ef40ae44ad3c",
            "86c7b55ebfec4af6be920b093973bcf9",
            "3befbf5009b84740801627ee81c909a2",
            "5c19a1fb404b436cb4f34a3ae6d31762",
            "796828cb72a34bd08208a3241afa8682",
            "d0c1b3b082414d05a9ef57a20fdb0116",
            "457a1d49c53a41f0bb0d0ab100313f48",
            "0a9a6f7d4ac84e6ca4eff72b2efda1a3",
            "87c5c5236a5f4f6d9f8c09e352ed9370",
            "965787a884644f8aa2baaf03a9f77b20",
            "a47f5370b2814cecb4fdbb4cd9daec3e",
            "750f19b39cfc4dcdbe180ba6dadcce95",
            "354d9e5604814f33aac2ad0b0eac5546",
            "375274206e7c417c9108992159a4e332",
            "fc809a364aee46baa3625eb7aae7e083",
            "63409c4d3cb049be8a626572be5be1e3",
            "daa4501f7f434b9e9ce5a65e47f7fcfa",
            "99a7c30d9de34c0f841deb66794ea0d9"
          ]
        },
        "id": "58tr9RZ3iYyJ",
        "outputId": "826f5c57-26a7-42c9-ca10-475977bd8e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit begins\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60ff4c915af94b0ab4cdfdb6d9fbf8f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started\n",
            "X_train.shape: torch.Size([1000000, 102])\n",
            "Y_train.shape: torch.Size([1000000, 102])\n",
            "X_dev.shape: torch.Size([10000, 102])\n",
            "Y_dev.shape: torch.Size([10000, 102])\n",
            "Epochs: 50\n",
            "Learning rate: 0.0001\n",
            "Weight decay: 0\n",
            "Epoch | Train                 | Development           | Minutes\n",
            "      | Loss     | Error Rate | Loss     | Error Rate |\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a9a6f7d4ac84e6ca4eff72b2efda1a3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GOTUz8pfiYmE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}