{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1675029271460,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "RYwpkolCjbwf"
   },
   "source": [
    "## Use opence-v1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285506,
     "status": "ok",
     "timestamp": 1675029556960,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "l2uSZFDYBfUt",
    "outputId": "97d0eaeb-4e7c-4574-818b-33cefe253fe6"
   },
   "outputs": [],
   "source": [
    "#  # mount drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/', force_remount=True)\n",
    "# root_dir = \"/content/gdrive/MyDrive\"\n",
    "# # change the OS to use your project folder as the working directory\n",
    "# notebooks = \"/post_ocr_repository/post_ocr_correction/notebooks/en\"\n",
    "# import os\n",
    "# os.chdir(root_dir + notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HAL\n",
    "# file_dir = '/home/jnaiman/wwt_image_extraction/alignments/'\n",
    "# output_folder = '/home/jnaiman/data/morgan/'\n",
    "# # utils from local\n",
    "# from sys import path\n",
    "# path.append('/home/jnaiman/libraries/')\n",
    "# from utils_ocr_mini import align_texts_fast\n",
    "\n",
    "# local\n",
    "file_dir = '/Users/jnaiman/Dropbox/wwt_image_extraction/OCRPostCorrection/alignments/'\n",
    "output_folder = '/Users/jnaiman/Downloads/tmp/ocrpost/data/morgan/'\n",
    "from sys import path\n",
    "path.append('../scienceDigitization/text_mining_ocr_and_pdf/ocr_spell_check/')\n",
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import align_texts_fast, get_fill_in_types\n",
    "\n",
    "realign_dir = '/Users/jnaiman/Dropbox/wwt_image_extraction/OCRPostCorrection/ocr_pdf_aligned_sents_each_realign5/'\n",
    "\n",
    "\n",
    "ender = '_small_words_pageLevel'\n",
    "\n",
    "\n",
    "window_length = 100 # for subsetting the data\n",
    "\n",
    "npages_train = 1000\n",
    "npages_val = 250\n",
    "npages_test = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2267,
     "status": "ok",
     "timestamp": 1675029559224,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "Twat4cYVq7Wp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sys import path\n",
    "#path.append('/home/jnaiman/.local')\n",
    "\n",
    "from nltk.lm import Vocabulary\n",
    "#import sys\n",
    "#sys.path.append(\"../../lib\")\n",
    "#from metrics import levenshtein\n",
    "import pickle\n",
    "from glob import glob\n",
    "\n",
    "from Levenshtein import distance\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "import Levenshtein\n",
    "\n",
    "import time\n",
    "#from multiprocessing import Pool\n",
    "from multiprocess import Pool # not sure if this is needed only on the mac?\n",
    "\n",
    "\n",
    "# from importlib import reload\n",
    "# import utils_ocr_mini\n",
    "# reload(utils_ocr_mini)\n",
    "# from utils_ocr_mini import align_texts_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(x):\n",
    "    A, B, window_length = x\n",
    "    assert len(A) == len(B)\n",
    "    return [(A[i:i + window_length], B[i:i + window_length]) \n",
    "            for i in range(len(A) + 1)]\n",
    "\n",
    "def levenshtein(reference, hypothesis, progress_bar = False):\n",
    "    assert len(reference) == len(hypothesis)\n",
    "    text = zip(reference, hypothesis)\n",
    "    if progress_bar:\n",
    "        text = tqdm(text, total = len(reference))\n",
    "    d = [distance(r, h) for r, h in text]\n",
    "    output = pd.DataFrame({\"reference\":reference, \"hypothesis\":hypothesis})\\\n",
    "    .assign(distance = lambda df: d)\\\n",
    "    .assign(\n",
    "        cer = lambda df: df.apply(\n",
    "            lambda r: 100 * r[\"distance\"] / max(len(r[\"reference\"]), 1), \n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all data, format maybe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7857"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "align_files = glob(realign_dir + '*.pickle')\n",
    "len(align_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(npages, arts_save = [], pages_save = [], imod=1000):\n",
    "    # arts_save = []\n",
    "    # pages_save = []\n",
    "    train_pdf = []; train_ocr = []\n",
    "    pages_save_out = []; filenames = []\n",
    "    pdf_clean = []; ocr_clean = []\n",
    "    while len(train_pdf) < npages:\n",
    "        if len(train_pdf)%imod == 0:\n",
    "            print('on', len(train_pdf), 'of', npages)\n",
    "        i = np.random.randint(len(align_files))\n",
    "        with open(align_files[i],'rb') as f:\n",
    "            article = pickle.load(f)\n",
    "        page_keys = list(article.keys())\n",
    "        if len(page_keys) > 0:\n",
    "            j = np.random.randint(len(page_keys))\n",
    "            # check already in there\n",
    "            alreadyIn = False\n",
    "            if align_files[i].split('/')[-1].split('.pickle')[0] in arts_save:\n",
    "                ind = arts_save.index(align_files[i].split('/')[-1].split('.pickle')[0])\n",
    "                if page_keys[j] in pages_save: # also in there, correct one?\n",
    "                    if pages_save[ind] == page_keys[j]: # same index\n",
    "                        alreadyIn = True\n",
    "            if not alreadyIn:\n",
    "                arts_save.append(align_files[i].split('/')[-1].split('.pickle')[0])\n",
    "                pages_save.append(page_keys[j])\n",
    "                if article[page_keys[j]] != {}:\n",
    "                    train_pdf.append(article[page_keys[j]]['PDF'])\n",
    "                    # for formatting\n",
    "                    train_ocr.append(article[page_keys[j]]['OCR'].replace('^','@'))\n",
    "                    # also cleaned\n",
    "                    pdf_clean.append(article[page_keys[j]]['PDF'].replace('@',''))\n",
    "                    ocr_clean.append(article[page_keys[j]]['OCR'].replace('^',''))\n",
    "                    pages_save_out.append(page_keys[j])\n",
    "                    filenames.append(align_files[i].split('/')[-1].split('.pickle')[0])\n",
    "\n",
    "    train_df = pd.DataFrame({'gt':train_pdf, 'ocr':train_ocr, 'filename':filenames, \n",
    "                             'page':pages_save_out,\n",
    "                            'gt_clean':pdf_clean, 'ocr_clean':ocr_clean})\n",
    "    return train_df, arts_save, pages_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 1000\n"
     ]
    }
   ],
   "source": [
    "train_data, arts_save, pages_save = make_dataframe(npages_train,\n",
    "                                                   arts_save = [], pages_save = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 250\n",
      "on 0 of 250\n"
     ]
    }
   ],
   "source": [
    "val_data, arts_save, pages_save = make_dataframe(npages_val, \n",
    "                                                arts_save=arts_save.copy(),\n",
    "                                               pages_save=pages_save.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 0 of 250\n",
      "on 0 of 250\n",
      "on 0 of 250\n",
      "on 0 of 250\n",
      "on 0 of 250\n"
     ]
    }
   ],
   "source": [
    "test_data, arts_save, pages_save = make_dataframe(npages_test, \n",
    "                                                arts_save=arts_save.copy(),\n",
    "                                               pages_save=pages_save.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all together to for vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data,val_data,test_data],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>ocr</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>gt_clean</th>\n",
       "      <th>ocr_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>1111_1111.5432d_hatp13_psfilefixedRTM_hocr</td>\n",
       "      <td>page8</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>@ Finally. the accurate. observational determi...</td>\n",
       "      <td>1009_1009.1978d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>Finally. the accurate. observational determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>1007_1007.0493d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>0810_0810.0555d_11077aph_psfilefixedRTM_hocr</td>\n",
       "      <td>page4</td>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>1106_1106.1432d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  @ Finally. the accurate. observational determi...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                       filename   page  \\\n",
       "0    1111_1111.5432d_hatp13_psfilefixedRTM_hocr  page8   \n",
       "1        1009_1009.1978d_ms_psfilefixedRTM_hocr  page1   \n",
       "2        1007_1007.0493d_ms_psfilefixedRTM_hocr  page1   \n",
       "3  0810_0810.0555d_11077aph_psfilefixedRTM_hocr  page4   \n",
       "4        1106_1106.1432d_ms_psfilefixedRTM_hocr  page1   \n",
       "\n",
       "                                            gt_clean  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                           ocr_clean  \n",
       "0  The HAT-P-13 system is unusual in that a trans...  \n",
       "1   Finally. the accurate. observational determin...  \n",
       "2  galaxies. BECs are known to have positive colo...  \n",
       "3  where with are the deusity fractions of each m...  \n",
       "4  resolution EVLA observations. We use a concord...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take out any weirdos\n",
    "mask = (pd.isnull(data['gt'])) | (pd.isnull(data['ocr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>ocr</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>gt_clean</th>\n",
       "      <th>ocr_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>1111_1111.5432d_hatp13_psfilefixedRTM_hocr</td>\n",
       "      <td>page8</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>@ Finally. the accurate. observational determi...</td>\n",
       "      <td>1009_1009.1978d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "      <td>Finally. the accurate. observational determin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>1007_1007.0493d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>0810_0810.0555d_11077aph_psfilefixedRTM_hocr</td>\n",
       "      <td>page4</td>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>1106_1106.1432d_ms_psfilefixedRTM_hocr</td>\n",
       "      <td>page1</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  gt  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                                 ocr  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  @ Finally. the accurate. observational determi...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                       filename   page  \\\n",
       "0    1111_1111.5432d_hatp13_psfilefixedRTM_hocr  page8   \n",
       "1        1009_1009.1978d_ms_psfilefixedRTM_hocr  page1   \n",
       "2        1007_1007.0493d_ms_psfilefixedRTM_hocr  page1   \n",
       "3  0810_0810.0555d_11077aph_psfilefixedRTM_hocr  page4   \n",
       "4        1106_1106.1432d_ms_psfilefixedRTM_hocr  page1   \n",
       "\n",
       "                                            gt_clean  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  . Finally, the accurate, observational determi...   \n",
       "2  galaxies. BEGs are known to have positive colo...   \n",
       "3  where with are the density fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                           ocr_clean  \n",
       "0  The HAT-P-13 system is unusual in that a trans...  \n",
       "1   Finally. the accurate. observational determin...  \n",
       "2  galaxies. BECs are known to have positive colo...  \n",
       "3  where with are the deusity fractions of each m...  \n",
       "4  resolution EVLA observations. We use a concord...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename with equivalents for the original OCR method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.rename(columns={\"sentences source\": \"ocr_aligned\", \n",
    "#                         \"sentences target\": \"gs_aligned\"})\n",
    "\n",
    "data = data.rename(columns={'ocr_clean':\"ocr_to_input\", \n",
    "                            'ocr': \"ocr_aligned\",\n",
    "                            'gt':\"gs_aligned\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_to_input</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "      <td>The HAT-P-13 system is unusual in that a trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finally. the accurate. observational determin...</td>\n",
       "      <td>@ Finally. the accurate. observational determi...</td>\n",
       "      <td>. Finally, the accurate, observational determi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>galaxies. BECs are known to have positive colo...</td>\n",
       "      <td>galaxies. BEGs are known to have positive colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>where with are the deusity fractions of each m...</td>\n",
       "      <td>where with are the density fractions of each m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "      <td>resolution EVLA observations. We use a concord...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ocr_to_input  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1   Finally. the accurate. observational determin...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                         ocr_aligned  \\\n",
       "0  The HAT-P-13 system is unusual in that a trans...   \n",
       "1  @ Finally. the accurate. observational determi...   \n",
       "2  galaxies. BECs are known to have positive colo...   \n",
       "3  where with are the deusity fractions of each m...   \n",
       "4  resolution EVLA observations. We use a concord...   \n",
       "\n",
       "                                          gs_aligned  \n",
       "0  The HAT-P-13 system is unusual in that a trans...  \n",
       "1  . Finally, the accurate, observational determi...  \n",
       "2  galaxies. BEGs are known to have positive colo...  \n",
       "3  where with are the density fractions of each m...  \n",
       "4  resolution EVLA observations. We use a concord...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['ocr_to_input','ocr_aligned', 'gs_aligned']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_to_input</th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3014.155333</td>\n",
       "      <td>3041.941333</td>\n",
       "      <td>3041.941333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1585.452724</td>\n",
       "      <td>1600.632865</td>\n",
       "      <td>1600.632865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1872.250000</td>\n",
       "      <td>1892.750000</td>\n",
       "      <td>1892.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2866.500000</td>\n",
       "      <td>2897.500000</td>\n",
       "      <td>2897.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4131.250000</td>\n",
       "      <td>4177.500000</td>\n",
       "      <td>4177.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7114.000000</td>\n",
       "      <td>8625.000000</td>\n",
       "      <td>8625.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_to_input  ocr_aligned   gs_aligned\n",
       "count   1500.000000  1500.000000  1500.000000\n",
       "mean    3014.155333  3041.941333  3041.941333\n",
       "std     1585.452724  1600.632865  1600.632865\n",
       "min        1.000000     1.000000     1.000000\n",
       "25%     1872.250000  1892.750000  1892.750000\n",
       "50%     2866.500000  2897.500000  2897.500000\n",
       "75%     4131.250000  4177.500000  4177.500000\n",
       "max     7114.000000  8625.000000  8625.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['ocr_to_input','ocr_aligned', 'gs_aligned']].applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1500.000000\n",
       "mean        5.413870\n",
       "std         6.446605\n",
       "min         0.000000\n",
       "25%         2.402198\n",
       "50%         4.319378\n",
       "75%         6.750639\n",
       "max        88.208617\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = data.gs_aligned.str.replace(\"@\", \"\"), \n",
    "            hypothesis = data.ocr_to_input).cer.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1500.000000\n",
       "mean        5.235680\n",
       "std         5.824194\n",
       "min         0.000000\n",
       "25%         2.370930\n",
       "50%         4.249685\n",
       "75%         6.629447\n",
       "max        83.165217\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = data.gs_aligned, \n",
    "            hypothesis = data.ocr_aligned).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    250.000000\n",
       "mean       6.048617\n",
       "std        8.439131\n",
       "min        0.000000\n",
       "25%        2.599628\n",
       "50%        4.564981\n",
       "75%        7.002886\n",
       "max       83.165217\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try with just test dataset:\n",
    "#data = pd.concat([train_data,val_data,test_data],ignore_index=True)\n",
    "levenshtein(reference = data.iloc[-len(test_data):].gs_aligned.replace(\"@\",\"\"), \n",
    "            hypothesis = data.iloc[-len(test_data):].ocr_aligned.replace(\"@\",\"\")).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gt</th>\n",
       "      <th>ocr</th>\n",
       "      <th>filename</th>\n",
       "      <th>page</th>\n",
       "      <th>gt_clean</th>\n",
       "      <th>ocr_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Define A@:= Since a complement space to the im...</td>\n",
       "      <td>Define AA:= Since a complement space to the im...</td>\n",
       "      <td>1112_1112.2544d_1112.2544_psfilefixedRTM_hocr</td>\n",
       "      <td>page6</td>\n",
       "      <td>Define A:= Since a complement space to the ima...</td>\n",
       "      <td>Define AA:= Since a complement space to the im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In van den Bergh (2009) it was speculated that...</td>\n",
       "      <td>In van den Bereh (2009) it was speculated that...</td>\n",
       "      <td>0907_0907.3715d_0907.3715_psfilefixedRTM_hocr</td>\n",
       "      <td>page5</td>\n",
       "      <td>In van den Bergh (2009) it was speculated that...</td>\n",
       "      <td>In van den Bereh (2009) it was speculated that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "      <td>1003_1003.4211d_boosting_psfilefixedRTM_hocr</td>\n",
       "      <td>page11</td>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "      <td>noise due to the low number density of galaxie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "      <td>0709_0709.1336d_paper_rev3_aph_psfilefixedRTM_...</td>\n",
       "      <td>page0</td>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "      <td>X-ray observations with the observatory have e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strong O band, however. Methane shows only one...</td>\n",
       "      <td>strong @ band. however. Methane shows only one...</td>\n",
       "      <td>0310_astro-ph0310805d_saumon_psfilefixedRTM_hocr</td>\n",
       "      <td>page3</td>\n",
       "      <td>strong O band, however. Methane shows only one...</td>\n",
       "      <td>strong  band. however. Methane shows only one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>motions one can estimate, e.g., the expected m...</td>\n",
       "      <td>motions one can estimate. e.g.. the expected m...</td>\n",
       "      <td>1011_1011.4816d_15641_psfilefixedRTM_hocr</td>\n",
       "      <td>page6</td>\n",
       "      <td>motions one can estimate, e.g., the expected m...</td>\n",
       "      <td>motions one can estimate. e.g.. the expected m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>numerous in our star sample (15381 stars), it ...</td>\n",
       "      <td>numerous in our star sample (15381 stars). it ...</td>\n",
       "      <td>0512_astro-ph0512352d_ngc7789_exp_psfilefixedR...</td>\n",
       "      <td>page7</td>\n",
       "      <td>numerous in our star sample (15381 stars), it ...</td>\n",
       "      <td>numerous in our star sample (15381 stars). it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "      <td>1008_1008.2986d_nsc_psfilefixedRTM_hocr</td>\n",
       "      <td>page2</td>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "      <td>we summarize our main conclusions. We assume t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "      <td>1111_1111.4270d_FCamiloJ2030+3641_psfilefixedR...</td>\n",
       "      <td>page4</td>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "      <td>RVM sign convention problem The phase of maxim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>= 9pt = 9pt</td>\n",
       "      <td>| Opt = 9pt</td>\n",
       "      <td>9903_astro-ph9903137d_buris98_psfilefixedRTM_hocr</td>\n",
       "      <td>page3</td>\n",
       "      <td>= 9pt = 9pt</td>\n",
       "      <td>| Opt = 9pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    gt  \\\n",
       "0    Define A@:= Since a complement space to the im...   \n",
       "1    In van den Bergh (2009) it was speculated that...   \n",
       "2    noise due to the low number density of galaxie...   \n",
       "3    X-ray observations with the observatory have e...   \n",
       "4    strong O band, however. Methane shows only one...   \n",
       "..                                                 ...   \n",
       "245  motions one can estimate, e.g., the expected m...   \n",
       "246  numerous in our star sample (15381 stars), it ...   \n",
       "247  we summarize our main conclusions. We assume t...   \n",
       "248  RVM sign convention problem The phase of maxim...   \n",
       "249                                       = 9pt = 9pt    \n",
       "\n",
       "                                                   ocr  \\\n",
       "0    Define AA:= Since a complement space to the im...   \n",
       "1    In van den Bereh (2009) it was speculated that...   \n",
       "2    noise due to the low number density of galaxie...   \n",
       "3    X-ray observations with the observatory have e...   \n",
       "4    strong @ band. however. Methane shows only one...   \n",
       "..                                                 ...   \n",
       "245  motions one can estimate. e.g.. the expected m...   \n",
       "246  numerous in our star sample (15381 stars). it ...   \n",
       "247  we summarize our main conclusions. We assume t...   \n",
       "248  RVM sign convention problem The phase of maxim...   \n",
       "249                                       | Opt = 9pt    \n",
       "\n",
       "                                              filename    page  \\\n",
       "0        1112_1112.2544d_1112.2544_psfilefixedRTM_hocr   page6   \n",
       "1        0907_0907.3715d_0907.3715_psfilefixedRTM_hocr   page5   \n",
       "2         1003_1003.4211d_boosting_psfilefixedRTM_hocr  page11   \n",
       "3    0709_0709.1336d_paper_rev3_aph_psfilefixedRTM_...   page0   \n",
       "4     0310_astro-ph0310805d_saumon_psfilefixedRTM_hocr   page3   \n",
       "..                                                 ...     ...   \n",
       "245          1011_1011.4816d_15641_psfilefixedRTM_hocr   page6   \n",
       "246  0512_astro-ph0512352d_ngc7789_exp_psfilefixedR...   page7   \n",
       "247            1008_1008.2986d_nsc_psfilefixedRTM_hocr   page2   \n",
       "248  1111_1111.4270d_FCamiloJ2030+3641_psfilefixedR...   page4   \n",
       "249  9903_astro-ph9903137d_buris98_psfilefixedRTM_hocr   page3   \n",
       "\n",
       "                                              gt_clean  \\\n",
       "0    Define A:= Since a complement space to the ima...   \n",
       "1    In van den Bergh (2009) it was speculated that...   \n",
       "2    noise due to the low number density of galaxie...   \n",
       "3    X-ray observations with the observatory have e...   \n",
       "4    strong O band, however. Methane shows only one...   \n",
       "..                                                 ...   \n",
       "245  motions one can estimate, e.g., the expected m...   \n",
       "246  numerous in our star sample (15381 stars), it ...   \n",
       "247  we summarize our main conclusions. We assume t...   \n",
       "248  RVM sign convention problem The phase of maxim...   \n",
       "249                                       = 9pt = 9pt    \n",
       "\n",
       "                                             ocr_clean  \n",
       "0    Define AA:= Since a complement space to the im...  \n",
       "1    In van den Bereh (2009) it was speculated that...  \n",
       "2    noise due to the low number density of galaxie...  \n",
       "3    X-ray observations with the observatory have e...  \n",
       "4    strong  band. however. Methane shows only one ...  \n",
       "..                                                 ...  \n",
       "245  motions one can estimate. e.g.. the expected m...  \n",
       "246  numerous in our star sample (15381 stars). it ...  \n",
       "247  we summarize our main conclusions. We assume t...  \n",
       "248  RVM sign convention problem The phase of maxim...  \n",
       "249                                       | Opt = 9pt   \n",
       "\n",
       "[250 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408\n",
      "time delta = 1.479722023010254 seconds, or 0.024662033716837565 minutes, or 0.0004110338952806261 hours\n"
     ]
    }
   ],
   "source": [
    "rerun_vocab = False\n",
    "\n",
    "if rerun_vocab:\n",
    "    start_time = time.time()\n",
    "    vocabulary = Vocabulary(data.ocr_to_input.sum() + data.ocr_aligned.sum() + data.gs_aligned.sum())\n",
    "    print(len(vocabulary))\n",
    "    with open(output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\", \"wb\") as file:\n",
    "        pickle.dump(vocabulary, file)\n",
    "    end_time = time.time()\n",
    "    print('time delta =', end_time-start_time, 'seconds, or', \n",
    "          (end_time-start_time)/60., 'minutes, or',\n",
    "         (end_time-start_time)/60./60., 'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_rename(datain):\n",
    "    mask = (pd.isnull(datain['gt'])) | (pd.isnull(datain['ocr']))\n",
    "    # datain = datain.rename(columns={'words source':\"ocr_to_input\", \n",
    "    #                             'words source aligned': \"ocr_aligned\",\n",
    "    #                             'words target aligned':\"gs_aligned\"})\n",
    "    datain = datain.rename(columns={'ocr_clean':\"ocr_to_input\", \n",
    "                            'ocr': \"ocr_aligned\",\n",
    "                            'gt':\"gs_aligned\"})\n",
    "    return datain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.to_pickle(output_folder+\"/data/train_new_pages\"+ender+\".pkl\")\n",
    "# train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format and save training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mask_rename(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfd9879429340809ae41636836b68af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c78bba31f864b3aaf59475663085c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3041135, 2)\n",
      "total time = 7.2342798709869385 seconds, or 0.12057133118311564 minutes\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with Pool(4) as p:\n",
    "    train_aligned = list(p.imap_unordered(create_windows, \n",
    "                                          tqdm(zip(train_data.ocr_aligned, \n",
    "                                                   train_data.gs_aligned, \n",
    "                                                   [window_length for x in train_data.ocr_aligned]), \n",
    "                                               total = len(train_data.ocr_aligned)),\n",
    "                                          chunksize = 128))\n",
    "s = []\n",
    "for r in tqdm(train_aligned):\n",
    "    s.extend(r)\n",
    "train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "print(train_aligned.shape)\n",
    "train_aligned.head()\n",
    "end_time = time.time()\n",
    "print('total time =', end_time-start_time, 'seconds, or', (end_time-start_time)/60., 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In this section we discuss the effects of clus...</td>\n",
       "      <td>In this section we discuss the effects of clus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n this section we discuss the effects of clust...</td>\n",
       "      <td>n this section we discuss the effects of clust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this section we discuss the effects of cluste...</td>\n",
       "      <td>this section we discuss the effects of cluste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this section we discuss the effects of cluster...</td>\n",
       "      <td>this section we discuss the effects of cluster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>his section we discuss the effects of cluster ...</td>\n",
       "      <td>his section we discuss the effects of cluster ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  In this section we discuss the effects of clus...   \n",
       "1  n this section we discuss the effects of clust...   \n",
       "2   this section we discuss the effects of cluste...   \n",
       "3  this section we discuss the effects of cluster...   \n",
       "4  his section we discuss the effects of cluster ...   \n",
       "\n",
       "                                              target  \n",
       "0  In this section we discuss the effects of clus...  \n",
       "1  n this section we discuss the effects of clust...  \n",
       "2   this section we discuss the effects of cluste...  \n",
       "3  this section we discuss the effects of cluster...  \n",
       "4  his section we discuss the effects of cluster ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aligned = train_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"data/train_aligned_new_pages\"+ender+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For dev:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = mask_rename(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(766032, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  total contribution of these two populations re...   \n",
       "1  otal contribution of these two populations res...   \n",
       "2  tal contribution of these two populations resu...   \n",
       "3  al contribution of these two populations resul...   \n",
       "4  l contribution of these two populations result...   \n",
       "\n",
       "                                              target  \n",
       "0  total contribution of these two populations re...  \n",
       "1  otal contribution of these two populations res...  \n",
       "2  tal contribution of these two populations resu...  \n",
       "3  al contribution of these two populations resul...  \n",
       "4  l contribution of these two populations result...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = val_data.apply(lambda r: create_windows((r[\"ocr_aligned\"], r[\"gs_aligned\"], window_length)), \n",
    "                            axis = 1).sum()\n",
    "dev_aligned = pd.DataFrame(dev_aligned, columns = [\"source\", \"target\"])\n",
    "print(dev_aligned.shape)\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "      <td>total contribution of these two populations re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "      <td>otal contribution of these two populations res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "      <td>tal contribution of these two populations resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "      <td>al contribution of these two populations resul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "      <td>l contribution of these two populations result...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  total contribution of these two populations re...   \n",
       "1  otal contribution of these two populations res...   \n",
       "2  tal contribution of these two populations resu...   \n",
       "3  al contribution of these two populations resul...   \n",
       "4  l contribution of these two populations result...   \n",
       "\n",
       "                                              target  \n",
       "0  total contribution of these two populations re...  \n",
       "1  otal contribution of these two populations res...  \n",
       "2  tal contribution of these two populations resu...  \n",
       "3  al contribution of these two populations resul...  \n",
       "4  l contribution of these two populations result...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_aligned.to_pickle(output_folder+\"data/dev_aligned_new_pages\"+ender+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------ HERE ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun_vocab = False\n",
    "\n",
    "# if rerun_vocab:\n",
    "#     start_time = time.time()\n",
    "#     #vocabulary = Vocabulary(data[~mask].ocr_aligned.sum() + data[~mask].gs_aligned.sum())\n",
    "#     vocabulary = Vocabulary(data[~mask]['words source'].sum() + data[~mask]['words target'].sum())\n",
    "#     print(len(vocabulary))\n",
    "#     with open(output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\", \"wb\") as file:\n",
    "#         pickle.dump(vocabulary, file)\n",
    "#     end_time = time.time()\n",
    "#     print('time delta =', end_time-start_time, 'seconds, or', \n",
    "#           (end_time-start_time)/60., 'minutes, or',\n",
    "#          (end_time-start_time)/60./60., 'hours')\n",
    "#     # last run:\n",
    "#     #time delta = 11285.80526137352 seconds, 188.09675435622532 minutes, ~3.3 hours on HAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create windowed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in only the training data and do stuff with that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv(file_dir + train_file)\n",
    "\n",
    "# train = train.rename(columns={\"sentences source\": \"ocr_aligned\", \n",
    "#                         \"sentences target\": \"gs_aligned\"})\n",
    "\n",
    "#mask = (pd.isnull(train['ocr_aligned'])) | (pd.isnull(train['gs_aligned']))\n",
    "#mask = (pd.isnull(train['sentences source'])) | (pd.isnull(train['sentences target']))\n",
    "mask = (pd.isnull(train_data['words source'])) | (pd.isnull(train_data['words target']))\n",
    "\n",
    "train_data = train_data[~mask]\n",
    "\n",
    "# now align\n",
    "gs_aligned = []; ocr_aligned = []\n",
    "gs = []; ocr = []\n",
    "for o,p in zip(train_data['words source'].values, train_data['words target'].values):\n",
    "    eops = Levenshtein.editops(o, p)\n",
    "    ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "    gs_aligned.append(pdf_text_aligned)\n",
    "    # futze with ocr aligned so it matches data input\n",
    "    ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "    ocr_aligned.append(ocr_text_aligned)\n",
    "    gs.append(pdf_text_aligned.replace('@',''))\n",
    "    ocr.append(ocr_text_aligned.replace('@',''))\n",
    "    \n",
    "train_data['gs_aligned'] = gs_aligned\n",
    "train_data['ocr_aligned'] = ocr_aligned\n",
    "train_data['gs'] = gs\n",
    "train_data['ocr'] = ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (pd.isnull(val_data['words source'])) | (pd.isnull(val_data['words target']))\n",
    "\n",
    "val_data = val_data[~mask]\n",
    "\n",
    "# now align\n",
    "gs_aligned = []; ocr_aligned = []\n",
    "gs = []; ocr = []\n",
    "for o,p in zip(val_data['words source'].values, val_data['words target'].values):\n",
    "    eops = Levenshtein.editops(o, p)\n",
    "    ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "    gs_aligned.append(pdf_text_aligned)\n",
    "    # futze with ocr aligned so it matches data input\n",
    "    ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "    ocr_aligned.append(ocr_text_aligned)\n",
    "    gs.append(pdf_text_aligned.replace('@',''))\n",
    "    ocr.append(ocr_text_aligned.replace('@',''))\n",
    "    \n",
    "val_data['gs_aligned'] = gs_aligned\n",
    "val_data['ocr_aligned'] = ocr_aligned\n",
    "val_data['gs'] = gs\n",
    "val_data['ocr'] = ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (pd.isnull(test_data['words source'])) | (pd.isnull(test_data['words target']))\n",
    "\n",
    "test_data = test_data[~mask]\n",
    "\n",
    "# now align\n",
    "gs_aligned = []; ocr_aligned = []\n",
    "gs = []; ocr = []\n",
    "for o,p in zip(test_data['words source'].values, test_data['words target'].values):\n",
    "    eops = Levenshtein.editops(o, p)\n",
    "    ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "    gs_aligned.append(pdf_text_aligned)\n",
    "    # futze with ocr aligned so it matches data input\n",
    "    ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "    ocr_aligned.append(ocr_text_aligned)\n",
    "    gs.append(pdf_text_aligned.replace('@',''))\n",
    "    ocr.append(ocr_text_aligned.replace('@',''))\n",
    "    \n",
    "test_data['gs_aligned'] = gs_aligned\n",
    "test_data['ocr_aligned'] = ocr_aligned\n",
    "test_data['gs'] = gs\n",
    "test_data['ocr'] = ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([train_data,val_data,test_data],ignore_index=True)\n",
    "\n",
    "# data['ocr'].iloc[:10].sum() + data['gs'].iloc[:10].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n",
      "time delta = 145.02771306037903 seconds, or 2.417128551006317 minutes, or 0.040285475850105286 hours\n"
     ]
    }
   ],
   "source": [
    "rerun_vocab = False\n",
    "\n",
    "if rerun_vocab:\n",
    "    data = pd.concat([train_data,val_data,test_data],ignore_index=True)\n",
    "    start_time = time.time()\n",
    "    #vocabulary = Vocabulary(data[~mask].ocr_aligned.sum() + data[~mask].gs_aligned.sum())\n",
    "    #vocabulary = Vocabulary(data[~mask]['ocr'].sum() + data[~mask]['gs'].sum())\n",
    "    vocabulary = Vocabulary(data['ocr'].sum() + data['gs'].sum() + '@')\n",
    "    print(len(vocabulary))\n",
    "    with open(output_folder+\"data/vocabulary_new_pages_new\"+ender+\".pkl\", \"wb\") as file:\n",
    "        pickle.dump(vocabulary, file)\n",
    "    end_time = time.time()\n",
    "    print('time delta =', end_time-start_time, 'seconds, or', \n",
    "          (end_time-start_time)/60., 'minutes, or',\n",
    "         (end_time-start_time)/60./60., 'hours')\n",
    "    # last run:\n",
    "    #time delta = 11285.80526137352 seconds, 188.09675435622532 minutes, ~3.3 hours on HAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p = Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 16)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train = data.drop(dev.index)\n",
    "train_data.to_pickle(output_folder+\"/data/train_new_pages\"+ender+\".pkl\")\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b5bf9fc7d14ebca671dfa4693c5838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dc67e0fe494ed1b42e646c0fad87af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13826088, 2)\n",
      "total time = 27.231825828552246 seconds, or 0.4538637638092041 minutes\n"
     ]
    }
   ],
   "source": [
    "# df = train#.head(100)\n",
    "# train_aligned = list(p.imap_unordered(create_windows, \n",
    "#                                       tqdm(zip(df.ocr_aligned, \n",
    "#                                                df.gs_aligned, \n",
    "#                                                [window_length for x in df.ocr_aligned]), \n",
    "#                                            total = len(df.ocr_aligned)),\n",
    "#                                       chunksize = 128))\n",
    "# s = []\n",
    "# for r in tqdm(train_aligned):\n",
    "#     s.extend(r)\n",
    "# train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "# print(train_aligned.shape)\n",
    "# train_aligned.head()\n",
    "start_time = time.time()\n",
    "with Pool(4) as p:\n",
    "    train_aligned = list(p.imap_unordered(create_windows, \n",
    "                                          tqdm(zip(train_data.ocr_aligned, \n",
    "                                                   train_data.gs_aligned, \n",
    "                                                   [window_length for x in train_data.ocr_aligned]), \n",
    "                                               total = len(train_data.ocr_aligned)),\n",
    "                                          chunksize = 128))\n",
    "s = []\n",
    "for r in tqdm(train_aligned):\n",
    "    s.extend(r)\n",
    "train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "print(train_aligned.shape)\n",
    "train_aligned.head()\n",
    "end_time = time.time()\n",
    "print('total time =', end_time-start_time, 'seconds, or', (end_time-start_time)/60., 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This research was supported by the TIER 11th ...</td>\n",
       "      <td>This research was supported by the TIFR 11th ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This research was supported by the TIER 11th F...</td>\n",
       "      <td>This research was supported by the TIFR 11th F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>his research was supported by the TIER 11th Fi...</td>\n",
       "      <td>his research was supported by the TIFR 11th Fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is research was supported by the TIER 11th Fiv...</td>\n",
       "      <td>is research was supported by the TIFR 11th Fiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s research was supported by the TIER 11th Five...</td>\n",
       "      <td>s research was supported by the TIFR 11th Five...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0   This research was supported by the TIER 11th ...   \n",
       "1  This research was supported by the TIER 11th F...   \n",
       "2  his research was supported by the TIER 11th Fi...   \n",
       "3  is research was supported by the TIER 11th Fiv...   \n",
       "4  s research was supported by the TIER 11th Five...   \n",
       "\n",
       "                                              target  \n",
       "0   This research was supported by the TIFR 11th ...  \n",
       "1  This research was supported by the TIFR 11th F...  \n",
       "2  his research was supported by the TIFR 11th Fi...  \n",
       "3  is research was supported by the TIFR 11th Fiv...  \n",
       "4  s research was supported by the TIFR 11th Five...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aligned = train_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid = pd.read_csv(file_dir + val_file)\n",
    "\n",
    "# mask = (pd.isnull(valid['sentences source'])) | (pd.isnull(valid['sentences target']))\n",
    "\n",
    "# valid = valid[~mask]\n",
    "\n",
    "# # now align\n",
    "# gs_aligned = []; ocr_aligned = []\n",
    "# for o,p in zip(valid['sentences source'].values, valid['sentences target'].values):\n",
    "#     eops = Levenshtein.editops(o, p)\n",
    "#     ocr_text_aligned, pdf_text_aligned = align_texts_fast(o,p,eops)\n",
    "#     gs_aligned.append(pdf_text_aligned)\n",
    "#     # futze with ocr aligned so it matches data input\n",
    "#     ocr_text_aligned = ocr_text_aligned.replace('^', '@')\n",
    "#     ocr_aligned.append(ocr_text_aligned)\n",
    "    \n",
    "# valid['gs_aligned'] = gs_aligned\n",
    "# valid['ocr_aligned'] = ocr_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690924, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First. claiming both uses for the spectroscop...</td>\n",
       "      <td>First, claiming both uses for the spectroscop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First. claiming both uses for the spectroscopi...</td>\n",
       "      <td>First, claiming both uses for the spectroscopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irst. claiming both uses for the spectroscopic...</td>\n",
       "      <td>irst, claiming both uses for the spectroscopic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rst. claiming both uses for the spectroscopic ...</td>\n",
       "      <td>rst, claiming both uses for the spectroscopic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st. claiming both uses for the spectroscopic s...</td>\n",
       "      <td>st, claiming both uses for the spectroscopic s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0   First. claiming both uses for the spectroscop...   \n",
       "1  First. claiming both uses for the spectroscopi...   \n",
       "2  irst. claiming both uses for the spectroscopic...   \n",
       "3  rst. claiming both uses for the spectroscopic ...   \n",
       "4  st. claiming both uses for the spectroscopic s...   \n",
       "\n",
       "                                              target  \n",
       "0   First, claiming both uses for the spectroscop...  \n",
       "1  First, claiming both uses for the spectroscopi...  \n",
       "2  irst, claiming both uses for the spectroscopic...  \n",
       "3  rst, claiming both uses for the spectroscopic ...  \n",
       "4  st, claiming both uses for the spectroscopic s...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = val_data.apply(lambda r: create_windows((r[\"ocr_aligned\"], r[\"gs_aligned\"], window_length)), \n",
    "                            axis = 1).sum()\n",
    "dev_aligned = pd.DataFrame(dev_aligned, columns = [\"source\", \"target\"])\n",
    "print(dev_aligned.shape)\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First. claiming both uses for the spectroscop...</td>\n",
       "      <td>First, claiming both uses for the spectroscop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First. claiming both uses for the spectroscopi...</td>\n",
       "      <td>First, claiming both uses for the spectroscopi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>irst. claiming both uses for the spectroscopic...</td>\n",
       "      <td>irst, claiming both uses for the spectroscopic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rst. claiming both uses for the spectroscopic ...</td>\n",
       "      <td>rst, claiming both uses for the spectroscopic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>st. claiming both uses for the spectroscopic s...</td>\n",
       "      <td>st, claiming both uses for the spectroscopic s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0   First. claiming both uses for the spectroscop...   \n",
       "1  First. claiming both uses for the spectroscopi...   \n",
       "2  irst. claiming both uses for the spectroscopic...   \n",
       "3  rst. claiming both uses for the spectroscopic ...   \n",
       "4  st. claiming both uses for the spectroscopic s...   \n",
       "\n",
       "                                              target  \n",
       "0   First, claiming both uses for the spectroscop...  \n",
       "1  First, claiming both uses for the spectroscopi...  \n",
       "2  irst, claiming both uses for the spectroscopic...  \n",
       "3  rst, claiming both uses for the spectroscopic ...  \n",
       "4  st, claiming both uses for the spectroscopic s...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"data/train_aligned_new_pages\"+ender+\".pkl\")\n",
    "dev_aligned.to_pickle(output_folder+\"data/dev_aligned_new_pages\"+ender+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jnaiman/Downloads/tmp/ocrpost/data/morgan/data/train_aligned_new_pages_small_words.pkl'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder+\"data/train_aligned_new_pages\"+ender+\".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jnaiman/Downloads/tmp/ocrpost/data/morgan/data/dev_aligned_new_pages_small_words.pkl'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder+\"data/dev_aligned_new_pages\"+ender+\".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(train_aligned)):\n",
    "#     d = train_aligned.iloc[i]\n",
    "#     if '@' in d['source'] or '@' in d['target']:\n",
    "#         import sys; sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d['source'], d['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --- orig stuff ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1675029559225,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "z2kK0OnM-R8h"
   },
   "outputs": [],
   "source": [
    "new_data_dir = '/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675029559225,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "cJkio5HIBBbs",
    "outputId": "d36f53e3-4eb0-4840-dba5-110d6b903c77"
   },
   "outputs": [],
   "source": [
    "output_folder = '/home/mcosi153/post_ocr_correction/data/en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7892"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_files = sorted(os.listdir(new_data_dir))\n",
    "len(new_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675029559226,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "4RVQ3jz9AG4J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 38890,
     "status": "ok",
     "timestamp": 1675029598110,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "EXsXQWE6AMiZ"
   },
   "outputs": [],
   "source": [
    "new_data_files = glob(new_data_dir+\"*.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1675029598110,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "GBVQ0lacAkP3",
    "outputId": "a3ebe4e1-b0bd-41e5-ed08-794e8e01b91f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/1005_1005.2297d_14607_psfilefixedRTM_hocr.pickle',\n",
       " '/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/9811_astro-ph9811382d_buzzoni_psfilefixedRTM_hocr.pickle',\n",
       " '/home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/0908_0908.4092d_Jenkins09b_psfilefixedRTM_hocr.pickle']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675029598111,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "YxzYDKTBBk8h",
    "outputId": "5436a35f-7ccc-4847-e4e5-6e8bbf293dd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7891"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675029598111,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "X7RPGyb9Brxp"
   },
   "outputs": [],
   "source": [
    "file0 = 1\n",
    "file_name = new_data_files[file0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml in ./.local/lib/python3.8/site-packages (4.9.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1675029599327,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "HwkWXBp-B-0Z"
   },
   "outputs": [],
   "source": [
    "# with open(file_name,'rb') as f:\n",
    "#     ffout,pdf_text_pages,ocr_text_pages,alignment_pages,pdf_sents_aligned_pages,ocr_sents_aligned_pages,pdf_sents_pages,ocr_sents_pages = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name,'rb') as f:\n",
    "    realign_pages = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1675029599327,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "PJHuDenlcDuK",
    "outputId": "27713c2a-e3b5-4d27-e265-35a7161cf958"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(realign_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1675029599328,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "FoRD0D5lda5X",
    "outputId": "626081a7-7f9e-4083-89c3-463b1bc01af8"
   },
   "outputs": [],
   "source": [
    "#len(pdf_sents_aligned_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1675029599331,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "e8usMbvWq7Wz",
    "outputId": "4039d610-cd1a-4a97-e1e2-b645dab9d555"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '0001_astro-ph0001013d_letter_psfilefixedRTM_hocr - Copy.pickle',\n",
       " '0001_astro-ph0001013d_letter_psfilefixedRTM_hocr.pickle']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files = sorted(os.listdir(folder))\n",
    "#len(files)\n",
    "files = sorted(os.listdir(new_data_dir))\n",
    "len(files)\n",
    "files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 197,
     "status": "ok",
     "timestamp": 1675029599519,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "r8VLa58yq7W0",
    "outputId": "25886572-7414-4141-cd6e-45bb41d8eff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7891"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "files = glob.glob(new_data_dir + '/**/*.pickle', recursive=True)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1146639,
     "status": "ok",
     "timestamp": 1675030746155,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "snkuAAeVq7W1",
    "outputId": "c9a8913e-4458-4a36-9217-3e67c5cef142"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /home/mcosi153/post_ocr_correction/data/ocr_pdf_aligned_sents_each_realign4/1005_1005.2297d_14607_psfilefixedRTM_hocr.pickle\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# def extract(name):\n",
    "   # with open(name) as file: #this is used to open and read text files\n",
    "        #return file.readlines()\n",
    "\n",
    "\n",
    "def create_windows(x):\n",
    "    A, B, window_length = x\n",
    "    assert len(A) == len(B)\n",
    "    return [(A[i:i + window_length], B[i:i + window_length]) \n",
    "            for i in range(len(A) + 1)]\n",
    "    \n",
    "p = Pool(4)\n",
    "    \n",
    "# #data = list(p.imap_unordered(extract, tqdm(files), chunksize = 128,))\n",
    "# #len(data)\n",
    "# #data = extract('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle')\n",
    "\n",
    "source_dataframe = pd.DataFrame({\"ocr_aligned\":[],\"gs_aligned\":[]})\n",
    "\n",
    "#for file_name in files:\n",
    "#for file_index in range(len(files)):# can change length of files ex: files/10 or 1000 to find out if there is less time\n",
    "import random\n",
    "#r = list(range(4773))\n",
    "r = list(range(40))\n",
    "random.shuffle(r)\n",
    "pdf_ocr = []\n",
    "for file_index in r: \n",
    "    file_name = files[file_index]\n",
    "    if file_index % 200 == 0:\n",
    "        print(str(file_index) + \" \" + file_name)\n",
    "    for key in realign_pages:\n",
    "        if 'PDF' in realign_pages[key] and 'OCR' in realign_pages[key]:\n",
    "            pdf_ocr.append({'ocr_aligned': realign_pages[key]['OCR'],'gs_aligned': realign_pages[key]['PDF']})\n",
    "\n",
    "    source_dataframe = pd.DataFrame(pdf_ocr)\n",
    "    #fh = open(str(file_name), 'rb')\n",
    "    #ffout,pdf_text_pages, ocr_text_pages, alignment_pages, pdf_sents_aligned_pages, ocr_sents_aligned_pages, pdf_sents_pages, ocr_sents_pages = pickle.load(fh)\n",
    "    ##print(len(pdf_sents_aligned_pages.keys()))\n",
    "    ##import sys; sys.exit()\n",
    "    #for key in pdf_sents_aligned_pages.keys():\n",
    "      ##for ocr_sents, pdf_sents in zip(ocr_sents_aligned_pages[key], pdf_sents_aligned_pages[key]):\n",
    "        #if ocr_sents_aligned_pages[key] != \"\" and pdf_sents_aligned_pages[key] != \"\":\n",
    "        ##print(\"not empty\")\n",
    "        ##print(key)\n",
    "            #new_dataframe = pd.DataFrame({\"ocr_aligned\":ocr_sents_aligned_pages[key], \"gs_aligned\":pdf_sents_aligned_pages[key]})\n",
    "            #source_dataframe = pd.concat([source_dataframe, new_dataframe], ignore_index = True, sort = False)\n",
    "#         else:\n",
    "#             #print(\"empty string\")\n",
    "#             print(key)\n",
    "\n",
    "# #use source_dataframe add code here to remove str from list\n",
    "# #empty_list = []\n",
    "#print(source_dataframe.shape)\n",
    "\n",
    "# # for index in range(len(source_dataframe.ocr_aligned)-1):\n",
    "# #   if type(source_dataframe.ocr_aligned[index]) != list:\n",
    "# #     source_dataframe.ocr_aligned.pop(index)\n",
    "# #     source_dataframe.gs_aligned.pop(index)\n",
    "\n",
    "# #print(source_dataframe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1675030746155,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "3qXs2vD9AJb_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ã€ basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ã€ basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ocr_aligned  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1  Ã€ basic step when asseniblung a vunthetec stel...   \n",
       "2  As a general feature. SSP post-MS evolution is...   \n",
       "3  MPollax population svuthesis has extensively b...   \n",
       "4  Ã€ basic step when asseniblung a vunthetec stel...   \n",
       "\n",
       "                                          gs_aligned  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  A basic step when assem@bling a synthetic stel...  \n",
       "2  As a general feature, SSP post-MS evolution is...  \n",
       "3  Stellar population synthesis has extensively b...  \n",
       "4  A basic step when assem@bling a synthetic stel...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1675030746395,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "NfsLhS5z5kjc",
    "outputId": "ea6f19dd-8145-465d-f863-bc15b8684f4d"
   },
   "outputs": [],
   "source": [
    "# for index_number in range(len(source_dataframe.gs_aligned)):\n",
    "#     if index_number % 5000 == 0:\n",
    "#       #print(source_dataframe.ocr_aligned[index_number])\n",
    "#       #print(source_dataframe.gs_aligned[index_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_dataframe.to_csv(\"full_source_dataframe_to_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1675030746396,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "GwiynkJtI9Bt"
   },
   "outputs": [],
   "source": [
    "# the rest of the code is using \"data\" for dataframe\n",
    "data = source_dataframe \n",
    "#data = pd.read_csv(\"full_train_data_672699.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1675030746396,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "Cyk27SJN9a5E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1675030746397,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "SQGTCyu8FLkL",
    "outputId": "24f6cc78-c74c-4bc6-9a7a-993482c9ec29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 2)\n"
     ]
    }
   ],
   "source": [
    "#check how many rows in data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675030746397,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "0FEvNdiGy9fw"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ã€ basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ã€ basic step when asseniblung a vunthetec stel...</td>\n",
       "      <td>A basic step when assem@bling a synthetic stel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ocr_aligned  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1  Ã€ basic step when asseniblung a vunthetec stel...   \n",
       "2  As a general feature. SSP post-MS evolution is...   \n",
       "3  MPollax population svuthesis has extensively b...   \n",
       "4  Ã€ basic step when asseniblung a vunthetec stel...   \n",
       "\n",
       "                                          gs_aligned  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  A basic step when assem@bling a synthetic stel...  \n",
       "2  As a general feature, SSP post-MS evolution is...  \n",
       "3  Stellar population synthesis has extensively b...  \n",
       "4  A basic step when assem@bling a synthetic stel...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop(columns=[\"Unnamed: 0.1\", \"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675030746397,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "4EWkOngLg_tb"
   },
   "outputs": [],
   "source": [
    "#this is what i added to make a list with one pickle file\n",
    "#lst = pd.read_pickle('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle')\n",
    "#with open('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle','rb') as f:\n",
    "# ffout,pdf_text_pages,ocr_text_pages,alignment_pages,pdf_sents_aligned_pages,ocr_sents_aligned_pages,pdf_sents_pages,ocr_sents_pages = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675030746808,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "dcF5ZLDYngU7"
   },
   "outputs": [],
   "source": [
    "#df1 = pd.read_pickle('../../../../OCR Spell check WWT Independent Study/data/ocr_pdf_aligned_sents_each2/0311_astro-ph0311556d_belsol_psfilefixedRTM_hocr.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1675030746808,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "ecZb13rZCgWG"
   },
   "outputs": [],
   "source": [
    "#print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675030746809,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "D25RmGn9q7W1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# data = pd.DataFrame(data, \n",
    "#                     columns = [\"ocr_to_input\", \n",
    "#                                \"ocr_aligned\", \n",
    "#                                \"gs_aligned\"])\\\n",
    "# .assign(ocr_to_input = lambda df: df.ocr_to_input.str.replace(\"[OCR_toInput] \", \"\", regex = False),\n",
    "#         ocr_aligned = lambda df: df.ocr_aligned.str.replace(\"[OCR_aligned] \", \"\", regex = False),\n",
    "#         gs_aligned = lambda df: df.gs_aligned.str.replace(\"[ GS_aligned] \", \"\", regex = False))\n",
    "\n",
    "# print(data.shape)\n",
    "# data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675030746809,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "lWgbmIskq7W2"
   },
   "outputs": [],
   "source": [
    "#data.to_csv(\"./github_training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1675030747320,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "0H4on41Gq7W3",
    "outputId": "6e66fe05-b87d-4608-9926-8032aec81fdc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.333333</td>\n",
       "      <td>77.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.946762</td>\n",
       "      <td>0.946762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_aligned  gs_aligned\n",
       "count   120.000000  120.000000\n",
       "mean     77.333333   77.333333\n",
       "std       0.946762    0.946762\n",
       "min      76.000000   76.000000\n",
       "25%      76.000000   76.000000\n",
       "50%      78.000000   78.000000\n",
       "75%      78.000000   78.000000\n",
       "max      78.000000   78.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7763,
     "status": "ok",
     "timestamp": 1675030755080,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "ggB3xzJuq7W3",
    "outputId": "93373911-3756-4b02-a7ec-7f695d6fad20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Levenshtein in ./.local/lib/python3.8/site-packages (0.20.9)\n",
      "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in ./.local/lib/python3.8/site-packages (from Levenshtein) (2.13.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Levenshtein\n",
    "import pandas as pd\n",
    "from Levenshtein import distance\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "       \n",
    "def levenshtein(reference, hypothesis, progress_bar = False):\n",
    "    assert len(reference) == len(hypothesis)\n",
    "    text = zip(reference, hypothesis)\n",
    "    if progress_bar:\n",
    "        text = tqdm(text, total = len(reference))\n",
    "    d = [distance(r, h) for r, h in text]\n",
    "    output = pd.DataFrame({\"reference\":reference, \"hypothesis\":hypothesis})\\\n",
    "    .assign(distance = lambda df: d)\\\n",
    "    .assign(\n",
    "        cer = lambda df: df.apply(\n",
    "            lambda r: 100 * r[\"distance\"] / max(len(r[\"reference\"]), 1), \n",
    "            axis = 1\n",
    "        )\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1675030755080,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "VCTJUASoSvGw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1675030755081,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "VGaMv03Kq7W4"
   },
   "outputs": [],
   "source": [
    "# levenshtein(reference = data.gs_aligned.str.replace(\"@\", \"\"), \n",
    "#             hypothesis = data.ocr_to_input).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15293,
     "status": "ok",
     "timestamp": 1675030770365,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "gwxxtpWyq7W4",
    "outputId": "117a740d-c050-4678-a9be-9b2b5f12d872"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120.000000\n",
       "mean       6.848853\n",
       "std        4.233466\n",
       "min        1.315789\n",
       "25%        1.315789\n",
       "50%        7.692308\n",
       "75%       11.538462\n",
       "max       11.538462\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = data.gs_aligned, \n",
    "            hypothesis = data.ocr_aligned).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Vocabulary(data.ocr_aligned.sum() + data.gs_aligned.sum())\n",
    "print(len(vocabulary))\n",
    "with open(output_folder+\"/\"+\"data/vocabulary_new_pages1.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770365,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "E4kWzO7Elhqc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "Kum9uJQCo3pk"
   },
   "outputs": [],
   "source": [
    "# data.gs_aligned[51173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "-0qvqkwPU5cp"
   },
   "outputs": [],
   "source": [
    "#output_folder = Path(\"../../data/en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "F5VozHE-rWve"
   },
   "outputs": [],
   "source": [
    "# data.ocr_aligned.pop(51173)\n",
    "# data.gs_aligned.pop(51173)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770366,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "i4L_FktbrrBO"
   },
   "outputs": [],
   "source": [
    "# type(data.ocr_aligned[51172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770367,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "lE1Vv2SasRT5"
   },
   "outputs": [],
   "source": [
    "# vocab1 = []\n",
    "# vocab2 = []\n",
    "\n",
    "# for index in range(len(data.ocr_aligned)-1):\n",
    "#   if type(data.ocr_aligned[index]) != type(vocab1):\n",
    "#     print(data.ocr_aligned[index])\n",
    "\n",
    "#   else:\n",
    "#       vocab1 = vocab1 + data.ocr_aligned[index]\n",
    "#     #source_dataframe.ocr_aligned.pop()\n",
    "#     #source_dataframe.gs_aligned.pop()\n",
    "\n",
    "# for index in range(len(data.gs_aligned)-1):\n",
    "#   if type(data.gs_aligned[index]) != type(vocab2):\n",
    "#     print(data.gs_aligned[index])\n",
    "#   else:\n",
    "#       vocab2 = vocab2 + data.gs_aligned[index]\n",
    "#     #source_dataframe.ocr_aligned.pop()\n",
    "\n",
    "# vocab = vocab1 + vocab2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675030770367,
     "user": {
      "displayName": "M. G. Cosillo",
      "userId": "10181870054312695310"
     },
     "user_tz": 360
    },
    "id": "KLyyhirmuoRI"
   },
   "outputs": [],
   "source": [
    "# data.gs_aligned.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "TdHduFRX5LQh"
   },
   "outputs": [],
   "source": [
    "# for d in data.ocr_aligned.values:\n",
    "#   if type(d) != list:\n",
    "#     print(d, \"here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "a9PCUN2c5uDp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@e confront the two models from Table @n this wavelength interval with each other. '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.gs_aligned.values [- 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:38\n"
     ]
    }
   ],
   "source": [
    "ocr = data.ocr_aligned.sum()\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:39\n"
     ]
    }
   ],
   "source": [
    "gs = data.gs_aligned.sum()\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "j5TYBK7Vq7W5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:40\n"
     ]
    }
   ],
   "source": [
    "#vocabulary = Vocabulary(data.ocr_aligned.sum() + data.gs_aligned.sum())\n",
    "vocab = ocr + gs\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:41\n"
     ]
    }
   ],
   "source": [
    "vocabulary = Vocabulary(ocr + gs)\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Current Time = 15:55:42\n"
     ]
    }
   ],
   "source": [
    "# vocabulary = Vocabulary(vocab)\n",
    "print(len(vocabulary))\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Time = 15:55:46\n"
     ]
    }
   ],
   "source": [
    "with open(output_folder+\"/data/vocabulary_new_pages.pkl\", \"wb\") as file:\n",
    "    pickle.dump(vocabulary, file)\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-bv4AXVHq7W5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = data.sample(n = 5, random_state = 1)\n",
    "dev.to_pickle(output_folder+\"/data/dev_new_pages.pkl\")\n",
    "dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Micp4fEsq7W6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data.drop(dev.index)\n",
    "train.to_pickle(output_folder+\"/data/train_new_pages.pkl\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "r4DPEHInq7W6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>115.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.356522</td>\n",
       "      <td>77.356522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.938376</td>\n",
       "      <td>0.938376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_aligned  gs_aligned\n",
       "count   115.000000  115.000000\n",
       "mean     77.356522   77.356522\n",
       "std       0.938376    0.938376\n",
       "min      76.000000   76.000000\n",
       "25%      76.000000   76.000000\n",
       "50%      78.000000   78.000000\n",
       "75%      78.000000   78.000000\n",
       "max      78.000000   78.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "lQZdmXf9q7W7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ocr_aligned</th>\n",
       "      <th>gs_aligned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>76.800000</td>\n",
       "      <td>76.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.095445</td>\n",
       "      <td>1.095445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>76.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ocr_aligned  gs_aligned\n",
       "count     5.000000    5.000000\n",
       "mean     76.800000   76.800000\n",
       "std       1.095445    1.095445\n",
       "min      76.000000   76.000000\n",
       "25%      76.000000   76.000000\n",
       "50%      76.000000   76.000000\n",
       "75%      78.000000   78.000000\n",
       "max      78.000000   78.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.applymap(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "OPyPNC5Mq7W7"
   },
   "outputs": [],
   "source": [
    "# levenshtein(reference = dev.gs_aligned.str.replace(\"@\", \"\"), \n",
    "#              hypothesis = dev.ocr_to_input).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hY6U7SZbq7W7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.000000\n",
       "mean     3.866397\n",
       "std      3.492563\n",
       "min      1.315789\n",
       "25%      1.315789\n",
       "50%      1.315789\n",
       "75%      7.692308\n",
       "max      7.692308\n",
       "Name: cer, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshtein(reference = dev.gs_aligned, \n",
    "            hypothesis = dev.ocr_aligned).cer.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qNJp4_L4q7W8"
   },
   "outputs": [],
   "source": [
    "window_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "# def extract(name):\n",
    "   # with open(name) as file: #this is used to open and read text files\n",
    "        #return file.readlines()\n",
    "\n",
    "\n",
    "def create_windows(x):\n",
    "    A, B, window_length = x\n",
    "    assert len(A) == len(B)\n",
    "    return [(A[i:i + window_length], B[i:i + window_length]) \n",
    "            for i in range(len(A) + 1)]\n",
    "p = Pool(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "rPD8VGSlq7W8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5962392d142487e93770e10285aa49f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd69436e50ec41dd81780bfce0fea979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9011, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pollax population svuthesis has extensively be...</td>\n",
       "      <td>tellar population synthesis has extensively be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollax population svuthesis has extensively bee...</td>\n",
       "      <td>ellar population synthesis has extensively bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llax population svuthesis has extensively been...</td>\n",
       "      <td>llar population synthesis has extensively been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lax population svuthesis has extensively been ...</td>\n",
       "      <td>lar population synthesis has extensively been ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1  Pollax population svuthesis has extensively be...   \n",
       "2  ollax population svuthesis has extensively bee...   \n",
       "3  llax population svuthesis has extensively been...   \n",
       "4  lax population svuthesis has extensively been ...   \n",
       "\n",
       "                                              target  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  tellar population synthesis has extensively be...  \n",
       "2  ellar population synthesis has extensively bee...  \n",
       "3  llar population synthesis has extensively been...  \n",
       "4  lar population synthesis has extensively been ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train#.head(100)\n",
    "train_aligned = list(p.imap_unordered(create_windows, \n",
    "                                      tqdm(zip(df.ocr_aligned, \n",
    "                                               df.gs_aligned, \n",
    "                                               [window_length for x in df.ocr_aligned]), \n",
    "                                           total = len(df.ocr_aligned)),\n",
    "                                      chunksize = 128))\n",
    "s = []\n",
    "for r in tqdm(train_aligned):\n",
    "    s.extend(r)\n",
    "train_aligned = pd.DataFrame(s, columns = [\"source\", \"target\"])\n",
    "print(train_aligned.shape)\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "NdtLZU8kq7W8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MPollax population svuthesis has extensively b...</td>\n",
       "      <td>Stellar population synthesis has extensively b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pollax population svuthesis has extensively be...</td>\n",
       "      <td>tellar population synthesis has extensively be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollax population svuthesis has extensively bee...</td>\n",
       "      <td>ellar population synthesis has extensively bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llax population svuthesis has extensively been...</td>\n",
       "      <td>llar population synthesis has extensively been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lax population svuthesis has extensively been ...</td>\n",
       "      <td>lar population synthesis has extensively been ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  MPollax population svuthesis has extensively b...   \n",
       "1  Pollax population svuthesis has extensively be...   \n",
       "2  ollax population svuthesis has extensively bee...   \n",
       "3  llax population svuthesis has extensively been...   \n",
       "4  lax population svuthesis has extensively been ...   \n",
       "\n",
       "                                              target  \n",
       "0  Stellar population synthesis has extensively b...  \n",
       "1  tellar population synthesis has extensively be...  \n",
       "2  ellar population synthesis has extensively bee...  \n",
       "3  llar population synthesis has extensively been...  \n",
       "4  lar population synthesis has extensively been ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_aligned = train_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "train_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "vzwv9ldEq7W8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(389, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s a general feature. SSP post-MS evolution is ...</td>\n",
       "      <td>s a general feature, SSP post-MS evolution is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a general feature. SSP post-MS evolution is r...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a general feature. SSP post-MS evolution is re...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general feature. SSP post-MS evolution is rec...</td>\n",
       "      <td>general feature, SSP post-MS evolution is rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  As a general feature. SSP post-MS evolution is...   \n",
       "1  s a general feature. SSP post-MS evolution is ...   \n",
       "2   a general feature. SSP post-MS evolution is r...   \n",
       "3  a general feature. SSP post-MS evolution is re...   \n",
       "4   general feature. SSP post-MS evolution is rec...   \n",
       "\n",
       "                                              target  \n",
       "0  As a general feature, SSP post-MS evolution is...  \n",
       "1  s a general feature, SSP post-MS evolution is ...  \n",
       "2   a general feature, SSP post-MS evolution is r...  \n",
       "3  a general feature, SSP post-MS evolution is re...  \n",
       "4   general feature, SSP post-MS evolution is rec...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev.apply(lambda r: create_windows((r[\"ocr_aligned\"], r[\"gs_aligned\"], window_length)), \n",
    "                            axis = 1).sum()\n",
    "dev_aligned = pd.DataFrame(dev_aligned, columns = [\"source\", \"target\"])\n",
    "print(dev_aligned.shape)\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_sample_df=train_aligned.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_sample_df.to_csv(\"trained_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "55tYY6PRq7W9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As a general feature. SSP post-MS evolution is...</td>\n",
       "      <td>As a general feature, SSP post-MS evolution is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s a general feature. SSP post-MS evolution is ...</td>\n",
       "      <td>s a general feature, SSP post-MS evolution is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a general feature. SSP post-MS evolution is r...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a general feature. SSP post-MS evolution is re...</td>\n",
       "      <td>a general feature, SSP post-MS evolution is re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>general feature. SSP post-MS evolution is rec...</td>\n",
       "      <td>general feature, SSP post-MS evolution is rec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  As a general feature. SSP post-MS evolution is...   \n",
       "1  s a general feature. SSP post-MS evolution is ...   \n",
       "2   a general feature. SSP post-MS evolution is r...   \n",
       "3  a general feature. SSP post-MS evolution is re...   \n",
       "4   general feature. SSP post-MS evolution is rec...   \n",
       "\n",
       "                                              target  \n",
       "0  As a general feature, SSP post-MS evolution is...  \n",
       "1  s a general feature, SSP post-MS evolution is ...  \n",
       "2   a general feature, SSP post-MS evolution is r...  \n",
       "3  a general feature, SSP post-MS evolution is re...  \n",
       "4   general feature, SSP post-MS evolution is rec...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_aligned = dev_aligned.assign(source = lambda df: df.source.str.replace(\"@\", \"\"))\n",
    "dev_aligned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"/data/train_aligned_new_pages.pkl\")\n",
    "dev_aligned.to_pickle(output_folder+\"/data/dev_aligned_new_pages.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91919976"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 dataframes have been created so far\n",
      "20 dataframes have been created so far\n",
      "30 dataframes have been created so far\n",
      "40 dataframes have been created so far\n",
      "50 dataframes have been created so far\n",
      "60 dataframes have been created so far\n",
      "70 dataframes have been created so far\n",
      "80 dataframes have been created so far\n",
      "90 dataframes have been created so far\n"
     ]
    }
   ],
   "source": [
    "train_aligned_chunks = np.array_split(df, 92)\n",
    "for i, df in enumerate(train_aligned_chunks):\n",
    "    if i % 10 == 0 and i != 0:\n",
    "        print(f\"{i} dataframes have been created so far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(92):\n",
    "    train_aligned_chunks[i].to_pickle(output_folder+\"/data/train_aligned_new_full\"+str(i).zfill(4)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df = dev_aligned\n",
    "len(dev_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.to_pickle(output_folder+\"/data/dev_aligned_new_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nLXGOTHq7W9"
   },
   "outputs": [],
   "source": [
    "train_aligned.to_pickle(output_folder+\"/data/train_aligned_new_full.pkl\")\n",
    "dev_aligned.to_pickle(output_folder+\"/data/dev_aligned_new_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle(output_folder+\"/data/train_aligned_new_full.pkl\")\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0,100,size=(100, 4)), columns=list('ABCD'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>41</td>\n",
       "      <td>27</td>\n",
       "      <td>88</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>85</td>\n",
       "      <td>39</td>\n",
       "      <td>59</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>69</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>95</td>\n",
       "      <td>97</td>\n",
       "      <td>90</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B   C   D\n",
       "0   29  94  33  50\n",
       "1   14  54  75  51\n",
       "2   35  36  61  66\n",
       "3   25   9  72  41\n",
       "4   26  66   9  22\n",
       "..  ..  ..  ..  ..\n",
       "95  41  27  88  65\n",
       "96   6  53  39  52\n",
       "97  85  39  59  92\n",
       "98  69  51   1  87\n",
       "99  95  97  90  25\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks = np.array_split(df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90</td>\n",
       "      <td>64</td>\n",
       "      <td>78</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>77</td>\n",
       "      <td>95</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>38</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>68</td>\n",
       "      <td>94</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   C   D\n",
       "0  29  94  33  50\n",
       "1  14  54  75  51\n",
       "2  35  36  61  66\n",
       "3  25   9  72  41\n",
       "4  26  66   9  22\n",
       "5  90  64  78  94\n",
       "6  77  95  99  98\n",
       "7  34  32  88  43\n",
       "8   2  80  38  18\n",
       "9  68  94  10   9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1946020/866910306.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_chunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/data/train_aligned_new_full\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    df_chunks[i].to_pickle(output_folder+\"/data/train_aligned_new_full\"+str(i).zfill(3)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
